2024-11-11 16:33:02,480 [trainer.py] => model: dsease_hoc
2024-11-11 16:33:02,480 [trainer.py] => prefix:  
2024-11-11 16:33:02,480 [trainer.py] => dataset: cifar224
2024-11-11 16:33:02,480 [trainer.py] => memory_size: 0
2024-11-11 16:33:02,480 [trainer.py] => memory_per_class: 0
2024-11-11 16:33:02,480 [trainer.py] => fixed_memory: False
2024-11-11 16:33:02,480 [trainer.py] => shuffle: True
2024-11-11 16:33:02,480 [trainer.py] => init_cls: 5
2024-11-11 16:33:02,481 [trainer.py] => increment: 5
2024-11-11 16:33:02,481 [trainer.py] => model_name: dsease_hoc
2024-11-11 16:33:02,481 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 16:33:02,481 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-11 16:33:02,481 [trainer.py] => seed: 110
2024-11-11 16:33:02,481 [trainer.py] => wandb_log: False
2024-11-11 16:33:02,481 [trainer.py] => test_future: False
2024-11-11 16:33:02,481 [trainer.py] => init_epochs: 3
2024-11-11 16:33:02,481 [trainer.py] => init_lr: 0.025
2024-11-11 16:33:02,481 [trainer.py] => later_epochs: 3
2024-11-11 16:33:02,481 [trainer.py] => later_lr: 0.025
2024-11-11 16:33:02,481 [trainer.py] => batch_size: 48
2024-11-11 16:33:02,482 [trainer.py] => weight_decay: 0.0005
2024-11-11 16:33:02,482 [trainer.py] => min_lr: 0
2024-11-11 16:33:02,482 [trainer.py] => optimizer: sgd
2024-11-11 16:33:02,482 [trainer.py] => scheduler: cosine
2024-11-11 16:33:02,482 [trainer.py] => pretrained: True
2024-11-11 16:33:02,482 [trainer.py] => vpt_type: Deep
2024-11-11 16:33:02,482 [trainer.py] => prompt_token_num: 5
2024-11-11 16:33:02,482 [trainer.py] => ffn_num: 64
2024-11-11 16:33:02,482 [trainer.py] => use_diagonal: False
2024-11-11 16:33:02,482 [trainer.py] => recalc_sim: True
2024-11-11 16:33:02,482 [trainer.py] => alpha: 0.1
2024-11-11 16:33:02,482 [trainer.py] => use_init_ptm: False
2024-11-11 16:33:02,482 [trainer.py] => beta: 0
2024-11-11 16:33:02,483 [trainer.py] => use_old_data: False
2024-11-11 16:33:02,483 [trainer.py] => use_reweight: False
2024-11-11 16:33:02,483 [trainer.py] => moni_adam: False
2024-11-11 16:33:02,483 [trainer.py] => adapter_num: -1
2024-11-11 16:33:04,192 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 16:33:40,758 [trainer.py] => model: dsease_hoc
2024-11-11 16:33:40,759 [trainer.py] => prefix:  
2024-11-11 16:33:40,759 [trainer.py] => dataset: cifar224
2024-11-11 16:33:40,759 [trainer.py] => memory_size: 0
2024-11-11 16:33:40,759 [trainer.py] => memory_per_class: 0
2024-11-11 16:33:40,759 [trainer.py] => fixed_memory: False
2024-11-11 16:33:40,759 [trainer.py] => shuffle: True
2024-11-11 16:33:40,759 [trainer.py] => init_cls: 5
2024-11-11 16:33:40,759 [trainer.py] => increment: 5
2024-11-11 16:33:40,759 [trainer.py] => model_name: dsease_hoc
2024-11-11 16:33:40,759 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 16:33:40,759 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-11 16:33:40,759 [trainer.py] => seed: 110
2024-11-11 16:33:40,759 [trainer.py] => wandb_log: False
2024-11-11 16:33:40,759 [trainer.py] => test_future: False
2024-11-11 16:33:40,759 [trainer.py] => init_epochs: 3
2024-11-11 16:33:40,759 [trainer.py] => init_lr: 0.025
2024-11-11 16:33:40,759 [trainer.py] => later_epochs: 3
2024-11-11 16:33:40,759 [trainer.py] => later_lr: 0.025
2024-11-11 16:33:40,759 [trainer.py] => batch_size: 48
2024-11-11 16:33:40,759 [trainer.py] => weight_decay: 0.0005
2024-11-11 16:33:40,759 [trainer.py] => min_lr: 0
2024-11-11 16:33:40,759 [trainer.py] => optimizer: sgd
2024-11-11 16:33:40,760 [trainer.py] => scheduler: cosine
2024-11-11 16:33:40,760 [trainer.py] => pretrained: True
2024-11-11 16:33:40,760 [trainer.py] => vpt_type: Deep
2024-11-11 16:33:40,760 [trainer.py] => prompt_token_num: 5
2024-11-11 16:33:40,760 [trainer.py] => ffn_num: 64
2024-11-11 16:33:40,760 [trainer.py] => use_diagonal: False
2024-11-11 16:33:40,760 [trainer.py] => recalc_sim: True
2024-11-11 16:33:40,760 [trainer.py] => alpha: 0.1
2024-11-11 16:33:40,760 [trainer.py] => use_init_ptm: False
2024-11-11 16:33:40,760 [trainer.py] => beta: 0
2024-11-11 16:33:40,760 [trainer.py] => use_old_data: False
2024-11-11 16:33:40,760 [trainer.py] => use_reweight: False
2024-11-11 16:33:40,760 [trainer.py] => moni_adam: False
2024-11-11 16:33:40,760 [trainer.py] => adapter_num: -1
2024-11-11 16:33:42,457 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 16:35:58,352 [trainer.py] => model: dsease_hoc
2024-11-11 16:35:58,352 [trainer.py] => prefix:  
2024-11-11 16:35:58,352 [trainer.py] => dataset: cifar224
2024-11-11 16:35:58,352 [trainer.py] => memory_size: 0
2024-11-11 16:35:58,352 [trainer.py] => memory_per_class: 0
2024-11-11 16:35:58,352 [trainer.py] => fixed_memory: False
2024-11-11 16:35:58,352 [trainer.py] => shuffle: True
2024-11-11 16:35:58,352 [trainer.py] => init_cls: 5
2024-11-11 16:35:58,352 [trainer.py] => increment: 5
2024-11-11 16:35:58,352 [trainer.py] => model_name: dsease_hoc
2024-11-11 16:35:58,352 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 16:35:58,352 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-11 16:35:58,352 [trainer.py] => seed: 110
2024-11-11 16:35:58,352 [trainer.py] => wandb_log: False
2024-11-11 16:35:58,352 [trainer.py] => test_future: False
2024-11-11 16:35:58,352 [trainer.py] => init_epochs: 3
2024-11-11 16:35:58,352 [trainer.py] => init_lr: 0.025
2024-11-11 16:35:58,353 [trainer.py] => later_epochs: 3
2024-11-11 16:35:58,353 [trainer.py] => later_lr: 0.025
2024-11-11 16:35:58,353 [trainer.py] => batch_size: 48
2024-11-11 16:35:58,353 [trainer.py] => weight_decay: 0.0005
2024-11-11 16:35:58,353 [trainer.py] => min_lr: 0
2024-11-11 16:35:58,353 [trainer.py] => optimizer: sgd
2024-11-11 16:35:58,353 [trainer.py] => scheduler: cosine
2024-11-11 16:35:58,353 [trainer.py] => pretrained: True
2024-11-11 16:35:58,353 [trainer.py] => vpt_type: Deep
2024-11-11 16:35:58,353 [trainer.py] => prompt_token_num: 5
2024-11-11 16:35:58,353 [trainer.py] => ffn_num: 64
2024-11-11 16:35:58,353 [trainer.py] => use_diagonal: False
2024-11-11 16:35:58,353 [trainer.py] => recalc_sim: True
2024-11-11 16:35:58,353 [trainer.py] => alpha: 0.1
2024-11-11 16:35:58,353 [trainer.py] => use_init_ptm: False
2024-11-11 16:35:58,353 [trainer.py] => beta: 0
2024-11-11 16:35:58,353 [trainer.py] => use_old_data: False
2024-11-11 16:35:58,353 [trainer.py] => use_reweight: False
2024-11-11 16:35:58,353 [trainer.py] => moni_adam: False
2024-11-11 16:35:58,353 [trainer.py] => adapter_num: -1
2024-11-11 16:36:00,057 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 16:36:35,323 [trainer.py] => model: dsease_hoc
2024-11-11 16:36:35,323 [trainer.py] => prefix:  
2024-11-11 16:36:35,323 [trainer.py] => dataset: cifar224
2024-11-11 16:36:35,323 [trainer.py] => memory_size: 0
2024-11-11 16:36:35,323 [trainer.py] => memory_per_class: 0
2024-11-11 16:36:35,323 [trainer.py] => fixed_memory: False
2024-11-11 16:36:35,323 [trainer.py] => shuffle: True
2024-11-11 16:36:35,323 [trainer.py] => init_cls: 5
2024-11-11 16:36:35,323 [trainer.py] => increment: 5
2024-11-11 16:36:35,323 [trainer.py] => model_name: dsease_hoc
2024-11-11 16:36:35,323 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 16:36:35,323 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-11 16:36:35,323 [trainer.py] => seed: 110
2024-11-11 16:36:35,323 [trainer.py] => wandb_log: False
2024-11-11 16:36:35,323 [trainer.py] => test_future: False
2024-11-11 16:36:35,323 [trainer.py] => init_epochs: 3
2024-11-11 16:36:35,323 [trainer.py] => init_lr: 0.025
2024-11-11 16:36:35,323 [trainer.py] => later_epochs: 3
2024-11-11 16:36:35,324 [trainer.py] => later_lr: 0.025
2024-11-11 16:36:35,324 [trainer.py] => batch_size: 48
2024-11-11 16:36:35,324 [trainer.py] => weight_decay: 0.0005
2024-11-11 16:36:35,324 [trainer.py] => min_lr: 0
2024-11-11 16:36:35,324 [trainer.py] => optimizer: sgd
2024-11-11 16:36:35,324 [trainer.py] => scheduler: cosine
2024-11-11 16:36:35,324 [trainer.py] => pretrained: True
2024-11-11 16:36:35,324 [trainer.py] => vpt_type: Deep
2024-11-11 16:36:35,324 [trainer.py] => prompt_token_num: 5
2024-11-11 16:36:35,324 [trainer.py] => ffn_num: 64
2024-11-11 16:36:35,324 [trainer.py] => use_diagonal: False
2024-11-11 16:36:35,324 [trainer.py] => recalc_sim: True
2024-11-11 16:36:35,324 [trainer.py] => alpha: 0.1
2024-11-11 16:36:35,324 [trainer.py] => use_init_ptm: False
2024-11-11 16:36:35,324 [trainer.py] => beta: 0
2024-11-11 16:36:35,324 [trainer.py] => use_old_data: False
2024-11-11 16:36:35,324 [trainer.py] => use_reweight: False
2024-11-11 16:36:35,324 [trainer.py] => moni_adam: False
2024-11-11 16:36:35,324 [trainer.py] => adapter_num: -1
2024-11-11 16:36:37,025 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 16:36:40,870 [trainer.py] => All params: 87074220
2024-11-11 16:36:40,871 [trainer.py] => Trainable params: 1265664
2024-11-11 16:36:40,872 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 16:36:40,872 [dsease_hoc.py] => Learning on 0-5
2024-11-11 16:36:59,758 [trainer.py] => model: dsease_hoc
2024-11-11 16:36:59,758 [trainer.py] => prefix:  
2024-11-11 16:36:59,758 [trainer.py] => dataset: cifar224
2024-11-11 16:36:59,758 [trainer.py] => memory_size: 0
2024-11-11 16:36:59,758 [trainer.py] => memory_per_class: 0
2024-11-11 16:36:59,758 [trainer.py] => fixed_memory: False
2024-11-11 16:36:59,758 [trainer.py] => shuffle: True
2024-11-11 16:36:59,758 [trainer.py] => init_cls: 5
2024-11-11 16:36:59,758 [trainer.py] => increment: 5
2024-11-11 16:36:59,758 [trainer.py] => model_name: dsease_hoc
2024-11-11 16:36:59,759 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 16:36:59,759 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-11 16:36:59,759 [trainer.py] => seed: 110
2024-11-11 16:36:59,759 [trainer.py] => wandb_log: False
2024-11-11 16:36:59,759 [trainer.py] => test_future: False
2024-11-11 16:36:59,759 [trainer.py] => init_epochs: 3
2024-11-11 16:36:59,759 [trainer.py] => init_lr: 0.025
2024-11-11 16:36:59,759 [trainer.py] => later_epochs: 3
2024-11-11 16:36:59,759 [trainer.py] => later_lr: 0.025
2024-11-11 16:36:59,759 [trainer.py] => batch_size: 48
2024-11-11 16:36:59,759 [trainer.py] => weight_decay: 0.0005
2024-11-11 16:36:59,759 [trainer.py] => min_lr: 0
2024-11-11 16:36:59,759 [trainer.py] => optimizer: sgd
2024-11-11 16:36:59,759 [trainer.py] => scheduler: cosine
2024-11-11 16:36:59,759 [trainer.py] => pretrained: True
2024-11-11 16:36:59,759 [trainer.py] => vpt_type: Deep
2024-11-11 16:36:59,759 [trainer.py] => prompt_token_num: 5
2024-11-11 16:36:59,759 [trainer.py] => ffn_num: 64
2024-11-11 16:36:59,759 [trainer.py] => use_diagonal: False
2024-11-11 16:36:59,759 [trainer.py] => recalc_sim: True
2024-11-11 16:36:59,759 [trainer.py] => alpha: 0.1
2024-11-11 16:36:59,759 [trainer.py] => use_init_ptm: False
2024-11-11 16:36:59,760 [trainer.py] => beta: 0
2024-11-11 16:36:59,760 [trainer.py] => use_old_data: False
2024-11-11 16:36:59,760 [trainer.py] => use_reweight: False
2024-11-11 16:36:59,760 [trainer.py] => moni_adam: False
2024-11-11 16:36:59,760 [trainer.py] => adapter_num: -1
2024-11-11 16:37:01,457 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 16:37:05,693 [trainer.py] => All params: 87074220
2024-11-11 16:37:05,693 [trainer.py] => Trainable params: 1265664
2024-11-11 16:37:05,694 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 16:37:05,694 [dsease_hoc.py] => Learning on 0-5
2024-11-11 16:38:12,344 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.305, Train_accy 94.96
2024-11-11 16:38:32,191 [trainer.py] => model: dsease_hoc
2024-11-11 16:38:32,191 [trainer.py] => prefix:  
2024-11-11 16:38:32,191 [trainer.py] => dataset: cifar224
2024-11-11 16:38:32,191 [trainer.py] => memory_size: 0
2024-11-11 16:38:32,191 [trainer.py] => memory_per_class: 0
2024-11-11 16:38:32,192 [trainer.py] => fixed_memory: False
2024-11-11 16:38:32,192 [trainer.py] => shuffle: True
2024-11-11 16:38:32,192 [trainer.py] => init_cls: 5
2024-11-11 16:38:32,192 [trainer.py] => increment: 5
2024-11-11 16:38:32,192 [trainer.py] => model_name: dsease_hoc
2024-11-11 16:38:32,192 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 16:38:32,192 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-11 16:38:32,192 [trainer.py] => seed: 110
2024-11-11 16:38:32,192 [trainer.py] => wandb_log: False
2024-11-11 16:38:32,192 [trainer.py] => test_future: False
2024-11-11 16:38:32,192 [trainer.py] => init_epochs: 3
2024-11-11 16:38:32,192 [trainer.py] => init_lr: 0.025
2024-11-11 16:38:32,192 [trainer.py] => later_epochs: 3
2024-11-11 16:38:32,192 [trainer.py] => later_lr: 0.025
2024-11-11 16:38:32,192 [trainer.py] => batch_size: 48
2024-11-11 16:38:32,192 [trainer.py] => weight_decay: 0.0005
2024-11-11 16:38:32,192 [trainer.py] => min_lr: 0
2024-11-11 16:38:32,192 [trainer.py] => optimizer: sgd
2024-11-11 16:38:32,192 [trainer.py] => scheduler: cosine
2024-11-11 16:38:32,192 [trainer.py] => pretrained: True
2024-11-11 16:38:32,192 [trainer.py] => vpt_type: Deep
2024-11-11 16:38:32,192 [trainer.py] => prompt_token_num: 5
2024-11-11 16:38:32,193 [trainer.py] => ffn_num: 64
2024-11-11 16:38:32,193 [trainer.py] => use_diagonal: False
2024-11-11 16:38:32,193 [trainer.py] => recalc_sim: True
2024-11-11 16:38:32,193 [trainer.py] => alpha: 0.1
2024-11-11 16:38:32,193 [trainer.py] => use_init_ptm: False
2024-11-11 16:38:32,193 [trainer.py] => beta: 0
2024-11-11 16:38:32,193 [trainer.py] => use_old_data: False
2024-11-11 16:38:32,193 [trainer.py] => use_reweight: False
2024-11-11 16:38:32,193 [trainer.py] => moni_adam: False
2024-11-11 16:38:32,193 [trainer.py] => adapter_num: -1
2024-11-11 16:38:33,900 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 16:38:37,471 [trainer.py] => All params: 87074220
2024-11-11 16:38:37,472 [trainer.py] => Trainable params: 1265664
2024-11-11 16:38:37,473 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 16:38:37,473 [dsease_hoc.py] => Learning on 0-5
2024-11-11 16:39:45,024 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.305, Train_accy 94.96
2024-11-11 16:39:47,731 [dsease_hoc.py] => Task correct: 100.0
2024-11-11 16:39:47,731 [dsease_hoc.py] => Task acc: 99.2
2024-11-11 16:39:47,772 [trainer.py] => No NME accuracy.
2024-11-11 16:39:47,772 [trainer.py] => CNN: {'total': 99.2, '00-04': 99.2, 'old': 0, 'new': 99.2}
2024-11-11 16:39:47,773 [trainer.py] => CNN top1 curve: [99.2]
2024-11-11 16:39:47,773 [trainer.py] => CNN top5 curve: [100.0]

2024-11-11 16:39:47,773 [trainer.py] => Average Accuracy (CNN): 99.2 

2024-11-11 16:39:47,774 [trainer.py] => All params: 87074220
2024-11-11 16:39:47,775 [trainer.py] => Trainable params: 1189632
2024-11-11 16:40:22,381 [trainer.py] => model: dsease_hoc
2024-11-11 16:40:22,381 [trainer.py] => prefix:  
2024-11-11 16:40:22,381 [trainer.py] => dataset: cifar224
2024-11-11 16:40:22,381 [trainer.py] => memory_size: 0
2024-11-11 16:40:22,381 [trainer.py] => memory_per_class: 0
2024-11-11 16:40:22,381 [trainer.py] => fixed_memory: False
2024-11-11 16:40:22,381 [trainer.py] => shuffle: True
2024-11-11 16:40:22,381 [trainer.py] => init_cls: 5
2024-11-11 16:40:22,381 [trainer.py] => increment: 5
2024-11-11 16:40:22,381 [trainer.py] => model_name: dsease_hoc
2024-11-11 16:40:22,381 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 16:40:22,382 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-11 16:40:22,382 [trainer.py] => seed: 110
2024-11-11 16:40:22,382 [trainer.py] => wandb_log: False
2024-11-11 16:40:22,382 [trainer.py] => test_future: False
2024-11-11 16:40:22,382 [trainer.py] => init_epochs: 3
2024-11-11 16:40:22,382 [trainer.py] => init_lr: 0.025
2024-11-11 16:40:22,382 [trainer.py] => later_epochs: 3
2024-11-11 16:40:22,382 [trainer.py] => later_lr: 0.025
2024-11-11 16:40:22,382 [trainer.py] => batch_size: 48
2024-11-11 16:40:22,382 [trainer.py] => weight_decay: 0.0005
2024-11-11 16:40:22,382 [trainer.py] => min_lr: 0
2024-11-11 16:40:22,382 [trainer.py] => optimizer: sgd
2024-11-11 16:40:22,382 [trainer.py] => scheduler: cosine
2024-11-11 16:40:22,383 [trainer.py] => pretrained: True
2024-11-11 16:40:22,383 [trainer.py] => vpt_type: Deep
2024-11-11 16:40:22,383 [trainer.py] => prompt_token_num: 5
2024-11-11 16:40:22,383 [trainer.py] => ffn_num: 64
2024-11-11 16:40:22,383 [trainer.py] => use_diagonal: False
2024-11-11 16:40:22,383 [trainer.py] => recalc_sim: True
2024-11-11 16:40:22,383 [trainer.py] => alpha: 0.1
2024-11-11 16:40:22,383 [trainer.py] => use_init_ptm: False
2024-11-11 16:40:22,383 [trainer.py] => beta: 0
2024-11-11 16:40:22,383 [trainer.py] => use_old_data: False
2024-11-11 16:40:22,383 [trainer.py] => use_reweight: False
2024-11-11 16:40:22,383 [trainer.py] => moni_adam: False
2024-11-11 16:40:22,383 [trainer.py] => adapter_num: -1
2024-11-11 16:40:24,056 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 16:40:27,529 [trainer.py] => All params: 87074220
2024-11-11 16:40:27,530 [trainer.py] => Trainable params: 1265664
2024-11-11 16:40:27,531 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 16:40:27,531 [dsease_hoc.py] => Learning on 0-5
2024-11-11 16:41:34,971 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.305, Train_accy 94.96
2024-11-11 16:41:37,677 [dsease_hoc.py] => Task correct: 100.0
2024-11-11 16:41:37,677 [dsease_hoc.py] => Task acc: 99.2
2024-11-11 16:41:37,718 [trainer.py] => No NME accuracy.
2024-11-11 16:41:37,719 [trainer.py] => CNN: {'total': 99.2, '00-04': 99.2, 'old': 0, 'new': 99.2}
2024-11-11 16:41:37,719 [trainer.py] => CNN top1 curve: [99.2]
2024-11-11 16:41:37,719 [trainer.py] => CNN top5 curve: [100.0]

2024-11-11 16:41:37,719 [trainer.py] => Average Accuracy (CNN): 99.2 

2024-11-11 16:41:37,720 [trainer.py] => All params: 87074220
2024-11-11 16:41:37,721 [trainer.py] => Trainable params: 1189632
2024-11-11 16:42:11,807 [trainer.py] => model: dsease_hoc
2024-11-11 16:42:11,807 [trainer.py] => prefix:  
2024-11-11 16:42:11,807 [trainer.py] => dataset: cifar224
2024-11-11 16:42:11,807 [trainer.py] => memory_size: 0
2024-11-11 16:42:11,807 [trainer.py] => memory_per_class: 0
2024-11-11 16:42:11,808 [trainer.py] => fixed_memory: False
2024-11-11 16:42:11,808 [trainer.py] => shuffle: True
2024-11-11 16:42:11,808 [trainer.py] => init_cls: 5
2024-11-11 16:42:11,808 [trainer.py] => increment: 5
2024-11-11 16:42:11,808 [trainer.py] => model_name: dsease_hoc
2024-11-11 16:42:11,808 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 16:42:11,808 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-11 16:42:11,808 [trainer.py] => seed: 110
2024-11-11 16:42:11,808 [trainer.py] => wandb_log: False
2024-11-11 16:42:11,808 [trainer.py] => test_future: False
2024-11-11 16:42:11,808 [trainer.py] => init_epochs: 3
2024-11-11 16:42:11,808 [trainer.py] => init_lr: 0.025
2024-11-11 16:42:11,808 [trainer.py] => later_epochs: 3
2024-11-11 16:42:11,808 [trainer.py] => later_lr: 0.025
2024-11-11 16:42:11,808 [trainer.py] => batch_size: 48
2024-11-11 16:42:11,808 [trainer.py] => weight_decay: 0.0005
2024-11-11 16:42:11,808 [trainer.py] => min_lr: 0
2024-11-11 16:42:11,808 [trainer.py] => optimizer: sgd
2024-11-11 16:42:11,808 [trainer.py] => scheduler: cosine
2024-11-11 16:42:11,808 [trainer.py] => pretrained: True
2024-11-11 16:42:11,808 [trainer.py] => vpt_type: Deep
2024-11-11 16:42:11,808 [trainer.py] => prompt_token_num: 5
2024-11-11 16:42:11,809 [trainer.py] => ffn_num: 64
2024-11-11 16:42:11,809 [trainer.py] => use_diagonal: False
2024-11-11 16:42:11,809 [trainer.py] => recalc_sim: True
2024-11-11 16:42:11,809 [trainer.py] => alpha: 0.1
2024-11-11 16:42:11,809 [trainer.py] => use_init_ptm: False
2024-11-11 16:42:11,809 [trainer.py] => beta: 0
2024-11-11 16:42:11,809 [trainer.py] => use_old_data: False
2024-11-11 16:42:11,809 [trainer.py] => use_reweight: False
2024-11-11 16:42:11,809 [trainer.py] => moni_adam: False
2024-11-11 16:42:11,809 [trainer.py] => adapter_num: -1
2024-11-11 16:42:13,511 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 16:42:17,097 [trainer.py] => All params: 87074220
2024-11-11 16:42:17,098 [trainer.py] => Trainable params: 1265664
2024-11-11 16:42:17,099 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 16:42:17,099 [dsease_hoc.py] => Learning on 0-5
2024-11-11 16:43:24,985 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.305, Train_accy 94.96
2024-11-11 16:43:27,703 [dsease_hoc.py] => Task correct: 100.0
2024-11-11 16:43:27,704 [dsease_hoc.py] => Task acc: 99.2
2024-11-11 16:43:27,731 [trainer.py] => No NME accuracy.
2024-11-11 16:43:27,731 [trainer.py] => CNN: {'total': 99.2, '00-04': 99.2, 'old': 0, 'new': 99.2}
2024-11-11 16:43:27,731 [trainer.py] => CNN top1 curve: [99.2]
2024-11-11 16:43:27,732 [trainer.py] => CNN top5 curve: [100.0]

2024-11-11 16:43:27,732 [trainer.py] => Average Accuracy (CNN): 99.2 

2024-11-11 16:43:27,732 [trainer.py] => All params: 87074220
2024-11-11 16:43:27,733 [trainer.py] => Trainable params: 1189632
2024-11-11 16:43:27,735 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-11 16:43:27,735 [dsease_hoc.py] => Learning on 5-10
2024-11-11 16:45:06,816 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 1.212, Train_accy 93.00
2024-11-11 16:45:16,397 [dsease_hoc.py] => Task correct: 50.0
2024-11-11 16:45:16,398 [dsease_hoc.py] => Task acc: 72.7
2024-11-11 16:45:16,429 [trainer.py] => No NME accuracy.
2024-11-11 16:45:16,429 [trainer.py] => CNN: {'total': 49.3, '00-04': 0.0, '05-09': 98.6, 'old': 0.0, 'new': 98.6}
2024-11-11 16:45:16,429 [trainer.py] => CNN top1 curve: [99.2, 49.3]
2024-11-11 16:45:16,429 [trainer.py] => CNN top5 curve: [100.0, 51.0]

2024-11-11 16:45:16,429 [trainer.py] => Average Accuracy (CNN): 74.25 

2024-11-11 16:45:16,430 [trainer.py] => All params: 87150252
2024-11-11 16:45:16,430 [trainer.py] => Trainable params: 1189632
2024-11-11 16:45:16,434 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-11 16:45:16,434 [dsease_hoc.py] => Learning on 10-15
2024-11-11 19:29:21,596 [trainer.py] => model: dsease_hoc
2024-11-11 19:29:21,619 [trainer.py] => prefix:  
2024-11-11 19:29:21,619 [trainer.py] => dataset: cifar224
2024-11-11 19:29:21,619 [trainer.py] => memory_size: 0
2024-11-11 19:29:21,619 [trainer.py] => memory_per_class: 0
2024-11-11 19:29:21,620 [trainer.py] => fixed_memory: False
2024-11-11 19:29:21,620 [trainer.py] => shuffle: True
2024-11-11 19:29:21,620 [trainer.py] => init_cls: 5
2024-11-11 19:29:21,620 [trainer.py] => increment: 5
2024-11-11 19:29:21,620 [trainer.py] => model_name: dsease_hoc
2024-11-11 19:29:21,620 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 19:29:21,620 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-11 19:29:21,620 [trainer.py] => seed: 110
2024-11-11 19:29:21,620 [trainer.py] => wandb_log: False
2024-11-11 19:29:21,620 [trainer.py] => test_future: False
2024-11-11 19:29:21,620 [trainer.py] => lambda: 0.1
2024-11-11 19:29:21,620 [trainer.py] => mu: 10
2024-11-11 19:29:21,620 [trainer.py] => init_epochs: 3
2024-11-11 19:29:21,621 [trainer.py] => init_lr: 0.025
2024-11-11 19:29:21,621 [trainer.py] => later_epochs: 3
2024-11-11 19:29:21,621 [trainer.py] => later_lr: 0.025
2024-11-11 19:29:21,621 [trainer.py] => batch_size: 48
2024-11-11 19:29:21,621 [trainer.py] => weight_decay: 0.0005
2024-11-11 19:29:21,621 [trainer.py] => min_lr: 0
2024-11-11 19:29:21,621 [trainer.py] => optimizer: sgd
2024-11-11 19:29:21,621 [trainer.py] => scheduler: cosine
2024-11-11 19:29:21,621 [trainer.py] => pretrained: True
2024-11-11 19:29:21,621 [trainer.py] => vpt_type: Deep
2024-11-11 19:29:21,621 [trainer.py] => prompt_token_num: 5
2024-11-11 19:29:21,621 [trainer.py] => ffn_num: 64
2024-11-11 19:29:21,621 [trainer.py] => use_diagonal: False
2024-11-11 19:29:21,621 [trainer.py] => recalc_sim: True
2024-11-11 19:29:21,622 [trainer.py] => alpha: 0.1
2024-11-11 19:29:21,622 [trainer.py] => use_init_ptm: False
2024-11-11 19:29:21,622 [trainer.py] => beta: 0
2024-11-11 19:29:21,622 [trainer.py] => use_old_data: False
2024-11-11 19:29:21,622 [trainer.py] => use_reweight: False
2024-11-11 19:29:21,622 [trainer.py] => moni_adam: False
2024-11-11 19:29:21,622 [trainer.py] => adapter_num: -1
2024-11-11 19:29:24,178 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 19:29:34,456 [trainer.py] => All params: 87074220
2024-11-11 19:29:34,457 [trainer.py] => Trainable params: 1265664
2024-11-11 19:29:34,538 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 19:29:34,538 [dsease_hoc.py] => Learning on 0-5
2024-11-11 19:29:47,439 [trainer.py] => model: dsease_hoc
2024-11-11 19:29:47,439 [trainer.py] => prefix:  
2024-11-11 19:29:47,439 [trainer.py] => dataset: cifar224
2024-11-11 19:29:47,439 [trainer.py] => memory_size: 0
2024-11-11 19:29:47,439 [trainer.py] => memory_per_class: 0
2024-11-11 19:29:47,439 [trainer.py] => fixed_memory: False
2024-11-11 19:29:47,439 [trainer.py] => shuffle: True
2024-11-11 19:29:47,439 [trainer.py] => init_cls: 5
2024-11-11 19:29:47,439 [trainer.py] => increment: 5
2024-11-11 19:29:47,439 [trainer.py] => model_name: dsease_hoc
2024-11-11 19:29:47,439 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 19:29:47,440 [trainer.py] => device: [device(type='cuda', index=0)]
2024-11-11 19:29:47,440 [trainer.py] => seed: 110
2024-11-11 19:29:47,440 [trainer.py] => wandb_log: False
2024-11-11 19:29:47,440 [trainer.py] => test_future: False
2024-11-11 19:29:47,440 [trainer.py] => lambda: 0.1
2024-11-11 19:29:47,440 [trainer.py] => mu: 10
2024-11-11 19:29:47,440 [trainer.py] => init_epochs: 3
2024-11-11 19:29:47,440 [trainer.py] => init_lr: 0.025
2024-11-11 19:29:47,440 [trainer.py] => later_epochs: 3
2024-11-11 19:29:47,440 [trainer.py] => later_lr: 0.025
2024-11-11 19:29:47,440 [trainer.py] => batch_size: 48
2024-11-11 19:29:47,440 [trainer.py] => weight_decay: 0.0005
2024-11-11 19:29:47,440 [trainer.py] => min_lr: 0
2024-11-11 19:29:47,440 [trainer.py] => optimizer: sgd
2024-11-11 19:29:47,440 [trainer.py] => scheduler: cosine
2024-11-11 19:29:47,440 [trainer.py] => pretrained: True
2024-11-11 19:29:47,440 [trainer.py] => vpt_type: Deep
2024-11-11 19:29:47,440 [trainer.py] => prompt_token_num: 5
2024-11-11 19:29:47,440 [trainer.py] => ffn_num: 64
2024-11-11 19:29:47,440 [trainer.py] => use_diagonal: False
2024-11-11 19:29:47,440 [trainer.py] => recalc_sim: True
2024-11-11 19:29:47,441 [trainer.py] => alpha: 0.1
2024-11-11 19:29:47,441 [trainer.py] => use_init_ptm: False
2024-11-11 19:29:47,441 [trainer.py] => beta: 0
2024-11-11 19:29:47,441 [trainer.py] => use_old_data: False
2024-11-11 19:29:47,441 [trainer.py] => use_reweight: False
2024-11-11 19:29:47,441 [trainer.py] => moni_adam: False
2024-11-11 19:29:47,441 [trainer.py] => adapter_num: -1
2024-11-11 19:29:49,216 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 19:29:53,583 [trainer.py] => All params: 87074220
2024-11-11 19:29:53,585 [trainer.py] => Trainable params: 1265664
2024-11-11 19:29:53,654 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 19:29:53,654 [dsease_hoc.py] => Learning on 0-5
2024-11-11 19:30:31,843 [trainer.py] => model: dsease_hoc
2024-11-11 19:30:31,843 [trainer.py] => prefix:  
2024-11-11 19:30:31,843 [trainer.py] => dataset: cifar224
2024-11-11 19:30:31,843 [trainer.py] => memory_size: 0
2024-11-11 19:30:31,843 [trainer.py] => memory_per_class: 0
2024-11-11 19:30:31,843 [trainer.py] => fixed_memory: False
2024-11-11 19:30:31,843 [trainer.py] => shuffle: True
2024-11-11 19:30:31,843 [trainer.py] => init_cls: 5
2024-11-11 19:30:31,843 [trainer.py] => increment: 5
2024-11-11 19:30:31,843 [trainer.py] => model_name: dsease_hoc
2024-11-11 19:30:31,843 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 19:30:31,843 [trainer.py] => device: [device(type='cuda', index=0)]
2024-11-11 19:30:31,843 [trainer.py] => seed: 110
2024-11-11 19:30:31,843 [trainer.py] => wandb_log: False
2024-11-11 19:30:31,843 [trainer.py] => test_future: False
2024-11-11 19:30:31,844 [trainer.py] => lambda: 0.1
2024-11-11 19:30:31,844 [trainer.py] => mu: 10
2024-11-11 19:30:31,844 [trainer.py] => init_epochs: 3
2024-11-11 19:30:31,844 [trainer.py] => init_lr: 0.025
2024-11-11 19:30:31,844 [trainer.py] => later_epochs: 3
2024-11-11 19:30:31,844 [trainer.py] => later_lr: 0.025
2024-11-11 19:30:31,844 [trainer.py] => batch_size: 48
2024-11-11 19:30:31,844 [trainer.py] => weight_decay: 0.0005
2024-11-11 19:30:31,844 [trainer.py] => min_lr: 0
2024-11-11 19:30:31,844 [trainer.py] => optimizer: sgd
2024-11-11 19:30:31,844 [trainer.py] => scheduler: cosine
2024-11-11 19:30:31,844 [trainer.py] => pretrained: True
2024-11-11 19:30:31,844 [trainer.py] => vpt_type: Deep
2024-11-11 19:30:31,844 [trainer.py] => prompt_token_num: 5
2024-11-11 19:30:31,844 [trainer.py] => ffn_num: 64
2024-11-11 19:30:31,844 [trainer.py] => use_diagonal: False
2024-11-11 19:30:31,844 [trainer.py] => recalc_sim: True
2024-11-11 19:30:31,844 [trainer.py] => alpha: 0.1
2024-11-11 19:30:31,845 [trainer.py] => use_init_ptm: False
2024-11-11 19:30:31,845 [trainer.py] => beta: 0
2024-11-11 19:30:31,845 [trainer.py] => use_old_data: False
2024-11-11 19:30:31,845 [trainer.py] => use_reweight: False
2024-11-11 19:30:31,845 [trainer.py] => moni_adam: False
2024-11-11 19:30:31,845 [trainer.py] => adapter_num: -1
2024-11-11 19:30:33,592 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 19:30:38,008 [trainer.py] => All params: 87074220
2024-11-11 19:30:38,009 [trainer.py] => Trainable params: 1265664
2024-11-11 19:30:38,078 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 19:30:38,078 [dsease_hoc.py] => Learning on 0-5
2024-11-11 19:30:58,147 [trainer.py] => model: dsease_hoc
2024-11-11 19:30:58,147 [trainer.py] => prefix:  
2024-11-11 19:30:58,147 [trainer.py] => dataset: cifar224
2024-11-11 19:30:58,147 [trainer.py] => memory_size: 0
2024-11-11 19:30:58,148 [trainer.py] => memory_per_class: 0
2024-11-11 19:30:58,148 [trainer.py] => fixed_memory: False
2024-11-11 19:30:58,148 [trainer.py] => shuffle: True
2024-11-11 19:30:58,148 [trainer.py] => init_cls: 5
2024-11-11 19:30:58,148 [trainer.py] => increment: 5
2024-11-11 19:30:58,148 [trainer.py] => model_name: dsease_hoc
2024-11-11 19:30:58,148 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 19:30:58,148 [trainer.py] => device: [device(type='cuda', index=0)]
2024-11-11 19:30:58,148 [trainer.py] => seed: 110
2024-11-11 19:30:58,148 [trainer.py] => wandb_log: False
2024-11-11 19:30:58,148 [trainer.py] => test_future: False
2024-11-11 19:30:58,148 [trainer.py] => lambda: 0.1
2024-11-11 19:30:58,148 [trainer.py] => mu: 10
2024-11-11 19:30:58,148 [trainer.py] => init_epochs: 3
2024-11-11 19:30:58,148 [trainer.py] => init_lr: 0.025
2024-11-11 19:30:58,148 [trainer.py] => later_epochs: 3
2024-11-11 19:30:58,148 [trainer.py] => later_lr: 0.025
2024-11-11 19:30:58,148 [trainer.py] => batch_size: 48
2024-11-11 19:30:58,148 [trainer.py] => weight_decay: 0.0005
2024-11-11 19:30:58,148 [trainer.py] => min_lr: 0
2024-11-11 19:30:58,148 [trainer.py] => optimizer: sgd
2024-11-11 19:30:58,149 [trainer.py] => scheduler: cosine
2024-11-11 19:30:58,149 [trainer.py] => pretrained: True
2024-11-11 19:30:58,149 [trainer.py] => vpt_type: Deep
2024-11-11 19:30:58,149 [trainer.py] => prompt_token_num: 5
2024-11-11 19:30:58,149 [trainer.py] => ffn_num: 64
2024-11-11 19:30:58,149 [trainer.py] => use_diagonal: False
2024-11-11 19:30:58,149 [trainer.py] => recalc_sim: True
2024-11-11 19:30:58,149 [trainer.py] => alpha: 0.1
2024-11-11 19:30:58,149 [trainer.py] => use_init_ptm: False
2024-11-11 19:30:58,149 [trainer.py] => beta: 0
2024-11-11 19:30:58,149 [trainer.py] => use_old_data: False
2024-11-11 19:30:58,149 [trainer.py] => use_reweight: False
2024-11-11 19:30:58,149 [trainer.py] => moni_adam: False
2024-11-11 19:30:58,149 [trainer.py] => adapter_num: -1
2024-11-11 19:30:59,934 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 19:31:04,426 [trainer.py] => All params: 87074220
2024-11-11 19:31:04,428 [trainer.py] => Trainable params: 1265664
2024-11-11 19:31:04,496 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 19:31:04,496 [dsease_hoc.py] => Learning on 0-5
2024-11-11 20:38:29,501 [trainer.py] => model: dsease_hoc
2024-11-11 20:38:29,518 [trainer.py] => prefix:  
2024-11-11 20:38:29,518 [trainer.py] => dataset: cifar224
2024-11-11 20:38:29,518 [trainer.py] => memory_size: 0
2024-11-11 20:38:29,518 [trainer.py] => memory_per_class: 0
2024-11-11 20:38:29,518 [trainer.py] => fixed_memory: False
2024-11-11 20:38:29,518 [trainer.py] => shuffle: True
2024-11-11 20:38:29,518 [trainer.py] => init_cls: 5
2024-11-11 20:38:29,518 [trainer.py] => increment: 5
2024-11-11 20:38:29,519 [trainer.py] => model_name: dsease_hoc
2024-11-11 20:38:29,519 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 20:38:29,519 [trainer.py] => device: [device(type='cuda', index=0)]
2024-11-11 20:38:29,519 [trainer.py] => seed: 110
2024-11-11 20:38:29,519 [trainer.py] => wandb_log: False
2024-11-11 20:38:29,519 [trainer.py] => test_future: False
2024-11-11 20:38:29,519 [trainer.py] => lambda: 0.1
2024-11-11 20:38:29,519 [trainer.py] => mu: 10
2024-11-11 20:38:29,519 [trainer.py] => init_epochs: 3
2024-11-11 20:38:29,520 [trainer.py] => init_lr: 0.025
2024-11-11 20:38:29,520 [trainer.py] => later_epochs: 3
2024-11-11 20:38:29,520 [trainer.py] => later_lr: 0.025
2024-11-11 20:38:29,520 [trainer.py] => batch_size: 48
2024-11-11 20:38:29,520 [trainer.py] => weight_decay: 0.0005
2024-11-11 20:38:29,520 [trainer.py] => min_lr: 0
2024-11-11 20:38:29,520 [trainer.py] => optimizer: sgd
2024-11-11 20:38:29,520 [trainer.py] => scheduler: cosine
2024-11-11 20:38:29,520 [trainer.py] => pretrained: True
2024-11-11 20:38:29,520 [trainer.py] => vpt_type: Deep
2024-11-11 20:38:29,521 [trainer.py] => prompt_token_num: 5
2024-11-11 20:38:29,521 [trainer.py] => ffn_num: 64
2024-11-11 20:38:29,521 [trainer.py] => use_diagonal: False
2024-11-11 20:38:29,521 [trainer.py] => recalc_sim: True
2024-11-11 20:38:29,521 [trainer.py] => alpha: 0.1
2024-11-11 20:38:29,521 [trainer.py] => use_init_ptm: False
2024-11-11 20:38:29,521 [trainer.py] => beta: 0
2024-11-11 20:38:29,521 [trainer.py] => use_old_data: False
2024-11-11 20:38:29,521 [trainer.py] => use_reweight: False
2024-11-11 20:38:29,522 [trainer.py] => moni_adam: False
2024-11-11 20:38:29,522 [trainer.py] => adapter_num: -1
2024-11-11 20:38:32,004 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 20:38:41,798 [trainer.py] => All params: 87074220
2024-11-11 20:38:41,801 [trainer.py] => Trainable params: 1265664
2024-11-11 20:38:41,961 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 20:38:41,961 [dsease_hoc.py] => Learning on 0-5
2024-11-11 20:40:20,120 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss -2.865, Train_accy 55.96
2024-11-11 20:40:22,913 [dsease_hoc.py] => Task correct: 56.6
2024-11-11 20:40:22,913 [dsease_hoc.py] => Task acc: 88.6
2024-11-11 20:40:22,953 [trainer.py] => No NME accuracy.
2024-11-11 20:40:22,953 [trainer.py] => CNN: {'total': 53.4, '00-04': 53.4, 'old': 0, 'new': 53.4}
2024-11-11 20:40:22,953 [trainer.py] => CNN top1 curve: [53.4]
2024-11-11 20:40:22,953 [trainer.py] => CNN top5 curve: [83.8]

2024-11-11 20:40:22,954 [trainer.py] => Average Accuracy (CNN): 53.4 

2024-11-11 20:40:22,955 [trainer.py] => All params: 87074220
2024-11-11 20:40:22,956 [trainer.py] => Trainable params: 1189632
2024-11-11 20:40:23,015 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-11 20:40:23,015 [dsease_hoc.py] => Learning on 5-10
2024-11-11 20:51:55,036 [trainer.py] => model: dsease_hoc
2024-11-11 20:51:55,036 [trainer.py] => prefix:  
2024-11-11 20:51:55,036 [trainer.py] => dataset: cifar224
2024-11-11 20:51:55,036 [trainer.py] => memory_size: 0
2024-11-11 20:51:55,036 [trainer.py] => memory_per_class: 0
2024-11-11 20:51:55,036 [trainer.py] => fixed_memory: False
2024-11-11 20:51:55,036 [trainer.py] => shuffle: True
2024-11-11 20:51:55,036 [trainer.py] => init_cls: 5
2024-11-11 20:51:55,036 [trainer.py] => increment: 5
2024-11-11 20:51:55,036 [trainer.py] => model_name: dsease_hoc
2024-11-11 20:51:55,036 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 20:51:55,036 [trainer.py] => device: [device(type='cuda', index=0)]
2024-11-11 20:51:55,036 [trainer.py] => seed: 110
2024-11-11 20:51:55,036 [trainer.py] => wandb_log: False
2024-11-11 20:51:55,036 [trainer.py] => test_future: False
2024-11-11 20:51:55,036 [trainer.py] => lambda: 0.1
2024-11-11 20:51:55,036 [trainer.py] => mu: 10
2024-11-11 20:51:55,037 [trainer.py] => init_epochs: 3
2024-11-11 20:51:55,037 [trainer.py] => init_lr: 0.025
2024-11-11 20:51:55,037 [trainer.py] => later_epochs: 3
2024-11-11 20:51:55,037 [trainer.py] => later_lr: 0.025
2024-11-11 20:51:55,037 [trainer.py] => batch_size: 48
2024-11-11 20:51:55,037 [trainer.py] => weight_decay: 0.0005
2024-11-11 20:51:55,037 [trainer.py] => min_lr: 0
2024-11-11 20:51:55,037 [trainer.py] => optimizer: sgd
2024-11-11 20:51:55,037 [trainer.py] => scheduler: cosine
2024-11-11 20:51:55,037 [trainer.py] => pretrained: True
2024-11-11 20:51:55,037 [trainer.py] => vpt_type: Deep
2024-11-11 20:51:55,037 [trainer.py] => prompt_token_num: 5
2024-11-11 20:51:55,037 [trainer.py] => ffn_num: 64
2024-11-11 20:51:55,037 [trainer.py] => use_diagonal: False
2024-11-11 20:51:55,037 [trainer.py] => recalc_sim: True
2024-11-11 20:51:55,037 [trainer.py] => alpha: 0.1
2024-11-11 20:51:55,037 [trainer.py] => use_init_ptm: False
2024-11-11 20:51:55,037 [trainer.py] => beta: 0
2024-11-11 20:51:55,038 [trainer.py] => use_old_data: False
2024-11-11 20:51:55,038 [trainer.py] => use_reweight: False
2024-11-11 20:51:55,038 [trainer.py] => moni_adam: False
2024-11-11 20:51:55,038 [trainer.py] => adapter_num: -1
2024-11-11 20:51:56,699 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 20:52:00,840 [trainer.py] => All params: 87074220
2024-11-11 20:52:00,841 [trainer.py] => Trainable params: 1265664
2024-11-11 20:52:01,031 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 20:52:01,031 [dsease_hoc.py] => Learning on 0-5
2024-11-11 20:55:20,143 [trainer.py] => model: dsease_hoc
2024-11-11 20:55:20,143 [trainer.py] => prefix:  
2024-11-11 20:55:20,143 [trainer.py] => dataset: cifar224
2024-11-11 20:55:20,143 [trainer.py] => memory_size: 0
2024-11-11 20:55:20,143 [trainer.py] => memory_per_class: 0
2024-11-11 20:55:20,143 [trainer.py] => fixed_memory: False
2024-11-11 20:55:20,143 [trainer.py] => shuffle: True
2024-11-11 20:55:20,143 [trainer.py] => init_cls: 5
2024-11-11 20:55:20,143 [trainer.py] => increment: 5
2024-11-11 20:55:20,143 [trainer.py] => model_name: dsease_hoc
2024-11-11 20:55:20,143 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 20:55:20,143 [trainer.py] => device: [device(type='cuda', index=0)]
2024-11-11 20:55:20,143 [trainer.py] => seed: 110
2024-11-11 20:55:20,143 [trainer.py] => wandb_log: False
2024-11-11 20:55:20,144 [trainer.py] => test_future: False
2024-11-11 20:55:20,144 [trainer.py] => lambda: 0.1
2024-11-11 20:55:20,144 [trainer.py] => mu: 10
2024-11-11 20:55:20,144 [trainer.py] => init_epochs: 3
2024-11-11 20:55:20,144 [trainer.py] => init_lr: 0.025
2024-11-11 20:55:20,144 [trainer.py] => later_epochs: 3
2024-11-11 20:55:20,144 [trainer.py] => later_lr: 0.025
2024-11-11 20:55:20,144 [trainer.py] => batch_size: 48
2024-11-11 20:55:20,144 [trainer.py] => weight_decay: 0.0005
2024-11-11 20:55:20,144 [trainer.py] => min_lr: 0
2024-11-11 20:55:20,144 [trainer.py] => optimizer: sgd
2024-11-11 20:55:20,144 [trainer.py] => scheduler: cosine
2024-11-11 20:55:20,144 [trainer.py] => pretrained: True
2024-11-11 20:55:20,144 [trainer.py] => vpt_type: Deep
2024-11-11 20:55:20,144 [trainer.py] => prompt_token_num: 5
2024-11-11 20:55:20,144 [trainer.py] => ffn_num: 64
2024-11-11 20:55:20,144 [trainer.py] => use_diagonal: False
2024-11-11 20:55:20,144 [trainer.py] => recalc_sim: True
2024-11-11 20:55:20,144 [trainer.py] => alpha: 0.1
2024-11-11 20:55:20,144 [trainer.py] => use_init_ptm: False
2024-11-11 20:55:20,144 [trainer.py] => beta: 0
2024-11-11 20:55:20,145 [trainer.py] => use_old_data: False
2024-11-11 20:55:20,145 [trainer.py] => use_reweight: False
2024-11-11 20:55:20,145 [trainer.py] => moni_adam: False
2024-11-11 20:55:20,145 [trainer.py] => adapter_num: -1
2024-11-11 20:55:21,813 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 20:55:25,211 [trainer.py] => All params: 87074220
2024-11-11 20:55:25,212 [trainer.py] => Trainable params: 1265664
2024-11-11 20:55:25,213 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 20:55:25,213 [dsease_hoc.py] => Learning on 0-5
2024-11-11 20:56:28,766 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.305, Train_accy 94.96
2024-11-11 20:56:31,340 [dsease_hoc.py] => Task correct: 100.0
2024-11-11 20:56:31,340 [dsease_hoc.py] => Task acc: 99.2
2024-11-11 20:56:31,369 [trainer.py] => No NME accuracy.
2024-11-11 20:56:31,369 [trainer.py] => CNN: {'total': 99.2, '00-04': 99.2, 'old': 0, 'new': 99.2}
2024-11-11 20:56:31,369 [trainer.py] => CNN top1 curve: [99.2]
2024-11-11 20:56:31,369 [trainer.py] => CNN top5 curve: [100.0]

2024-11-11 20:56:31,369 [trainer.py] => Average Accuracy (CNN): 99.2 

2024-11-11 20:56:31,370 [trainer.py] => All params: 87074220
2024-11-11 20:56:31,370 [trainer.py] => Trainable params: 1189632
2024-11-11 20:56:31,438 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-11 20:56:31,438 [dsease_hoc.py] => Learning on 5-10
2024-11-11 21:04:17,623 [trainer.py] => model: dsease_hoc
2024-11-11 21:04:17,623 [trainer.py] => prefix:  
2024-11-11 21:04:17,623 [trainer.py] => dataset: cifar224
2024-11-11 21:04:17,623 [trainer.py] => memory_size: 0
2024-11-11 21:04:17,623 [trainer.py] => memory_per_class: 0
2024-11-11 21:04:17,623 [trainer.py] => fixed_memory: False
2024-11-11 21:04:17,623 [trainer.py] => shuffle: True
2024-11-11 21:04:17,623 [trainer.py] => init_cls: 5
2024-11-11 21:04:17,624 [trainer.py] => increment: 5
2024-11-11 21:04:17,624 [trainer.py] => model_name: dsease_hoc
2024-11-11 21:04:17,624 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 21:04:17,624 [trainer.py] => device: [device(type='cuda', index=0)]
2024-11-11 21:04:17,624 [trainer.py] => seed: 110
2024-11-11 21:04:17,624 [trainer.py] => wandb_log: False
2024-11-11 21:04:17,624 [trainer.py] => test_future: False
2024-11-11 21:04:17,624 [trainer.py] => lambda: 0.1
2024-11-11 21:04:17,624 [trainer.py] => mu: 10
2024-11-11 21:04:17,624 [trainer.py] => init_epochs: 3
2024-11-11 21:04:17,624 [trainer.py] => init_lr: 0.025
2024-11-11 21:04:17,624 [trainer.py] => later_epochs: 3
2024-11-11 21:04:17,624 [trainer.py] => later_lr: 0.025
2024-11-11 21:04:17,625 [trainer.py] => batch_size: 48
2024-11-11 21:04:17,625 [trainer.py] => weight_decay: 0.0005
2024-11-11 21:04:17,625 [trainer.py] => min_lr: 0
2024-11-11 21:04:17,625 [trainer.py] => optimizer: sgd
2024-11-11 21:04:17,625 [trainer.py] => scheduler: cosine
2024-11-11 21:04:17,625 [trainer.py] => pretrained: True
2024-11-11 21:04:17,625 [trainer.py] => vpt_type: Deep
2024-11-11 21:04:17,625 [trainer.py] => prompt_token_num: 5
2024-11-11 21:04:17,625 [trainer.py] => ffn_num: 64
2024-11-11 21:04:17,625 [trainer.py] => use_diagonal: False
2024-11-11 21:04:17,625 [trainer.py] => recalc_sim: True
2024-11-11 21:04:17,625 [trainer.py] => alpha: 0.1
2024-11-11 21:04:17,625 [trainer.py] => use_init_ptm: False
2024-11-11 21:04:17,626 [trainer.py] => beta: 0
2024-11-11 21:04:17,626 [trainer.py] => use_old_data: False
2024-11-11 21:04:17,626 [trainer.py] => use_reweight: False
2024-11-11 21:04:17,626 [trainer.py] => moni_adam: False
2024-11-11 21:04:17,626 [trainer.py] => adapter_num: -1
2024-11-11 21:04:19,295 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 21:04:22,779 [trainer.py] => All params: 87074220
2024-11-11 21:04:22,780 [trainer.py] => Trainable params: 1265664
2024-11-11 21:04:22,781 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 21:04:22,781 [dsease_hoc.py] => Learning on 0-5
2024-11-11 21:05:26,169 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.305, Train_accy 94.96
2024-11-11 21:05:28,763 [dsease_hoc.py] => Task correct: 100.0
2024-11-11 21:05:28,763 [dsease_hoc.py] => Task acc: 99.2
2024-11-11 21:05:28,805 [trainer.py] => No NME accuracy.
2024-11-11 21:05:28,805 [trainer.py] => CNN: {'total': 99.2, '00-04': 99.2, 'old': 0, 'new': 99.2}
2024-11-11 21:05:28,805 [trainer.py] => CNN top1 curve: [99.2]
2024-11-11 21:05:28,805 [trainer.py] => CNN top5 curve: [100.0]

2024-11-11 21:05:28,805 [trainer.py] => Average Accuracy (CNN): 99.2 

2024-11-11 21:05:28,806 [trainer.py] => All params: 87074220
2024-11-11 21:05:28,807 [trainer.py] => Trainable params: 1189632
2024-11-11 21:05:28,910 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-11 21:05:28,910 [dsease_hoc.py] => Learning on 5-10
2024-11-11 21:10:02,496 [trainer.py] => model: dsease_hoc
2024-11-11 21:10:02,496 [trainer.py] => prefix:  
2024-11-11 21:10:02,496 [trainer.py] => dataset: cifar224
2024-11-11 21:10:02,496 [trainer.py] => memory_size: 0
2024-11-11 21:10:02,496 [trainer.py] => memory_per_class: 0
2024-11-11 21:10:02,496 [trainer.py] => fixed_memory: False
2024-11-11 21:10:02,496 [trainer.py] => shuffle: True
2024-11-11 21:10:02,497 [trainer.py] => init_cls: 5
2024-11-11 21:10:02,497 [trainer.py] => increment: 5
2024-11-11 21:10:02,497 [trainer.py] => model_name: dsease_hoc
2024-11-11 21:10:02,497 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 21:10:02,497 [trainer.py] => device: [device(type='cuda', index=0)]
2024-11-11 21:10:02,497 [trainer.py] => seed: 110
2024-11-11 21:10:02,497 [trainer.py] => wandb_log: False
2024-11-11 21:10:02,497 [trainer.py] => test_future: False
2024-11-11 21:10:02,497 [trainer.py] => lambda: 0.1
2024-11-11 21:10:02,497 [trainer.py] => mu: 10
2024-11-11 21:10:02,497 [trainer.py] => init_epochs: 3
2024-11-11 21:10:02,497 [trainer.py] => init_lr: 0.025
2024-11-11 21:10:02,497 [trainer.py] => later_epochs: 3
2024-11-11 21:10:02,498 [trainer.py] => later_lr: 0.025
2024-11-11 21:10:02,498 [trainer.py] => batch_size: 48
2024-11-11 21:10:02,498 [trainer.py] => weight_decay: 0.0005
2024-11-11 21:10:02,498 [trainer.py] => min_lr: 0
2024-11-11 21:10:02,498 [trainer.py] => optimizer: sgd
2024-11-11 21:10:02,498 [trainer.py] => scheduler: cosine
2024-11-11 21:10:02,498 [trainer.py] => pretrained: True
2024-11-11 21:10:02,498 [trainer.py] => vpt_type: Deep
2024-11-11 21:10:02,498 [trainer.py] => prompt_token_num: 5
2024-11-11 21:10:02,498 [trainer.py] => ffn_num: 64
2024-11-11 21:10:02,498 [trainer.py] => use_diagonal: False
2024-11-11 21:10:02,498 [trainer.py] => recalc_sim: True
2024-11-11 21:10:02,498 [trainer.py] => alpha: 0.1
2024-11-11 21:10:02,499 [trainer.py] => use_init_ptm: False
2024-11-11 21:10:02,499 [trainer.py] => beta: 0
2024-11-11 21:10:02,499 [trainer.py] => use_old_data: False
2024-11-11 21:10:02,499 [trainer.py] => use_reweight: False
2024-11-11 21:10:02,499 [trainer.py] => moni_adam: False
2024-11-11 21:10:02,499 [trainer.py] => adapter_num: -1
2024-11-11 21:10:04,163 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 21:10:07,426 [trainer.py] => All params: 87074220
2024-11-11 21:10:07,427 [trainer.py] => Trainable params: 1265664
2024-11-11 21:10:07,428 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 21:10:07,428 [dsease_hoc.py] => Learning on 0-5
2024-11-11 21:10:43,845 [trainer.py] => model: dsease_hoc
2024-11-11 21:10:43,845 [trainer.py] => prefix:  
2024-11-11 21:10:43,845 [trainer.py] => dataset: cifar224
2024-11-11 21:10:43,845 [trainer.py] => memory_size: 0
2024-11-11 21:10:43,845 [trainer.py] => memory_per_class: 0
2024-11-11 21:10:43,845 [trainer.py] => fixed_memory: False
2024-11-11 21:10:43,845 [trainer.py] => shuffle: True
2024-11-11 21:10:43,845 [trainer.py] => init_cls: 5
2024-11-11 21:10:43,846 [trainer.py] => increment: 5
2024-11-11 21:10:43,846 [trainer.py] => model_name: dsease_hoc
2024-11-11 21:10:43,846 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 21:10:43,846 [trainer.py] => device: [device(type='cuda', index=0)]
2024-11-11 21:10:43,846 [trainer.py] => seed: 110
2024-11-11 21:10:43,846 [trainer.py] => wandb_log: False
2024-11-11 21:10:43,846 [trainer.py] => test_future: False
2024-11-11 21:10:43,846 [trainer.py] => lambda: 0.1
2024-11-11 21:10:43,846 [trainer.py] => mu: 10
2024-11-11 21:10:43,846 [trainer.py] => init_epochs: 3
2024-11-11 21:10:43,846 [trainer.py] => init_lr: 0.025
2024-11-11 21:10:43,846 [trainer.py] => later_epochs: 3
2024-11-11 21:10:43,846 [trainer.py] => later_lr: 0.025
2024-11-11 21:10:43,847 [trainer.py] => batch_size: 48
2024-11-11 21:10:43,847 [trainer.py] => weight_decay: 0.0005
2024-11-11 21:10:43,847 [trainer.py] => min_lr: 0
2024-11-11 21:10:43,847 [trainer.py] => optimizer: sgd
2024-11-11 21:10:43,847 [trainer.py] => scheduler: cosine
2024-11-11 21:10:43,847 [trainer.py] => pretrained: True
2024-11-11 21:10:43,847 [trainer.py] => vpt_type: Deep
2024-11-11 21:10:43,847 [trainer.py] => prompt_token_num: 5
2024-11-11 21:10:43,847 [trainer.py] => ffn_num: 64
2024-11-11 21:10:43,847 [trainer.py] => use_diagonal: False
2024-11-11 21:10:43,847 [trainer.py] => recalc_sim: True
2024-11-11 21:10:43,847 [trainer.py] => alpha: 0.1
2024-11-11 21:10:43,848 [trainer.py] => use_init_ptm: False
2024-11-11 21:10:43,848 [trainer.py] => beta: 0
2024-11-11 21:10:43,848 [trainer.py] => use_old_data: False
2024-11-11 21:10:43,848 [trainer.py] => use_reweight: False
2024-11-11 21:10:43,848 [trainer.py] => moni_adam: False
2024-11-11 21:10:43,848 [trainer.py] => adapter_num: -1
2024-11-11 21:10:45,494 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 21:10:48,978 [trainer.py] => All params: 87074220
2024-11-11 21:10:48,979 [trainer.py] => Trainable params: 1265664
2024-11-11 21:11:45,509 [trainer.py] => model: dsease_hoc
2024-11-11 21:11:45,509 [trainer.py] => prefix:  
2024-11-11 21:11:45,510 [trainer.py] => dataset: cifar224
2024-11-11 21:11:45,510 [trainer.py] => memory_size: 0
2024-11-11 21:11:45,510 [trainer.py] => memory_per_class: 0
2024-11-11 21:11:45,510 [trainer.py] => fixed_memory: False
2024-11-11 21:11:45,510 [trainer.py] => shuffle: True
2024-11-11 21:11:45,510 [trainer.py] => init_cls: 5
2024-11-11 21:11:45,510 [trainer.py] => increment: 5
2024-11-11 21:11:45,510 [trainer.py] => model_name: dsease_hoc
2024-11-11 21:11:45,510 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 21:11:45,510 [trainer.py] => device: [device(type='cuda', index=0)]
2024-11-11 21:11:45,510 [trainer.py] => seed: 110
2024-11-11 21:11:45,510 [trainer.py] => wandb_log: False
2024-11-11 21:11:45,510 [trainer.py] => test_future: False
2024-11-11 21:11:45,511 [trainer.py] => lambda: 0.1
2024-11-11 21:11:45,511 [trainer.py] => mu: 10
2024-11-11 21:11:45,511 [trainer.py] => init_epochs: 3
2024-11-11 21:11:45,511 [trainer.py] => init_lr: 0.025
2024-11-11 21:11:45,511 [trainer.py] => later_epochs: 3
2024-11-11 21:11:45,511 [trainer.py] => later_lr: 0.025
2024-11-11 21:11:45,511 [trainer.py] => batch_size: 48
2024-11-11 21:11:45,511 [trainer.py] => weight_decay: 0.0005
2024-11-11 21:11:45,511 [trainer.py] => min_lr: 0
2024-11-11 21:11:45,511 [trainer.py] => optimizer: sgd
2024-11-11 21:11:45,511 [trainer.py] => scheduler: cosine
2024-11-11 21:11:45,512 [trainer.py] => pretrained: True
2024-11-11 21:11:45,512 [trainer.py] => vpt_type: Deep
2024-11-11 21:11:45,512 [trainer.py] => prompt_token_num: 5
2024-11-11 21:11:45,512 [trainer.py] => ffn_num: 64
2024-11-11 21:11:45,512 [trainer.py] => use_diagonal: False
2024-11-11 21:11:45,512 [trainer.py] => recalc_sim: True
2024-11-11 21:11:45,512 [trainer.py] => alpha: 0.1
2024-11-11 21:11:45,512 [trainer.py] => use_init_ptm: False
2024-11-11 21:11:45,512 [trainer.py] => beta: 0
2024-11-11 21:11:45,512 [trainer.py] => use_old_data: False
2024-11-11 21:11:45,512 [trainer.py] => use_reweight: False
2024-11-11 21:11:45,512 [trainer.py] => moni_adam: False
2024-11-11 21:11:45,512 [trainer.py] => adapter_num: -1
2024-11-11 21:11:47,178 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 21:11:50,754 [trainer.py] => All params: 87074220
2024-11-11 21:11:50,754 [trainer.py] => Trainable params: 1265664
2024-11-11 21:12:22,744 [trainer.py] => model: dsease_hoc
2024-11-11 21:12:22,744 [trainer.py] => prefix:  
2024-11-11 21:12:22,745 [trainer.py] => dataset: cifar224
2024-11-11 21:12:22,745 [trainer.py] => memory_size: 0
2024-11-11 21:12:22,745 [trainer.py] => memory_per_class: 0
2024-11-11 21:12:22,745 [trainer.py] => fixed_memory: False
2024-11-11 21:12:22,745 [trainer.py] => shuffle: True
2024-11-11 21:12:22,745 [trainer.py] => init_cls: 5
2024-11-11 21:12:22,745 [trainer.py] => increment: 5
2024-11-11 21:12:22,745 [trainer.py] => model_name: dsease_hoc
2024-11-11 21:12:22,745 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 21:12:22,745 [trainer.py] => device: [device(type='cuda', index=0)]
2024-11-11 21:12:22,745 [trainer.py] => seed: 110
2024-11-11 21:12:22,745 [trainer.py] => wandb_log: False
2024-11-11 21:12:22,745 [trainer.py] => test_future: False
2024-11-11 21:12:22,746 [trainer.py] => lambda: 0.1
2024-11-11 21:12:22,746 [trainer.py] => mu: 10
2024-11-11 21:12:22,746 [trainer.py] => init_epochs: 3
2024-11-11 21:12:22,746 [trainer.py] => init_lr: 0.025
2024-11-11 21:12:22,746 [trainer.py] => later_epochs: 3
2024-11-11 21:12:22,746 [trainer.py] => later_lr: 0.025
2024-11-11 21:12:22,746 [trainer.py] => batch_size: 48
2024-11-11 21:12:22,746 [trainer.py] => weight_decay: 0.0005
2024-11-11 21:12:22,746 [trainer.py] => min_lr: 0
2024-11-11 21:12:22,746 [trainer.py] => optimizer: sgd
2024-11-11 21:12:22,746 [trainer.py] => scheduler: cosine
2024-11-11 21:12:22,746 [trainer.py] => pretrained: True
2024-11-11 21:12:22,746 [trainer.py] => vpt_type: Deep
2024-11-11 21:12:22,747 [trainer.py] => prompt_token_num: 5
2024-11-11 21:12:22,747 [trainer.py] => ffn_num: 64
2024-11-11 21:12:22,747 [trainer.py] => use_diagonal: False
2024-11-11 21:12:22,747 [trainer.py] => recalc_sim: True
2024-11-11 21:12:22,747 [trainer.py] => alpha: 0.1
2024-11-11 21:12:22,747 [trainer.py] => use_init_ptm: False
2024-11-11 21:12:22,747 [trainer.py] => beta: 0
2024-11-11 21:12:22,747 [trainer.py] => use_old_data: False
2024-11-11 21:12:22,747 [trainer.py] => use_reweight: False
2024-11-11 21:12:22,747 [trainer.py] => moni_adam: False
2024-11-11 21:12:22,747 [trainer.py] => adapter_num: -1
2024-11-11 21:12:24,411 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 21:12:28,444 [trainer.py] => All params: 87074220
2024-11-11 21:12:28,445 [trainer.py] => Trainable params: 1265664
2024-11-11 21:12:28,446 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 21:12:28,446 [dsease_hoc.py] => Learning on 0-5
2024-11-11 21:13:31,538 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.305, Train_accy 94.96
2024-11-11 21:13:34,077 [dsease_hoc.py] => Task correct: 100.0
2024-11-11 21:13:34,077 [dsease_hoc.py] => Task acc: 99.2
2024-11-11 21:13:34,106 [trainer.py] => No NME accuracy.
2024-11-11 21:13:34,106 [trainer.py] => CNN: {'total': 99.2, '00-04': 99.2, 'old': 0, 'new': 99.2}
2024-11-11 21:13:34,106 [trainer.py] => CNN top1 curve: [99.2]
2024-11-11 21:13:34,106 [trainer.py] => CNN top5 curve: [100.0]

2024-11-11 21:13:34,106 [trainer.py] => Average Accuracy (CNN): 99.2 

2024-11-11 21:13:34,107 [trainer.py] => All params: 87074220
2024-11-11 21:13:34,107 [trainer.py] => Trainable params: 1189632
2024-11-11 21:13:34,173 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-11 21:13:34,173 [dsease_hoc.py] => Learning on 5-10
2024-11-11 21:41:21,026 [trainer.py] => model: dsease_hoc
2024-11-11 21:41:21,026 [trainer.py] => prefix:  
2024-11-11 21:41:21,027 [trainer.py] => dataset: cifar224
2024-11-11 21:41:21,027 [trainer.py] => memory_size: 0
2024-11-11 21:41:21,027 [trainer.py] => memory_per_class: 0
2024-11-11 21:41:21,027 [trainer.py] => fixed_memory: False
2024-11-11 21:41:21,027 [trainer.py] => shuffle: True
2024-11-11 21:41:21,027 [trainer.py] => init_cls: 5
2024-11-11 21:41:21,027 [trainer.py] => increment: 5
2024-11-11 21:41:21,027 [trainer.py] => model_name: dsease_hoc
2024-11-11 21:41:21,027 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-11 21:41:21,027 [trainer.py] => device: [device(type='cuda', index=0)]
2024-11-11 21:41:21,027 [trainer.py] => seed: 110
2024-11-11 21:41:21,027 [trainer.py] => wandb_log: False
2024-11-11 21:41:21,027 [trainer.py] => test_future: False
2024-11-11 21:41:21,027 [trainer.py] => lambda: 0.1
2024-11-11 21:41:21,027 [trainer.py] => mu: 10
2024-11-11 21:41:21,027 [trainer.py] => model_weights_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-11 21:41:21,027 [trainer.py] => init_epochs: 3
2024-11-11 21:41:21,027 [trainer.py] => init_lr: 0.025
2024-11-11 21:41:21,027 [trainer.py] => later_epochs: 3
2024-11-11 21:41:21,027 [trainer.py] => later_lr: 0.025
2024-11-11 21:41:21,028 [trainer.py] => batch_size: 48
2024-11-11 21:41:21,028 [trainer.py] => weight_decay: 0.0005
2024-11-11 21:41:21,028 [trainer.py] => min_lr: 0
2024-11-11 21:41:21,028 [trainer.py] => optimizer: sgd
2024-11-11 21:41:21,028 [trainer.py] => scheduler: cosine
2024-11-11 21:41:21,028 [trainer.py] => pretrained: True
2024-11-11 21:41:21,028 [trainer.py] => vpt_type: Deep
2024-11-11 21:41:21,028 [trainer.py] => prompt_token_num: 5
2024-11-11 21:41:21,028 [trainer.py] => ffn_num: 64
2024-11-11 21:41:21,028 [trainer.py] => use_diagonal: False
2024-11-11 21:41:21,028 [trainer.py] => recalc_sim: True
2024-11-11 21:41:21,028 [trainer.py] => alpha: 0.1
2024-11-11 21:41:21,028 [trainer.py] => use_init_ptm: False
2024-11-11 21:41:21,028 [trainer.py] => beta: 0
2024-11-11 21:41:21,028 [trainer.py] => use_old_data: False
2024-11-11 21:41:21,028 [trainer.py] => use_reweight: False
2024-11-11 21:41:21,028 [trainer.py] => moni_adam: False
2024-11-11 21:41:21,028 [trainer.py] => adapter_num: -1
2024-11-11 21:41:22,878 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-11 21:41:26,591 [trainer.py] => All params: 87074220
2024-11-11 21:41:26,591 [trainer.py] => Trainable params: 1265664
2024-11-11 21:41:26,593 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-11 21:41:26,593 [dsease_hoc.py] => Learning on 0-5
2024-11-12 14:04:07,463 [trainer.py] => model: dsease_hoc
2024-11-12 14:04:07,464 [trainer.py] => prefix:  
2024-11-12 14:04:07,464 [trainer.py] => dataset: cifar224
2024-11-12 14:04:07,464 [trainer.py] => memory_size: 0
2024-11-12 14:04:07,464 [trainer.py] => memory_per_class: 0
2024-11-12 14:04:07,464 [trainer.py] => fixed_memory: False
2024-11-12 14:04:07,464 [trainer.py] => shuffle: True
2024-11-12 14:04:07,464 [trainer.py] => init_cls: 5
2024-11-12 14:04:07,464 [trainer.py] => increment: 5
2024-11-12 14:04:07,464 [trainer.py] => model_name: dsease_hoc
2024-11-12 14:04:07,464 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 14:04:07,464 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 14:04:07,464 [trainer.py] => seed: 110
2024-11-12 14:04:07,464 [trainer.py] => wandb_log: False
2024-11-12 14:04:07,464 [trainer.py] => test_future: False
2024-11-12 14:04:07,464 [trainer.py] => lambda: 0.1
2024-11-12 14:04:07,464 [trainer.py] => mu: 10
2024-11-12 14:04:07,464 [trainer.py] => model_weights_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 14:04:07,464 [trainer.py] => init_epochs: 3
2024-11-12 14:04:07,464 [trainer.py] => init_lr: 0.025
2024-11-12 14:04:07,464 [trainer.py] => later_epochs: 3
2024-11-12 14:04:07,465 [trainer.py] => later_lr: 0.025
2024-11-12 14:04:07,465 [trainer.py] => batch_size: 48
2024-11-12 14:04:07,465 [trainer.py] => weight_decay: 0.0005
2024-11-12 14:04:07,465 [trainer.py] => min_lr: 0
2024-11-12 14:04:07,465 [trainer.py] => optimizer: sgd
2024-11-12 14:04:07,465 [trainer.py] => scheduler: cosine
2024-11-12 14:04:07,465 [trainer.py] => pretrained: True
2024-11-12 14:04:07,465 [trainer.py] => vpt_type: Deep
2024-11-12 14:04:07,465 [trainer.py] => prompt_token_num: 5
2024-11-12 14:04:07,465 [trainer.py] => ffn_num: 64
2024-11-12 14:04:07,465 [trainer.py] => use_diagonal: False
2024-11-12 14:04:07,465 [trainer.py] => recalc_sim: True
2024-11-12 14:04:07,465 [trainer.py] => alpha: 0.1
2024-11-12 14:04:07,465 [trainer.py] => use_init_ptm: False
2024-11-12 14:04:07,465 [trainer.py] => beta: 0
2024-11-12 14:04:07,465 [trainer.py] => use_old_data: False
2024-11-12 14:04:07,465 [trainer.py] => use_reweight: False
2024-11-12 14:04:07,465 [trainer.py] => moni_adam: False
2024-11-12 14:04:07,465 [trainer.py] => adapter_num: -1
2024-11-12 14:04:09,208 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 14:04:13,703 [trainer.py] => All params: 87074220
2024-11-12 14:04:13,705 [trainer.py] => Trainable params: 1265664
2024-11-12 14:04:13,707 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-12 14:04:13,707 [dsease_hoc.py] => Learning on 0-5
2024-11-12 14:05:20,186 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.305, Train_accy 94.96
2024-11-12 14:06:33,072 [trainer.py] => model: dsease_hoc
2024-11-12 14:06:33,072 [trainer.py] => prefix:  
2024-11-12 14:06:33,072 [trainer.py] => dataset: cifar224
2024-11-12 14:06:33,072 [trainer.py] => memory_size: 0
2024-11-12 14:06:33,072 [trainer.py] => memory_per_class: 0
2024-11-12 14:06:33,073 [trainer.py] => fixed_memory: False
2024-11-12 14:06:33,073 [trainer.py] => shuffle: True
2024-11-12 14:06:33,073 [trainer.py] => init_cls: 5
2024-11-12 14:06:33,073 [trainer.py] => increment: 5
2024-11-12 14:06:33,073 [trainer.py] => model_name: dsease_hoc
2024-11-12 14:06:33,073 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 14:06:33,073 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 14:06:33,073 [trainer.py] => seed: 110
2024-11-12 14:06:33,073 [trainer.py] => wandb_log: False
2024-11-12 14:06:33,073 [trainer.py] => test_future: False
2024-11-12 14:06:33,073 [trainer.py] => lambda: 0.1
2024-11-12 14:06:33,073 [trainer.py] => mu: 10
2024-11-12 14:06:33,073 [trainer.py] => model_weights_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 14:06:33,073 [trainer.py] => init_epochs: 3
2024-11-12 14:06:33,073 [trainer.py] => init_lr: 0.025
2024-11-12 14:06:33,073 [trainer.py] => later_epochs: 3
2024-11-12 14:06:33,073 [trainer.py] => later_lr: 0.025
2024-11-12 14:06:33,073 [trainer.py] => batch_size: 48
2024-11-12 14:06:33,073 [trainer.py] => weight_decay: 0.0005
2024-11-12 14:06:33,074 [trainer.py] => min_lr: 0
2024-11-12 14:06:33,074 [trainer.py] => optimizer: sgd
2024-11-12 14:06:33,074 [trainer.py] => scheduler: cosine
2024-11-12 14:06:33,074 [trainer.py] => pretrained: True
2024-11-12 14:06:33,074 [trainer.py] => vpt_type: Deep
2024-11-12 14:06:33,074 [trainer.py] => prompt_token_num: 5
2024-11-12 14:06:33,074 [trainer.py] => ffn_num: 64
2024-11-12 14:06:33,074 [trainer.py] => use_diagonal: False
2024-11-12 14:06:33,074 [trainer.py] => recalc_sim: True
2024-11-12 14:06:33,074 [trainer.py] => alpha: 0.1
2024-11-12 14:06:33,074 [trainer.py] => use_init_ptm: False
2024-11-12 14:06:33,074 [trainer.py] => beta: 0
2024-11-12 14:06:33,074 [trainer.py] => use_old_data: False
2024-11-12 14:06:33,074 [trainer.py] => use_reweight: False
2024-11-12 14:06:33,074 [trainer.py] => moni_adam: False
2024-11-12 14:06:33,074 [trainer.py] => adapter_num: -1
2024-11-12 14:06:34,922 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 14:07:44,243 [trainer.py] => model: dsease_hoc
2024-11-12 14:07:44,243 [trainer.py] => prefix:  
2024-11-12 14:07:44,244 [trainer.py] => dataset: cifar224
2024-11-12 14:07:44,244 [trainer.py] => memory_size: 0
2024-11-12 14:07:44,244 [trainer.py] => memory_per_class: 0
2024-11-12 14:07:44,244 [trainer.py] => fixed_memory: False
2024-11-12 14:07:44,244 [trainer.py] => shuffle: True
2024-11-12 14:07:44,244 [trainer.py] => init_cls: 5
2024-11-12 14:07:44,244 [trainer.py] => increment: 5
2024-11-12 14:07:44,244 [trainer.py] => model_name: dsease_hoc
2024-11-12 14:07:44,244 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 14:07:44,244 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 14:07:44,244 [trainer.py] => seed: 110
2024-11-12 14:07:44,244 [trainer.py] => wandb_log: False
2024-11-12 14:07:44,244 [trainer.py] => test_future: False
2024-11-12 14:07:44,244 [trainer.py] => lambda: 0.1
2024-11-12 14:07:44,244 [trainer.py] => mu: 10
2024-11-12 14:07:44,244 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 14:07:44,244 [trainer.py] => init_epochs: 3
2024-11-12 14:07:44,244 [trainer.py] => init_lr: 0.025
2024-11-12 14:07:44,244 [trainer.py] => later_epochs: 3
2024-11-12 14:07:44,244 [trainer.py] => later_lr: 0.025
2024-11-12 14:07:44,244 [trainer.py] => batch_size: 48
2024-11-12 14:07:44,245 [trainer.py] => weight_decay: 0.0005
2024-11-12 14:07:44,245 [trainer.py] => min_lr: 0
2024-11-12 14:07:44,245 [trainer.py] => optimizer: sgd
2024-11-12 14:07:44,245 [trainer.py] => scheduler: cosine
2024-11-12 14:07:44,245 [trainer.py] => pretrained: True
2024-11-12 14:07:44,245 [trainer.py] => vpt_type: Deep
2024-11-12 14:07:44,245 [trainer.py] => prompt_token_num: 5
2024-11-12 14:07:44,245 [trainer.py] => ffn_num: 64
2024-11-12 14:07:44,245 [trainer.py] => use_diagonal: False
2024-11-12 14:07:44,245 [trainer.py] => recalc_sim: True
2024-11-12 14:07:44,245 [trainer.py] => alpha: 0.1
2024-11-12 14:07:44,245 [trainer.py] => use_init_ptm: False
2024-11-12 14:07:44,245 [trainer.py] => beta: 0
2024-11-12 14:07:44,245 [trainer.py] => use_old_data: False
2024-11-12 14:07:44,245 [trainer.py] => use_reweight: False
2024-11-12 14:07:44,245 [trainer.py] => moni_adam: False
2024-11-12 14:07:44,245 [trainer.py] => adapter_num: -1
2024-11-12 14:07:45,886 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 14:07:49,684 [trainer.py] => All params: 87074220
2024-11-12 14:07:49,685 [trainer.py] => Trainable params: 1265664
2024-11-12 14:07:49,687 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-12 14:07:49,687 [dsease_hoc.py] => Learning on 0-5
2024-11-12 14:08:56,306 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.305, Train_accy 94.96
2024-11-12 14:08:59,483 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 14:08:59,484 [dsease_hoc.py] => Task acc: 99.2
2024-11-12 14:08:59,515 [trainer.py] => No NME accuracy.
2024-11-12 14:08:59,516 [trainer.py] => CNN: {'total': 99.2, '00-04': 99.2, 'old': 0, 'new': 99.2}
2024-11-12 14:08:59,516 [trainer.py] => CNN top1 curve: [99.2]
2024-11-12 14:08:59,516 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 14:08:59,516 [trainer.py] => Average Accuracy (CNN): 99.2 

2024-11-12 14:08:59,517 [trainer.py] => All params: 87074220
2024-11-12 14:08:59,518 [trainer.py] => Trainable params: 1189632
2024-11-12 14:08:59,784 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 14:08:59,784 [dsease_hoc.py] => Learning on 5-10
2024-11-12 14:11:12,283 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 2.330, Train_accy 87.56
2024-11-12 14:11:23,829 [dsease_hoc.py] => Task correct: 92.4
2024-11-12 14:11:23,829 [dsease_hoc.py] => Task acc: 97.2
2024-11-12 14:11:23,864 [trainer.py] => No NME accuracy.
2024-11-12 14:11:23,864 [trainer.py] => CNN: {'total': 91.0, '00-04': 93.6, '05-09': 88.4, 'old': 93.6, 'new': 88.4}
2024-11-12 14:11:23,864 [trainer.py] => CNN top1 curve: [99.2, 91.0]
2024-11-12 14:11:23,865 [trainer.py] => CNN top5 curve: [100.0, 99.2]

2024-11-12 14:11:23,865 [trainer.py] => Average Accuracy (CNN): 95.1 

2024-11-12 14:11:23,865 [trainer.py] => All params: 87150252
2024-11-12 14:11:23,866 [trainer.py] => Trainable params: 1189632
2024-11-12 14:11:24,165 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-12 14:11:24,165 [dsease_hoc.py] => Learning on 10-15
2024-11-12 14:15:16,729 [trainer.py] => model: dsease_hoc
2024-11-12 14:15:16,729 [trainer.py] => prefix:  
2024-11-12 14:15:16,729 [trainer.py] => dataset: cifar224
2024-11-12 14:15:16,730 [trainer.py] => memory_size: 0
2024-11-12 14:15:16,730 [trainer.py] => memory_per_class: 0
2024-11-12 14:15:16,730 [trainer.py] => fixed_memory: False
2024-11-12 14:15:16,730 [trainer.py] => shuffle: True
2024-11-12 14:15:16,731 [trainer.py] => init_cls: 5
2024-11-12 14:15:16,731 [trainer.py] => increment: 5
2024-11-12 14:15:16,731 [trainer.py] => model_name: dsease_hoc
2024-11-12 14:15:16,732 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 14:15:16,732 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 14:15:16,732 [trainer.py] => seed: 110
2024-11-12 14:15:16,732 [trainer.py] => wandb_log: True
2024-11-12 14:15:16,733 [trainer.py] => test_future: False
2024-11-12 14:15:16,733 [trainer.py] => lambda: 0.1
2024-11-12 14:15:16,733 [trainer.py] => mu: 10
2024-11-12 14:15:16,733 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 14:15:16,734 [trainer.py] => init_epochs: 20
2024-11-12 14:15:16,734 [trainer.py] => init_lr: 0.025
2024-11-12 14:15:16,734 [trainer.py] => later_epochs: 20
2024-11-12 14:15:16,735 [trainer.py] => later_lr: 0.025
2024-11-12 14:15:16,735 [trainer.py] => batch_size: 48
2024-11-12 14:15:16,735 [trainer.py] => weight_decay: 0.0005
2024-11-12 14:15:16,735 [trainer.py] => min_lr: 0
2024-11-12 14:15:16,736 [trainer.py] => optimizer: sgd
2024-11-12 14:15:16,736 [trainer.py] => scheduler: cosine
2024-11-12 14:15:16,736 [trainer.py] => pretrained: True
2024-11-12 14:15:16,736 [trainer.py] => vpt_type: Deep
2024-11-12 14:15:16,737 [trainer.py] => prompt_token_num: 5
2024-11-12 14:15:16,737 [trainer.py] => ffn_num: 64
2024-11-12 14:15:16,737 [trainer.py] => use_diagonal: False
2024-11-12 14:15:16,737 [trainer.py] => recalc_sim: True
2024-11-12 14:15:16,738 [trainer.py] => alpha: 0.1
2024-11-12 14:15:16,738 [trainer.py] => use_init_ptm: False
2024-11-12 14:15:16,738 [trainer.py] => beta: 0
2024-11-12 14:15:16,738 [trainer.py] => use_old_data: False
2024-11-12 14:15:16,739 [trainer.py] => use_reweight: False
2024-11-12 14:15:16,739 [trainer.py] => moni_adam: False
2024-11-12 14:15:16,739 [trainer.py] => adapter_num: -1
2024-11-12 14:15:18,616 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 14:15:22,214 [trainer.py] => All params: 87074220
2024-11-12 14:15:22,216 [trainer.py] => Trainable params: 1265664
2024-11-12 14:15:22,217 [dsease_hoc.py] => Total trainable params: 1265664
2024-11-12 14:15:22,217 [dsease_hoc.py] => Learning on 0-5
2024-11-12 14:22:49,318 [dsease_hoc.py] => Task 0, Epoch 20/20 => Loss 0.086, Train_accy 97.16
2024-11-12 14:22:54,515 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 14:22:54,516 [dsease_hoc.py] => Task acc: 99.8
2024-11-12 14:22:54,546 [trainer.py] => No NME accuracy.
2024-11-12 14:22:54,546 [trainer.py] => CNN: {'total': 99.8, '00-04': 99.8, 'old': 0, 'new': 99.8}
2024-11-12 14:22:54,547 [trainer.py] => CNN top1 curve: [99.8]
2024-11-12 14:22:54,547 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 14:22:54,548 [trainer.py] => Average Accuracy (CNN): 99.8 

2024-11-12 14:22:54,550 [trainer.py] => All params: 87074220
2024-11-12 14:22:54,551 [trainer.py] => Trainable params: 1189632
2024-11-12 14:22:54,948 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 14:22:54,949 [dsease_hoc.py] => Learning on 5-10
2024-11-12 14:37:41,998 [dsease_hoc.py] => Task 1, Epoch 20/20 => Loss 1.932, Train_accy 79.48
2024-11-12 14:37:53,548 [dsease_hoc.py] => Task correct: 92.1
2024-11-12 14:37:53,549 [dsease_hoc.py] => Task acc: 99.1
2024-11-12 14:37:53,593 [trainer.py] => No NME accuracy.
2024-11-12 14:37:53,593 [trainer.py] => CNN: {'total': 91.4, '00-04': 98.6, '05-09': 84.2, 'old': 98.6, 'new': 84.2}
2024-11-12 14:37:53,593 [trainer.py] => CNN top1 curve: [99.8, 91.4]
2024-11-12 14:37:53,594 [trainer.py] => CNN top5 curve: [100.0, 99.8]

2024-11-12 14:37:53,594 [trainer.py] => Average Accuracy (CNN): 95.6 

2024-11-12 14:37:53,596 [trainer.py] => All params: 87150252
2024-11-12 14:37:53,597 [trainer.py] => Trainable params: 1189632
2024-11-12 14:37:54,227 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-12 14:37:54,227 [dsease_hoc.py] => Learning on 10-15
2024-11-12 15:24:12,714 [trainer.py] => model: dsease_hoc
2024-11-12 15:24:12,714 [trainer.py] => prefix:  
2024-11-12 15:24:12,714 [trainer.py] => dataset: cifar224
2024-11-12 15:24:12,715 [trainer.py] => memory_size: 0
2024-11-12 15:24:12,715 [trainer.py] => memory_per_class: 0
2024-11-12 15:24:12,715 [trainer.py] => fixed_memory: False
2024-11-12 15:24:12,715 [trainer.py] => shuffle: True
2024-11-12 15:24:12,715 [trainer.py] => init_cls: 5
2024-11-12 15:24:12,715 [trainer.py] => increment: 5
2024-11-12 15:24:12,715 [trainer.py] => model_name: dsease_hoc
2024-11-12 15:24:12,715 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 15:24:12,715 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 15:24:12,715 [trainer.py] => seed: 110
2024-11-12 15:24:12,715 [trainer.py] => wandb_log: False
2024-11-12 15:24:12,715 [trainer.py] => test_future: False
2024-11-12 15:24:12,715 [trainer.py] => lambda: 0.1
2024-11-12 15:24:12,715 [trainer.py] => mu: 10
2024-11-12 15:24:12,715 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 15:24:12,715 [trainer.py] => hoc_epochs: 5
2024-11-12 15:24:12,715 [trainer.py] => init_epochs: 3
2024-11-12 15:24:12,715 [trainer.py] => init_lr: 0.025
2024-11-12 15:24:12,715 [trainer.py] => later_epochs: 3
2024-11-12 15:24:12,715 [trainer.py] => later_lr: 0.025
2024-11-12 15:24:12,716 [trainer.py] => batch_size: 48
2024-11-12 15:24:12,716 [trainer.py] => weight_decay: 0.0005
2024-11-12 15:24:12,716 [trainer.py] => min_lr: 0
2024-11-12 15:24:12,716 [trainer.py] => optimizer: sgd
2024-11-12 15:24:12,716 [trainer.py] => scheduler: cosine
2024-11-12 15:24:12,716 [trainer.py] => pretrained: True
2024-11-12 15:24:12,716 [trainer.py] => vpt_type: Deep
2024-11-12 15:24:12,716 [trainer.py] => prompt_token_num: 5
2024-11-12 15:24:12,716 [trainer.py] => ffn_num: 64
2024-11-12 15:24:12,716 [trainer.py] => use_diagonal: False
2024-11-12 15:24:12,716 [trainer.py] => recalc_sim: True
2024-11-12 15:24:12,716 [trainer.py] => alpha: 0.1
2024-11-12 15:24:12,716 [trainer.py] => use_init_ptm: False
2024-11-12 15:24:12,716 [trainer.py] => beta: 0
2024-11-12 15:24:12,716 [trainer.py] => use_old_data: False
2024-11-12 15:24:12,716 [trainer.py] => use_reweight: False
2024-11-12 15:24:12,716 [trainer.py] => moni_adam: False
2024-11-12 15:24:12,716 [trainer.py] => adapter_num: -1
2024-11-12 15:24:14,545 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 15:24:18,353 [trainer.py] => All params: 87150351
2024-11-12 15:24:18,353 [trainer.py] => Trainable params: 1341795
2024-11-12 15:24:18,355 [dsease_hoc.py] => Total trainable params: 1341795
2024-11-12 15:24:18,355 [dsease_hoc.py] => Learning on 0-5
2024-11-12 15:25:24,175 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.738, Train_accy 94.24
2024-11-12 15:26:22,581 [dsease_hoc.py] => Junction Layer Train: Task 0, Epoch 5/5 => Loss 4.481, Train_accy 1.12
2024-11-12 15:26:27,518 [dsease_hoc.py] => Task correct: 15.0
2024-11-12 15:26:27,518 [dsease_hoc.py] => Task acc: 20.0
2024-11-12 15:26:27,552 [trainer.py] => No NME accuracy.
2024-11-12 15:26:27,552 [trainer.py] => CNN: {'total': 1.2, '00-04': 1.2, 'old': 0, 'new': 1.2}
2024-11-12 15:26:27,552 [trainer.py] => CNN top1 curve: [1.2]
2024-11-12 15:26:27,552 [trainer.py] => CNN top5 curve: [8.6]

2024-11-12 15:26:27,552 [trainer.py] => Average Accuracy (CNN): 1.2 

2024-11-12 15:26:27,553 [trainer.py] => All params: 87150351
2024-11-12 15:26:27,554 [trainer.py] => Trainable params: 1189632
2024-11-12 15:26:27,990 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 15:26:27,991 [dsease_hoc.py] => Learning on 5-10
2024-11-12 15:38:18,395 [trainer.py] => model: dsease_hoc
2024-11-12 15:38:18,395 [trainer.py] => prefix:  
2024-11-12 15:38:18,395 [trainer.py] => dataset: cifar224
2024-11-12 15:38:18,395 [trainer.py] => memory_size: 0
2024-11-12 15:38:18,396 [trainer.py] => memory_per_class: 0
2024-11-12 15:38:18,396 [trainer.py] => fixed_memory: False
2024-11-12 15:38:18,396 [trainer.py] => shuffle: True
2024-11-12 15:38:18,396 [trainer.py] => init_cls: 5
2024-11-12 15:38:18,396 [trainer.py] => increment: 5
2024-11-12 15:38:18,396 [trainer.py] => model_name: dsease_hoc
2024-11-12 15:38:18,396 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 15:38:18,396 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 15:38:18,396 [trainer.py] => seed: 110
2024-11-12 15:38:18,396 [trainer.py] => wandb_log: False
2024-11-12 15:38:18,396 [trainer.py] => test_future: False
2024-11-12 15:38:18,396 [trainer.py] => lambda: 0.1
2024-11-12 15:38:18,396 [trainer.py] => mu: 10
2024-11-12 15:38:18,396 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 15:38:18,396 [trainer.py] => hoc_epochs: 5
2024-11-12 15:38:18,396 [trainer.py] => init_epochs: 3
2024-11-12 15:38:18,396 [trainer.py] => init_lr: 0.025
2024-11-12 15:38:18,396 [trainer.py] => later_epochs: 3
2024-11-12 15:38:18,396 [trainer.py] => later_lr: 0.025
2024-11-12 15:38:18,396 [trainer.py] => batch_size: 48
2024-11-12 15:38:18,397 [trainer.py] => weight_decay: 0.0005
2024-11-12 15:38:18,397 [trainer.py] => min_lr: 0
2024-11-12 15:38:18,397 [trainer.py] => optimizer: sgd
2024-11-12 15:38:18,397 [trainer.py] => scheduler: cosine
2024-11-12 15:38:18,397 [trainer.py] => pretrained: True
2024-11-12 15:38:18,397 [trainer.py] => vpt_type: Deep
2024-11-12 15:38:18,397 [trainer.py] => prompt_token_num: 5
2024-11-12 15:38:18,397 [trainer.py] => ffn_num: 64
2024-11-12 15:38:18,397 [trainer.py] => use_diagonal: False
2024-11-12 15:38:18,397 [trainer.py] => recalc_sim: True
2024-11-12 15:38:18,397 [trainer.py] => alpha: 0.1
2024-11-12 15:38:18,397 [trainer.py] => use_init_ptm: False
2024-11-12 15:38:18,397 [trainer.py] => beta: 0
2024-11-12 15:38:18,397 [trainer.py] => use_old_data: False
2024-11-12 15:38:18,397 [trainer.py] => use_reweight: False
2024-11-12 15:38:18,397 [trainer.py] => moni_adam: False
2024-11-12 15:38:18,397 [trainer.py] => adapter_num: -1
2024-11-12 15:38:20,173 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 15:38:24,618 [trainer.py] => All params: 87150351
2024-11-12 15:38:24,619 [trainer.py] => Trainable params: 1341795
2024-11-12 15:38:24,621 [dsease_hoc.py] => Total trainable params: 1341795
2024-11-12 15:38:24,621 [dsease_hoc.py] => Learning on 0-5
2024-11-12 15:39:26,879 [trainer.py] => model: dsease_hoc
2024-11-12 15:39:26,880 [trainer.py] => prefix:  
2024-11-12 15:39:26,880 [trainer.py] => dataset: cifar224
2024-11-12 15:39:26,880 [trainer.py] => memory_size: 0
2024-11-12 15:39:26,880 [trainer.py] => memory_per_class: 0
2024-11-12 15:39:26,880 [trainer.py] => fixed_memory: False
2024-11-12 15:39:26,880 [trainer.py] => shuffle: True
2024-11-12 15:39:26,880 [trainer.py] => init_cls: 5
2024-11-12 15:39:26,880 [trainer.py] => increment: 5
2024-11-12 15:39:26,880 [trainer.py] => model_name: dsease_hoc
2024-11-12 15:39:26,880 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 15:39:26,880 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 15:39:26,880 [trainer.py] => seed: 110
2024-11-12 15:39:26,880 [trainer.py] => wandb_log: False
2024-11-12 15:39:26,880 [trainer.py] => test_future: False
2024-11-12 15:39:26,880 [trainer.py] => lambda: 0.1
2024-11-12 15:39:26,880 [trainer.py] => mu: 10
2024-11-12 15:39:26,880 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 15:39:26,880 [trainer.py] => hoc_epochs: 5
2024-11-12 15:39:26,880 [trainer.py] => init_epochs: 3
2024-11-12 15:39:26,880 [trainer.py] => init_lr: 0.025
2024-11-12 15:39:26,881 [trainer.py] => later_epochs: 3
2024-11-12 15:39:26,881 [trainer.py] => later_lr: 0.025
2024-11-12 15:39:26,881 [trainer.py] => batch_size: 48
2024-11-12 15:39:26,881 [trainer.py] => weight_decay: 0.0005
2024-11-12 15:39:26,881 [trainer.py] => min_lr: 0
2024-11-12 15:39:26,881 [trainer.py] => optimizer: sgd
2024-11-12 15:39:26,881 [trainer.py] => scheduler: cosine
2024-11-12 15:39:26,881 [trainer.py] => pretrained: True
2024-11-12 15:39:26,881 [trainer.py] => vpt_type: Deep
2024-11-12 15:39:26,881 [trainer.py] => prompt_token_num: 5
2024-11-12 15:39:26,881 [trainer.py] => ffn_num: 64
2024-11-12 15:39:26,881 [trainer.py] => use_diagonal: False
2024-11-12 15:39:26,881 [trainer.py] => recalc_sim: True
2024-11-12 15:39:26,881 [trainer.py] => alpha: 0.1
2024-11-12 15:39:26,881 [trainer.py] => use_init_ptm: False
2024-11-12 15:39:26,881 [trainer.py] => beta: 0
2024-11-12 15:39:26,881 [trainer.py] => use_old_data: False
2024-11-12 15:39:26,881 [trainer.py] => use_reweight: False
2024-11-12 15:39:26,881 [trainer.py] => moni_adam: False
2024-11-12 15:39:26,881 [trainer.py] => adapter_num: -1
2024-11-12 15:39:28,728 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 15:39:33,221 [trainer.py] => All params: 87150351
2024-11-12 15:39:33,222 [trainer.py] => Trainable params: 1341795
2024-11-12 15:39:33,224 [dsease_hoc.py] => Total trainable params: 1341795
2024-11-12 15:39:33,224 [dsease_hoc.py] => Learning on 0-5
2024-11-12 15:40:39,471 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.738, Train_accy 94.24
2024-11-12 15:41:38,081 [dsease_hoc.py] => Junction Layer Train: Task 0, Epoch 5/5 => Loss 4.481, Train_accy 1.12
2024-11-12 15:41:42,902 [dsease_hoc.py] => Task correct: 15.0
2024-11-12 15:41:42,903 [dsease_hoc.py] => Task acc: 20.0
2024-11-12 15:41:42,945 [trainer.py] => No NME accuracy.
2024-11-12 15:41:42,946 [trainer.py] => CNN: {'total': 1.2, '00-04': 1.2, 'old': 0, 'new': 1.2}
2024-11-12 15:41:42,946 [trainer.py] => CNN top1 curve: [1.2]
2024-11-12 15:41:42,946 [trainer.py] => CNN top5 curve: [8.6]

2024-11-12 15:41:42,946 [trainer.py] => Average Accuracy (CNN): 1.2 

2024-11-12 15:41:42,947 [trainer.py] => All params: 87150351
2024-11-12 15:41:42,949 [trainer.py] => Trainable params: 1189632
2024-11-12 15:41:43,227 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 15:41:43,227 [dsease_hoc.py] => Learning on 5-10
2024-11-12 15:42:50,282 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.292, Train_accy 91.16
2024-11-12 15:45:37,859 [dsease_hoc.py] => Junction Layer Train: Task 1, Epoch 5/5 => Loss 2.857, Train_accy 0.32
2024-11-12 15:45:49,550 [dsease_hoc.py] => Task correct: 10.7
2024-11-12 15:45:49,550 [dsease_hoc.py] => Task acc: 23.0
2024-11-12 15:45:49,587 [trainer.py] => No NME accuracy.
2024-11-12 15:45:49,588 [trainer.py] => CNN: {'total': 1.4, '00-04': 2.6, '05-09': 0.2, 'old': 2.6, 'new': 0.2}
2024-11-12 15:45:49,588 [trainer.py] => CNN top1 curve: [1.2, 1.4]
2024-11-12 15:45:49,588 [trainer.py] => CNN top5 curve: [8.6, 8.9]

2024-11-12 15:45:49,588 [trainer.py] => Average Accuracy (CNN): 1.2999999999999998 

2024-11-12 15:45:49,589 [trainer.py] => All params: 87226383
2024-11-12 15:45:49,589 [trainer.py] => Trainable params: 1189632
2024-11-12 15:45:49,900 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-12 15:45:49,900 [dsease_hoc.py] => Learning on 10-15
2024-11-12 16:30:29,872 [trainer.py] => model: dsease_hoc
2024-11-12 16:30:29,872 [trainer.py] => prefix:  
2024-11-12 16:30:29,872 [trainer.py] => dataset: cifar224
2024-11-12 16:30:29,872 [trainer.py] => memory_size: 0
2024-11-12 16:30:29,873 [trainer.py] => memory_per_class: 0
2024-11-12 16:30:29,873 [trainer.py] => fixed_memory: False
2024-11-12 16:30:29,873 [trainer.py] => shuffle: True
2024-11-12 16:30:29,873 [trainer.py] => init_cls: 5
2024-11-12 16:30:29,873 [trainer.py] => increment: 5
2024-11-12 16:30:29,873 [trainer.py] => model_name: dsease_hoc
2024-11-12 16:30:29,873 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 16:30:29,873 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 16:30:29,873 [trainer.py] => seed: 110
2024-11-12 16:30:29,874 [trainer.py] => wandb_log: False
2024-11-12 16:30:29,874 [trainer.py] => test_future: False
2024-11-12 16:30:29,874 [trainer.py] => lambda: 0.1
2024-11-12 16:30:29,874 [trainer.py] => mu: 10
2024-11-12 16:30:29,874 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 16:30:29,874 [trainer.py] => hoc_epochs: 5
2024-11-12 16:30:29,874 [trainer.py] => init_epochs: 3
2024-11-12 16:30:29,874 [trainer.py] => init_lr: 0.025
2024-11-12 16:30:29,874 [trainer.py] => later_epochs: 3
2024-11-12 16:30:29,875 [trainer.py] => later_lr: 0.025
2024-11-12 16:30:29,875 [trainer.py] => batch_size: 48
2024-11-12 16:30:29,875 [trainer.py] => weight_decay: 0.0005
2024-11-12 16:30:29,875 [trainer.py] => min_lr: 0
2024-11-12 16:30:29,875 [trainer.py] => optimizer: sgd
2024-11-12 16:30:29,875 [trainer.py] => scheduler: cosine
2024-11-12 16:30:29,875 [trainer.py] => pretrained: True
2024-11-12 16:30:29,875 [trainer.py] => vpt_type: Deep
2024-11-12 16:30:29,875 [trainer.py] => prompt_token_num: 5
2024-11-12 16:30:29,876 [trainer.py] => ffn_num: 64
2024-11-12 16:30:29,876 [trainer.py] => use_diagonal: False
2024-11-12 16:30:29,876 [trainer.py] => recalc_sim: True
2024-11-12 16:30:29,876 [trainer.py] => alpha: 0.1
2024-11-12 16:30:29,876 [trainer.py] => use_init_ptm: False
2024-11-12 16:30:29,876 [trainer.py] => beta: 0
2024-11-12 16:30:29,876 [trainer.py] => use_old_data: False
2024-11-12 16:30:29,876 [trainer.py] => use_reweight: False
2024-11-12 16:30:29,876 [trainer.py] => moni_adam: False
2024-11-12 16:30:29,876 [trainer.py] => adapter_num: -1
2024-11-12 16:30:31,844 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 16:30:37,611 [trainer.py] => All params: 87150351
2024-11-12 16:30:37,613 [trainer.py] => Trainable params: 1341795
2024-11-12 16:30:37,618 [dsease_hoc.py] => Total trainable params: 1341795
2024-11-12 16:30:37,619 [dsease_hoc.py] => Learning on 0-5
2024-11-12 16:31:44,450 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.738, Train_accy 94.24
2024-11-12 16:32:43,736 [dsease_hoc.py] => Junction Layer Train: Task 0, Epoch 5/5 => Loss 4.481, Train_accy 1.12
2024-11-12 16:32:48,939 [dsease_hoc.py] => Task correct: 15.0
2024-11-12 16:32:48,940 [dsease_hoc.py] => Task acc: 20.0
2024-11-12 16:32:48,998 [trainer.py] => No NME accuracy.
2024-11-12 16:32:48,998 [trainer.py] => CNN: {'total': 1.2, '00-04': 1.2, 'old': 0, 'new': 1.2}
2024-11-12 16:32:48,999 [trainer.py] => CNN top1 curve: [1.2]
2024-11-12 16:32:48,999 [trainer.py] => CNN top5 curve: [8.6]

2024-11-12 16:32:48,999 [trainer.py] => Average Accuracy (CNN): 1.2 

2024-11-12 16:32:49,000 [trainer.py] => All params: 87150351
2024-11-12 16:32:49,001 [trainer.py] => Trainable params: 1189632
2024-11-12 16:32:49,326 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 16:32:49,326 [dsease_hoc.py] => Learning on 5-10
2024-11-12 16:33:41,005 [trainer.py] => model: dsease_hoc
2024-11-12 16:33:41,005 [trainer.py] => prefix:  
2024-11-12 16:33:41,005 [trainer.py] => dataset: cifar224
2024-11-12 16:33:41,005 [trainer.py] => memory_size: 0
2024-11-12 16:33:41,005 [trainer.py] => memory_per_class: 0
2024-11-12 16:33:41,005 [trainer.py] => fixed_memory: False
2024-11-12 16:33:41,005 [trainer.py] => shuffle: True
2024-11-12 16:33:41,005 [trainer.py] => init_cls: 5
2024-11-12 16:33:41,005 [trainer.py] => increment: 5
2024-11-12 16:33:41,006 [trainer.py] => model_name: dsease_hoc
2024-11-12 16:33:41,006 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 16:33:41,006 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 16:33:41,006 [trainer.py] => seed: 110
2024-11-12 16:33:41,006 [trainer.py] => wandb_log: False
2024-11-12 16:33:41,006 [trainer.py] => test_future: False
2024-11-12 16:33:41,006 [trainer.py] => lambda: 0.1
2024-11-12 16:33:41,006 [trainer.py] => mu: 10
2024-11-12 16:33:41,006 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 16:33:41,006 [trainer.py] => hoc_epochs: 5
2024-11-12 16:33:41,006 [trainer.py] => init_epochs: 3
2024-11-12 16:33:41,006 [trainer.py] => init_lr: 0.025
2024-11-12 16:33:41,006 [trainer.py] => later_epochs: 3
2024-11-12 16:33:41,006 [trainer.py] => later_lr: 0.025
2024-11-12 16:33:41,006 [trainer.py] => batch_size: 48
2024-11-12 16:33:41,006 [trainer.py] => weight_decay: 0.0005
2024-11-12 16:33:41,006 [trainer.py] => min_lr: 0
2024-11-12 16:33:41,006 [trainer.py] => optimizer: sgd
2024-11-12 16:33:41,006 [trainer.py] => scheduler: cosine
2024-11-12 16:33:41,006 [trainer.py] => pretrained: True
2024-11-12 16:33:41,007 [trainer.py] => vpt_type: Deep
2024-11-12 16:33:41,007 [trainer.py] => prompt_token_num: 5
2024-11-12 16:33:41,007 [trainer.py] => ffn_num: 64
2024-11-12 16:33:41,007 [trainer.py] => use_diagonal: False
2024-11-12 16:33:41,007 [trainer.py] => recalc_sim: True
2024-11-12 16:33:41,007 [trainer.py] => alpha: 0.1
2024-11-12 16:33:41,007 [trainer.py] => use_init_ptm: False
2024-11-12 16:33:41,007 [trainer.py] => beta: 0
2024-11-12 16:33:41,007 [trainer.py] => use_old_data: False
2024-11-12 16:33:41,007 [trainer.py] => use_reweight: False
2024-11-12 16:33:41,007 [trainer.py] => moni_adam: False
2024-11-12 16:33:41,007 [trainer.py] => adapter_num: -1
2024-11-12 16:33:42,944 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 16:33:48,165 [trainer.py] => All params: 87150252
2024-11-12 16:33:48,167 [trainer.py] => Trainable params: 1341696
2024-11-12 16:33:48,170 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 16:33:48,170 [dsease_hoc.py] => Learning on 0-5
2024-11-12 16:34:56,875 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 16:35:56,910 [dsease_hoc.py] => Junction Layer Train: Task 0, Epoch 5/5 => Loss 4.618, Train_accy 2.40
2024-11-12 16:36:02,145 [dsease_hoc.py] => Task correct: 27.4
2024-11-12 16:36:02,146 [dsease_hoc.py] => Task acc: 17.6
2024-11-12 16:36:02,201 [trainer.py] => No NME accuracy.
2024-11-12 16:36:02,201 [trainer.py] => CNN: {'total': 2.2, '00-04': 2.2, 'old': 0, 'new': 2.2}
2024-11-12 16:36:02,201 [trainer.py] => CNN top1 curve: [2.2]
2024-11-12 16:36:02,202 [trainer.py] => CNN top5 curve: [8.8]

2024-11-12 16:36:02,202 [trainer.py] => Average Accuracy (CNN): 2.2 

2024-11-12 16:36:02,203 [trainer.py] => All params: 87150252
2024-11-12 16:36:02,204 [trainer.py] => Trainable params: 1189632
2024-11-12 16:36:02,522 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 16:36:02,522 [dsease_hoc.py] => Learning on 5-10
2024-11-12 16:45:07,832 [trainer.py] => model: dsease_hoc
2024-11-12 16:45:07,833 [trainer.py] => prefix:  
2024-11-12 16:45:07,833 [trainer.py] => dataset: cifar224
2024-11-12 16:45:07,833 [trainer.py] => memory_size: 0
2024-11-12 16:45:07,833 [trainer.py] => memory_per_class: 0
2024-11-12 16:45:07,833 [trainer.py] => fixed_memory: False
2024-11-12 16:45:07,833 [trainer.py] => shuffle: True
2024-11-12 16:45:07,833 [trainer.py] => init_cls: 5
2024-11-12 16:45:07,833 [trainer.py] => increment: 5
2024-11-12 16:45:07,833 [trainer.py] => model_name: dsease_hoc
2024-11-12 16:45:07,834 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 16:45:07,834 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 16:45:07,834 [trainer.py] => seed: 110
2024-11-12 16:45:07,834 [trainer.py] => wandb_log: False
2024-11-12 16:45:07,834 [trainer.py] => test_future: False
2024-11-12 16:45:07,834 [trainer.py] => lambda: 0.1
2024-11-12 16:45:07,834 [trainer.py] => mu: 10
2024-11-12 16:45:07,834 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 16:45:07,834 [trainer.py] => hoc_epochs: 5
2024-11-12 16:45:07,834 [trainer.py] => init_epochs: 3
2024-11-12 16:45:07,835 [trainer.py] => init_lr: 0.025
2024-11-12 16:45:07,835 [trainer.py] => later_epochs: 3
2024-11-12 16:45:07,835 [trainer.py] => later_lr: 0.025
2024-11-12 16:45:07,835 [trainer.py] => batch_size: 48
2024-11-12 16:45:07,835 [trainer.py] => weight_decay: 0.0005
2024-11-12 16:45:07,835 [trainer.py] => min_lr: 0
2024-11-12 16:45:07,835 [trainer.py] => optimizer: sgd
2024-11-12 16:45:07,835 [trainer.py] => scheduler: cosine
2024-11-12 16:45:07,836 [trainer.py] => pretrained: True
2024-11-12 16:45:07,836 [trainer.py] => vpt_type: Deep
2024-11-12 16:45:07,836 [trainer.py] => prompt_token_num: 5
2024-11-12 16:45:07,836 [trainer.py] => ffn_num: 64
2024-11-12 16:45:07,836 [trainer.py] => use_diagonal: False
2024-11-12 16:45:07,836 [trainer.py] => recalc_sim: True
2024-11-12 16:45:07,836 [trainer.py] => alpha: 0.1
2024-11-12 16:45:07,836 [trainer.py] => use_init_ptm: False
2024-11-12 16:45:07,836 [trainer.py] => beta: 0
2024-11-12 16:45:07,836 [trainer.py] => use_old_data: False
2024-11-12 16:45:07,837 [trainer.py] => use_reweight: False
2024-11-12 16:45:07,837 [trainer.py] => moni_adam: False
2024-11-12 16:45:07,837 [trainer.py] => adapter_num: -1
2024-11-12 16:45:09,878 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 16:45:14,802 [trainer.py] => All params: 87150252
2024-11-12 16:45:14,803 [trainer.py] => Trainable params: 1341696
2024-11-12 16:45:14,805 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 16:45:14,805 [dsease_hoc.py] => Learning on 0-5
2024-11-12 17:09:41,008 [trainer.py] => model: dsease_hoc
2024-11-12 17:09:41,008 [trainer.py] => prefix:  
2024-11-12 17:09:41,008 [trainer.py] => dataset: cifar224
2024-11-12 17:09:41,008 [trainer.py] => memory_size: 0
2024-11-12 17:09:41,009 [trainer.py] => memory_per_class: 0
2024-11-12 17:09:41,009 [trainer.py] => fixed_memory: False
2024-11-12 17:09:41,009 [trainer.py] => shuffle: True
2024-11-12 17:09:41,009 [trainer.py] => init_cls: 5
2024-11-12 17:09:41,009 [trainer.py] => increment: 5
2024-11-12 17:09:41,009 [trainer.py] => model_name: dsease_hoc
2024-11-12 17:09:41,009 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 17:09:41,009 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 17:09:41,009 [trainer.py] => seed: 110
2024-11-12 17:09:41,009 [trainer.py] => wandb_log: False
2024-11-12 17:09:41,009 [trainer.py] => test_future: False
2024-11-12 17:09:41,009 [trainer.py] => lambda: 0.1
2024-11-12 17:09:41,009 [trainer.py] => mu: 10
2024-11-12 17:09:41,009 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 17:09:41,009 [trainer.py] => hoc_epochs: 5
2024-11-12 17:09:41,009 [trainer.py] => init_epochs: 3
2024-11-12 17:09:41,009 [trainer.py] => init_lr: 0.025
2024-11-12 17:09:41,009 [trainer.py] => later_epochs: 3
2024-11-12 17:09:41,009 [trainer.py] => later_lr: 0.025
2024-11-12 17:09:41,009 [trainer.py] => batch_size: 48
2024-11-12 17:09:41,009 [trainer.py] => weight_decay: 0.0005
2024-11-12 17:09:41,010 [trainer.py] => min_lr: 0
2024-11-12 17:09:41,010 [trainer.py] => optimizer: sgd
2024-11-12 17:09:41,010 [trainer.py] => scheduler: cosine
2024-11-12 17:09:41,010 [trainer.py] => pretrained: True
2024-11-12 17:09:41,010 [trainer.py] => vpt_type: Deep
2024-11-12 17:09:41,010 [trainer.py] => prompt_token_num: 5
2024-11-12 17:09:41,010 [trainer.py] => ffn_num: 64
2024-11-12 17:09:41,010 [trainer.py] => use_diagonal: False
2024-11-12 17:09:41,010 [trainer.py] => recalc_sim: True
2024-11-12 17:09:41,010 [trainer.py] => alpha: 0.1
2024-11-12 17:09:41,010 [trainer.py] => use_init_ptm: False
2024-11-12 17:09:41,010 [trainer.py] => beta: 0
2024-11-12 17:09:41,010 [trainer.py] => use_old_data: False
2024-11-12 17:09:41,010 [trainer.py] => use_reweight: False
2024-11-12 17:09:41,010 [trainer.py] => moni_adam: False
2024-11-12 17:09:41,010 [trainer.py] => adapter_num: -1
2024-11-12 17:09:42,741 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 17:09:46,943 [trainer.py] => All params: 87150252
2024-11-12 17:09:46,944 [trainer.py] => Trainable params: 1341696
2024-11-12 17:10:14,496 [trainer.py] => model: dsease_hoc
2024-11-12 17:10:14,496 [trainer.py] => prefix:  
2024-11-12 17:10:14,496 [trainer.py] => dataset: cifar224
2024-11-12 17:10:14,496 [trainer.py] => memory_size: 0
2024-11-12 17:10:14,496 [trainer.py] => memory_per_class: 0
2024-11-12 17:10:14,496 [trainer.py] => fixed_memory: False
2024-11-12 17:10:14,496 [trainer.py] => shuffle: True
2024-11-12 17:10:14,497 [trainer.py] => init_cls: 5
2024-11-12 17:10:14,497 [trainer.py] => increment: 5
2024-11-12 17:10:14,497 [trainer.py] => model_name: dsease_hoc
2024-11-12 17:10:14,497 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 17:10:14,497 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 17:10:14,497 [trainer.py] => seed: 110
2024-11-12 17:10:14,497 [trainer.py] => wandb_log: False
2024-11-12 17:10:14,497 [trainer.py] => test_future: False
2024-11-12 17:10:14,497 [trainer.py] => lambda: 0.1
2024-11-12 17:10:14,497 [trainer.py] => mu: 10
2024-11-12 17:10:14,497 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 17:10:14,497 [trainer.py] => hoc_epochs: 5
2024-11-12 17:10:14,498 [trainer.py] => init_epochs: 3
2024-11-12 17:10:14,498 [trainer.py] => init_lr: 0.025
2024-11-12 17:10:14,498 [trainer.py] => later_epochs: 3
2024-11-12 17:10:14,498 [trainer.py] => later_lr: 0.025
2024-11-12 17:10:14,498 [trainer.py] => batch_size: 48
2024-11-12 17:10:14,498 [trainer.py] => weight_decay: 0.0005
2024-11-12 17:10:14,498 [trainer.py] => min_lr: 0
2024-11-12 17:10:14,498 [trainer.py] => optimizer: sgd
2024-11-12 17:10:14,498 [trainer.py] => scheduler: cosine
2024-11-12 17:10:14,498 [trainer.py] => pretrained: True
2024-11-12 17:10:14,498 [trainer.py] => vpt_type: Deep
2024-11-12 17:10:14,498 [trainer.py] => prompt_token_num: 5
2024-11-12 17:10:14,499 [trainer.py] => ffn_num: 64
2024-11-12 17:10:14,499 [trainer.py] => use_diagonal: False
2024-11-12 17:10:14,499 [trainer.py] => recalc_sim: True
2024-11-12 17:10:14,499 [trainer.py] => alpha: 0.1
2024-11-12 17:10:14,499 [trainer.py] => use_init_ptm: False
2024-11-12 17:10:14,499 [trainer.py] => beta: 0
2024-11-12 17:10:14,499 [trainer.py] => use_old_data: False
2024-11-12 17:10:14,499 [trainer.py] => use_reweight: False
2024-11-12 17:10:14,499 [trainer.py] => moni_adam: False
2024-11-12 17:10:14,499 [trainer.py] => adapter_num: -1
2024-11-12 17:10:16,350 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 17:10:20,432 [trainer.py] => All params: 87150252
2024-11-12 17:10:20,433 [trainer.py] => Trainable params: 1341696
2024-11-12 17:10:20,435 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 17:10:20,435 [dsease_hoc.py] => Learning on 0-5
2024-11-12 17:11:26,929 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.405, Train_accy 95.12
2024-11-12 17:12:07,578 [trainer.py] => model: dsease_hoc
2024-11-12 17:12:07,578 [trainer.py] => prefix:  
2024-11-12 17:12:07,579 [trainer.py] => dataset: cifar224
2024-11-12 17:12:07,579 [trainer.py] => memory_size: 0
2024-11-12 17:12:07,579 [trainer.py] => memory_per_class: 0
2024-11-12 17:12:07,579 [trainer.py] => fixed_memory: False
2024-11-12 17:12:07,579 [trainer.py] => shuffle: True
2024-11-12 17:12:07,579 [trainer.py] => init_cls: 5
2024-11-12 17:12:07,579 [trainer.py] => increment: 5
2024-11-12 17:12:07,579 [trainer.py] => model_name: dsease_hoc
2024-11-12 17:12:07,579 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 17:12:07,579 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 17:12:07,579 [trainer.py] => seed: 110
2024-11-12 17:12:07,579 [trainer.py] => wandb_log: False
2024-11-12 17:12:07,579 [trainer.py] => test_future: False
2024-11-12 17:12:07,579 [trainer.py] => lambda: 0.1
2024-11-12 17:12:07,579 [trainer.py] => mu: 10
2024-11-12 17:12:07,579 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 17:12:07,579 [trainer.py] => hoc_epochs: 5
2024-11-12 17:12:07,579 [trainer.py] => init_epochs: 3
2024-11-12 17:12:07,579 [trainer.py] => init_lr: 0.025
2024-11-12 17:12:07,580 [trainer.py] => later_epochs: 3
2024-11-12 17:12:07,580 [trainer.py] => later_lr: 0.025
2024-11-12 17:12:07,580 [trainer.py] => batch_size: 48
2024-11-12 17:12:07,580 [trainer.py] => weight_decay: 0.0005
2024-11-12 17:12:07,580 [trainer.py] => min_lr: 0
2024-11-12 17:12:07,580 [trainer.py] => optimizer: sgd
2024-11-12 17:12:07,580 [trainer.py] => scheduler: cosine
2024-11-12 17:12:07,580 [trainer.py] => pretrained: True
2024-11-12 17:12:07,580 [trainer.py] => vpt_type: Deep
2024-11-12 17:12:07,580 [trainer.py] => prompt_token_num: 5
2024-11-12 17:12:07,580 [trainer.py] => ffn_num: 64
2024-11-12 17:12:07,580 [trainer.py] => use_diagonal: False
2024-11-12 17:12:07,580 [trainer.py] => recalc_sim: True
2024-11-12 17:12:07,580 [trainer.py] => alpha: 0.1
2024-11-12 17:12:07,580 [trainer.py] => use_init_ptm: False
2024-11-12 17:12:07,580 [trainer.py] => beta: 0
2024-11-12 17:12:07,580 [trainer.py] => use_old_data: False
2024-11-12 17:12:07,580 [trainer.py] => use_reweight: False
2024-11-12 17:12:07,580 [trainer.py] => moni_adam: False
2024-11-12 17:12:07,580 [trainer.py] => adapter_num: -1
2024-11-12 17:12:09,410 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 17:12:13,625 [trainer.py] => All params: 87150252
2024-11-12 17:12:13,626 [trainer.py] => Trainable params: 1341696
2024-11-12 17:12:13,628 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 17:12:13,628 [dsease_hoc.py] => Learning on 0-5
2024-11-12 17:13:20,639 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.405, Train_accy 95.12
2024-11-12 17:13:25,591 [dsease_hoc.py] => Task correct: 7.6
2024-11-12 17:13:25,592 [dsease_hoc.py] => Task acc: 20.2
2024-11-12 17:13:25,637 [trainer.py] => No NME accuracy.
2024-11-12 17:13:25,637 [trainer.py] => CNN: {'total': 0.2, '00-04': 0.2, 'old': 0, 'new': 0.2}
2024-11-12 17:13:25,637 [trainer.py] => CNN top1 curve: [0.2]
2024-11-12 17:13:25,637 [trainer.py] => CNN top5 curve: [3.2]

2024-11-12 17:13:25,637 [trainer.py] => Average Accuracy (CNN): 0.2 

2024-11-12 17:13:25,639 [trainer.py] => All params: 87150252
2024-11-12 17:13:25,640 [trainer.py] => Trainable params: 1189632
2024-11-12 17:13:25,903 [dsease_hoc.py] => Total trainable params: 1189632
2024-11-12 17:13:25,903 [dsease_hoc.py] => Learning on 5-10
2024-11-12 17:14:33,179 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 1.672, Train_accy 19.44
2024-11-12 17:16:50,844 [trainer.py] => model: dsease_hoc
2024-11-12 17:16:50,844 [trainer.py] => prefix:  
2024-11-12 17:16:50,844 [trainer.py] => dataset: cifar224
2024-11-12 17:16:50,844 [trainer.py] => memory_size: 0
2024-11-12 17:16:50,844 [trainer.py] => memory_per_class: 0
2024-11-12 17:16:50,844 [trainer.py] => fixed_memory: False
2024-11-12 17:16:50,844 [trainer.py] => shuffle: True
2024-11-12 17:16:50,844 [trainer.py] => init_cls: 5
2024-11-12 17:16:50,844 [trainer.py] => increment: 5
2024-11-12 17:16:50,844 [trainer.py] => model_name: dsease_hoc
2024-11-12 17:16:50,845 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 17:16:50,845 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 17:16:50,845 [trainer.py] => seed: 110
2024-11-12 17:16:50,845 [trainer.py] => wandb_log: False
2024-11-12 17:16:50,845 [trainer.py] => test_future: False
2024-11-12 17:16:50,845 [trainer.py] => lambda: 0.1
2024-11-12 17:16:50,845 [trainer.py] => mu: 10
2024-11-12 17:16:50,845 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 17:16:50,845 [trainer.py] => hoc_epochs: 5
2024-11-12 17:16:50,845 [trainer.py] => init_epochs: 3
2024-11-12 17:16:50,845 [trainer.py] => init_lr: 0.025
2024-11-12 17:16:50,845 [trainer.py] => later_epochs: 3
2024-11-12 17:16:50,845 [trainer.py] => later_lr: 0.025
2024-11-12 17:16:50,845 [trainer.py] => batch_size: 48
2024-11-12 17:16:50,845 [trainer.py] => weight_decay: 0.0005
2024-11-12 17:16:50,845 [trainer.py] => min_lr: 0
2024-11-12 17:16:50,845 [trainer.py] => optimizer: sgd
2024-11-12 17:16:50,845 [trainer.py] => scheduler: cosine
2024-11-12 17:16:50,845 [trainer.py] => pretrained: True
2024-11-12 17:16:50,845 [trainer.py] => vpt_type: Deep
2024-11-12 17:16:50,845 [trainer.py] => prompt_token_num: 5
2024-11-12 17:16:50,846 [trainer.py] => ffn_num: 64
2024-11-12 17:16:50,846 [trainer.py] => use_diagonal: False
2024-11-12 17:16:50,846 [trainer.py] => recalc_sim: True
2024-11-12 17:16:50,846 [trainer.py] => alpha: 0.1
2024-11-12 17:16:50,846 [trainer.py] => use_init_ptm: False
2024-11-12 17:16:50,846 [trainer.py] => beta: 0
2024-11-12 17:16:50,846 [trainer.py] => use_old_data: False
2024-11-12 17:16:50,846 [trainer.py] => use_reweight: False
2024-11-12 17:16:50,846 [trainer.py] => moni_adam: False
2024-11-12 17:16:50,846 [trainer.py] => adapter_num: -1
2024-11-12 17:16:52,699 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 17:16:56,500 [trainer.py] => All params: 87150252
2024-11-12 17:16:56,501 [trainer.py] => Trainable params: 1341696
2024-11-12 17:16:56,502 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 17:16:56,502 [dsease_hoc.py] => Learning on 0-5
2024-11-12 17:18:03,809 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.405, Train_accy 95.12
2024-11-12 17:18:08,860 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 17:18:08,860 [dsease_hoc.py] => Task acc: 99.2
2024-11-12 17:18:08,915 [trainer.py] => No NME accuracy.
2024-11-12 17:18:08,915 [trainer.py] => CNN: {'total': 99.2, '00-04': 99.2, 'old': 0, 'new': 99.2}
2024-11-12 17:18:08,915 [trainer.py] => CNN top1 curve: [99.2]
2024-11-12 17:18:08,915 [trainer.py] => CNN top5 curve: [99.8]

2024-11-12 17:18:08,916 [trainer.py] => Average Accuracy (CNN): 99.2 

2024-11-12 17:18:08,917 [trainer.py] => All params: 87150252
2024-11-12 17:18:08,918 [trainer.py] => Trainable params: 1189632
2024-11-12 17:18:09,224 [dsease_hoc.py] => Total trainable params: 1189632
2024-11-12 17:18:09,224 [dsease_hoc.py] => Learning on 5-10
2024-11-12 17:19:16,833 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.336, Train_accy 90.20
2024-11-12 17:21:58,391 [trainer.py] => model: dsease_hoc
2024-11-12 17:21:58,391 [trainer.py] => prefix:  
2024-11-12 17:21:58,392 [trainer.py] => dataset: cifar224
2024-11-12 17:21:58,392 [trainer.py] => memory_size: 0
2024-11-12 17:21:58,392 [trainer.py] => memory_per_class: 0
2024-11-12 17:21:58,392 [trainer.py] => fixed_memory: False
2024-11-12 17:21:58,392 [trainer.py] => shuffle: True
2024-11-12 17:21:58,392 [trainer.py] => init_cls: 5
2024-11-12 17:21:58,392 [trainer.py] => increment: 5
2024-11-12 17:21:58,392 [trainer.py] => model_name: dsease_hoc
2024-11-12 17:21:58,392 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 17:21:58,392 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 17:21:58,392 [trainer.py] => seed: 110
2024-11-12 17:21:58,392 [trainer.py] => wandb_log: False
2024-11-12 17:21:58,392 [trainer.py] => test_future: False
2024-11-12 17:21:58,392 [trainer.py] => lambda: 0.1
2024-11-12 17:21:58,392 [trainer.py] => mu: 10
2024-11-12 17:21:58,392 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 17:21:58,392 [trainer.py] => hoc_epochs: 5
2024-11-12 17:21:58,392 [trainer.py] => init_epochs: 3
2024-11-12 17:21:58,392 [trainer.py] => init_lr: 0.025
2024-11-12 17:21:58,393 [trainer.py] => later_epochs: 3
2024-11-12 17:21:58,393 [trainer.py] => later_lr: 0.025
2024-11-12 17:21:58,393 [trainer.py] => batch_size: 48
2024-11-12 17:21:58,393 [trainer.py] => weight_decay: 0.0005
2024-11-12 17:21:58,393 [trainer.py] => min_lr: 0
2024-11-12 17:21:58,393 [trainer.py] => optimizer: sgd
2024-11-12 17:21:58,393 [trainer.py] => scheduler: cosine
2024-11-12 17:21:58,393 [trainer.py] => pretrained: True
2024-11-12 17:21:58,393 [trainer.py] => vpt_type: Deep
2024-11-12 17:21:58,393 [trainer.py] => prompt_token_num: 5
2024-11-12 17:21:58,393 [trainer.py] => ffn_num: 64
2024-11-12 17:21:58,393 [trainer.py] => use_diagonal: False
2024-11-12 17:21:58,393 [trainer.py] => recalc_sim: True
2024-11-12 17:21:58,393 [trainer.py] => alpha: 0.1
2024-11-12 17:21:58,393 [trainer.py] => use_init_ptm: False
2024-11-12 17:21:58,393 [trainer.py] => beta: 0
2024-11-12 17:21:58,393 [trainer.py] => use_old_data: False
2024-11-12 17:21:58,393 [trainer.py] => use_reweight: False
2024-11-12 17:21:58,393 [trainer.py] => moni_adam: False
2024-11-12 17:21:58,393 [trainer.py] => adapter_num: -1
2024-11-12 17:22:00,094 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 17:22:04,128 [trainer.py] => All params: 87150252
2024-11-12 17:22:04,128 [trainer.py] => Trainable params: 1341696
2024-11-12 17:22:04,130 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 17:22:04,130 [dsease_hoc.py] => Learning on 0-5
2024-11-12 17:23:11,307 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 17:23:16,254 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 17:23:16,254 [dsease_hoc.py] => Task acc: 98.8
2024-11-12 17:23:16,298 [trainer.py] => No NME accuracy.
2024-11-12 17:23:16,298 [trainer.py] => CNN: {'total': 98.8, '00-04': 98.8, 'old': 0, 'new': 98.8}
2024-11-12 17:23:16,299 [trainer.py] => CNN top1 curve: [98.8]
2024-11-12 17:23:16,299 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 17:23:16,299 [trainer.py] => Average Accuracy (CNN): 98.8 

2024-11-12 17:23:16,300 [trainer.py] => All params: 87150252
2024-11-12 17:23:16,301 [trainer.py] => Trainable params: 1189632
2024-11-12 17:23:16,608 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 17:23:16,608 [dsease_hoc.py] => Learning on 5-10
2024-11-12 17:24:24,348 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.351, Train_accy 89.40
2024-11-12 17:29:09,776 [trainer.py] => model: dsease_hoc
2024-11-12 17:29:09,776 [trainer.py] => prefix:  
2024-11-12 17:29:09,776 [trainer.py] => dataset: cifar224
2024-11-12 17:29:09,776 [trainer.py] => memory_size: 0
2024-11-12 17:29:09,777 [trainer.py] => memory_per_class: 0
2024-11-12 17:29:09,777 [trainer.py] => fixed_memory: False
2024-11-12 17:29:09,777 [trainer.py] => shuffle: True
2024-11-12 17:29:09,777 [trainer.py] => init_cls: 5
2024-11-12 17:29:09,777 [trainer.py] => increment: 5
2024-11-12 17:29:09,777 [trainer.py] => model_name: dsease_hoc
2024-11-12 17:29:09,777 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 17:29:09,777 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 17:29:09,777 [trainer.py] => seed: 110
2024-11-12 17:29:09,777 [trainer.py] => wandb_log: False
2024-11-12 17:29:09,777 [trainer.py] => test_future: False
2024-11-12 17:29:09,777 [trainer.py] => lambda: 0.1
2024-11-12 17:29:09,778 [trainer.py] => mu: 10
2024-11-12 17:29:09,778 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 17:29:09,778 [trainer.py] => hoc_epochs: 5
2024-11-12 17:29:09,778 [trainer.py] => init_epochs: 3
2024-11-12 17:29:09,778 [trainer.py] => init_lr: 0.025
2024-11-12 17:29:09,778 [trainer.py] => later_epochs: 3
2024-11-12 17:29:09,778 [trainer.py] => later_lr: 0.025
2024-11-12 17:29:09,778 [trainer.py] => batch_size: 48
2024-11-12 17:29:09,778 [trainer.py] => weight_decay: 0.0005
2024-11-12 17:29:09,778 [trainer.py] => min_lr: 0
2024-11-12 17:29:09,778 [trainer.py] => optimizer: sgd
2024-11-12 17:29:09,778 [trainer.py] => scheduler: cosine
2024-11-12 17:29:09,778 [trainer.py] => pretrained: True
2024-11-12 17:29:09,779 [trainer.py] => vpt_type: Deep
2024-11-12 17:29:09,779 [trainer.py] => prompt_token_num: 5
2024-11-12 17:29:09,779 [trainer.py] => ffn_num: 64
2024-11-12 17:29:09,779 [trainer.py] => use_diagonal: False
2024-11-12 17:29:09,779 [trainer.py] => recalc_sim: True
2024-11-12 17:29:09,779 [trainer.py] => alpha: 0.1
2024-11-12 17:29:09,779 [trainer.py] => use_init_ptm: False
2024-11-12 17:29:09,779 [trainer.py] => beta: 0
2024-11-12 17:29:09,779 [trainer.py] => use_old_data: False
2024-11-12 17:29:09,779 [trainer.py] => use_reweight: False
2024-11-12 17:29:09,779 [trainer.py] => moni_adam: False
2024-11-12 17:29:09,779 [trainer.py] => adapter_num: -1
2024-11-12 17:29:11,561 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 17:29:16,431 [trainer.py] => All params: 87150252
2024-11-12 17:29:16,432 [trainer.py] => Trainable params: 1341696
2024-11-12 17:29:16,433 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 17:29:16,433 [dsease_hoc.py] => Learning on 0-5
2024-11-12 17:30:23,282 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 17:30:28,222 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 17:30:28,222 [dsease_hoc.py] => Task acc: 98.8
2024-11-12 17:30:28,250 [trainer.py] => No NME accuracy.
2024-11-12 17:30:28,250 [trainer.py] => CNN: {'total': 98.8, '00-04': 98.8, 'old': 0, 'new': 98.8}
2024-11-12 17:30:28,250 [trainer.py] => CNN top1 curve: [98.8]
2024-11-12 17:30:28,250 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 17:30:28,250 [trainer.py] => Average Accuracy (CNN): 98.8 

2024-11-12 17:30:28,251 [trainer.py] => All params: 87150252
2024-11-12 17:30:28,252 [trainer.py] => Trainable params: 1189632
2024-11-12 17:30:28,527 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 17:30:28,527 [dsease_hoc.py] => Learning on 5-10
2024-11-12 17:31:36,250 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.351, Train_accy 89.40
2024-11-12 17:31:47,955 [dsease_hoc.py] => Task correct: 0.0
2024-11-12 17:31:47,955 [dsease_hoc.py] => Task acc: 21.0
2024-11-12 17:31:47,998 [trainer.py] => No NME accuracy.
2024-11-12 17:31:47,998 [trainer.py] => CNN: {'total': 0.0, '00-04': 0.0, '05-09': 0.0, 'old': 0.0, 'new': 0.0}
2024-11-12 17:31:47,998 [trainer.py] => CNN top1 curve: [98.8, 0.0]
2024-11-12 17:31:47,998 [trainer.py] => CNN top5 curve: [100.0, 0.4]

2024-11-12 17:31:47,998 [trainer.py] => Average Accuracy (CNN): 49.4 

2024-11-12 17:31:47,999 [trainer.py] => All params: 87226284
2024-11-12 17:31:48,001 [trainer.py] => Trainable params: 1189632
2024-11-12 17:31:48,316 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-12 17:31:48,316 [dsease_hoc.py] => Learning on 10-15
2024-11-12 17:52:16,791 [trainer.py] => model: dsease_hoc
2024-11-12 17:52:16,791 [trainer.py] => prefix:  
2024-11-12 17:52:16,791 [trainer.py] => dataset: cifar224
2024-11-12 17:52:16,791 [trainer.py] => memory_size: 0
2024-11-12 17:52:16,791 [trainer.py] => memory_per_class: 0
2024-11-12 17:52:16,791 [trainer.py] => fixed_memory: False
2024-11-12 17:52:16,791 [trainer.py] => shuffle: True
2024-11-12 17:52:16,791 [trainer.py] => init_cls: 5
2024-11-12 17:52:16,791 [trainer.py] => increment: 5
2024-11-12 17:52:16,791 [trainer.py] => model_name: dsease_hoc
2024-11-12 17:52:16,791 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 17:52:16,791 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 17:52:16,791 [trainer.py] => seed: 110
2024-11-12 17:52:16,791 [trainer.py] => wandb_log: False
2024-11-12 17:52:16,791 [trainer.py] => test_future: False
2024-11-12 17:52:16,791 [trainer.py] => lambda: 0.1
2024-11-12 17:52:16,791 [trainer.py] => mu: 10
2024-11-12 17:52:16,791 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 17:52:16,792 [trainer.py] => hoc_epochs: 5
2024-11-12 17:52:16,792 [trainer.py] => init_epochs: 3
2024-11-12 17:52:16,792 [trainer.py] => init_lr: 0.025
2024-11-12 17:52:16,792 [trainer.py] => later_epochs: 3
2024-11-12 17:52:16,792 [trainer.py] => later_lr: 0.025
2024-11-12 17:52:16,792 [trainer.py] => batch_size: 48
2024-11-12 17:52:16,792 [trainer.py] => weight_decay: 0.0005
2024-11-12 17:52:16,792 [trainer.py] => min_lr: 0
2024-11-12 17:52:16,792 [trainer.py] => optimizer: sgd
2024-11-12 17:52:16,792 [trainer.py] => scheduler: cosine
2024-11-12 17:52:16,792 [trainer.py] => pretrained: True
2024-11-12 17:52:16,792 [trainer.py] => vpt_type: Deep
2024-11-12 17:52:16,792 [trainer.py] => prompt_token_num: 5
2024-11-12 17:52:16,792 [trainer.py] => ffn_num: 64
2024-11-12 17:52:16,792 [trainer.py] => use_diagonal: False
2024-11-12 17:52:16,792 [trainer.py] => recalc_sim: True
2024-11-12 17:52:16,792 [trainer.py] => alpha: 0.1
2024-11-12 17:52:16,792 [trainer.py] => use_init_ptm: False
2024-11-12 17:52:16,792 [trainer.py] => beta: 0
2024-11-12 17:52:16,792 [trainer.py] => use_old_data: False
2024-11-12 17:52:16,792 [trainer.py] => use_reweight: False
2024-11-12 17:52:16,793 [trainer.py] => moni_adam: False
2024-11-12 17:52:16,793 [trainer.py] => adapter_num: -1
2024-11-12 17:52:18,629 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 17:52:22,613 [trainer.py] => All params: 87150252
2024-11-12 17:52:22,614 [trainer.py] => Trainable params: 1341696
2024-11-12 17:52:22,616 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 17:52:22,616 [dsease_hoc.py] => Learning on 0-5
2024-11-12 17:53:29,515 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 17:53:35,443 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 17:53:35,444 [dsease_hoc.py] => Task acc: 98.8
2024-11-12 17:53:35,475 [trainer.py] => No NME accuracy.
2024-11-12 17:53:35,475 [trainer.py] => CNN: {'total': 98.8, '00-04': 98.8, 'old': 0, 'new': 98.8}
2024-11-12 17:53:35,475 [trainer.py] => CNN top1 curve: [98.8]
2024-11-12 17:53:35,475 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 17:53:35,475 [trainer.py] => Average Accuracy (CNN): 98.8 

2024-11-12 17:53:35,476 [trainer.py] => All params: 87150252
2024-11-12 17:53:35,476 [trainer.py] => Trainable params: 1189632
2024-11-12 17:53:35,769 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 17:53:35,769 [dsease_hoc.py] => Learning on 5-10
2024-11-12 17:54:43,410 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.351, Train_accy 89.40
2024-11-12 17:54:55,289 [dsease_hoc.py] => Task correct: 50.0
2024-11-12 17:54:55,290 [dsease_hoc.py] => Task acc: 86.9
2024-11-12 17:54:55,349 [trainer.py] => No NME accuracy.
2024-11-12 17:54:55,350 [trainer.py] => CNN: {'total': 49.2, '00-04': 98.4, '05-09': 0.0, 'old': 98.4, 'new': 0.0}
2024-11-12 17:54:55,350 [trainer.py] => CNN top1 curve: [98.8, 49.2]
2024-11-12 17:54:55,350 [trainer.py] => CNN top5 curve: [100.0, 57.5]

2024-11-12 17:54:55,350 [trainer.py] => Average Accuracy (CNN): 74.0 

2024-11-12 17:54:55,351 [trainer.py] => All params: 87226284
2024-11-12 17:54:55,352 [trainer.py] => Trainable params: 1189632
2024-11-12 17:54:55,713 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-12 17:54:55,713 [dsease_hoc.py] => Learning on 10-15
2024-11-12 17:56:04,072 [dsease_hoc.py] => Task 2, Epoch 3/3 => Loss 0.282, Train_accy 91.48
2024-11-12 17:56:27,356 [dsease_hoc.py] => Task correct: 33.46666666666667
2024-11-12 17:56:27,357 [dsease_hoc.py] => Task acc: 84.46666666666667
2024-11-12 17:56:27,401 [trainer.py] => No NME accuracy.
2024-11-12 17:56:27,402 [trainer.py] => CNN: {'total': 33.0, '00-04': 98.6, '05-09': 0.0, '10-14': 0.4, 'old': 49.3, 'new': 0.4}
2024-11-12 17:56:27,402 [trainer.py] => CNN top1 curve: [98.8, 49.2, 33.0]
2024-11-12 17:56:27,402 [trainer.py] => CNN top5 curve: [100.0, 57.5, 46.73]

2024-11-12 17:56:27,402 [trainer.py] => Average Accuracy (CNN): 60.333333333333336 

2024-11-12 17:56:27,403 [trainer.py] => All params: 87302316
2024-11-12 17:56:27,404 [trainer.py] => Trainable params: 1189632
2024-11-12 17:56:27,790 [dsease_hoc.py] => Total trainable params: 1493760
2024-11-12 17:56:27,790 [dsease_hoc.py] => Learning on 15-20
2024-11-12 18:13:45,043 [trainer.py] => model: dsease_hoc
2024-11-12 18:13:45,043 [trainer.py] => prefix:  
2024-11-12 18:13:45,043 [trainer.py] => dataset: cifar224
2024-11-12 18:13:45,043 [trainer.py] => memory_size: 0
2024-11-12 18:13:45,043 [trainer.py] => memory_per_class: 0
2024-11-12 18:13:45,043 [trainer.py] => fixed_memory: False
2024-11-12 18:13:45,043 [trainer.py] => shuffle: True
2024-11-12 18:13:45,043 [trainer.py] => init_cls: 5
2024-11-12 18:13:45,043 [trainer.py] => increment: 5
2024-11-12 18:13:45,043 [trainer.py] => model_name: dsease_hoc
2024-11-12 18:13:45,043 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 18:13:45,044 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 18:13:45,044 [trainer.py] => seed: 110
2024-11-12 18:13:45,044 [trainer.py] => wandb_log: False
2024-11-12 18:13:45,044 [trainer.py] => test_future: False
2024-11-12 18:13:45,044 [trainer.py] => lambda: 0.1
2024-11-12 18:13:45,044 [trainer.py] => mu: 10
2024-11-12 18:13:45,044 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 18:13:45,044 [trainer.py] => hoc_epochs: 5
2024-11-12 18:13:45,044 [trainer.py] => init_epochs: 3
2024-11-12 18:13:45,044 [trainer.py] => init_lr: 0.025
2024-11-12 18:13:45,044 [trainer.py] => later_epochs: 3
2024-11-12 18:13:45,044 [trainer.py] => later_lr: 0.025
2024-11-12 18:13:45,044 [trainer.py] => batch_size: 48
2024-11-12 18:13:45,045 [trainer.py] => weight_decay: 0.0005
2024-11-12 18:13:45,045 [trainer.py] => min_lr: 0
2024-11-12 18:13:45,045 [trainer.py] => optimizer: sgd
2024-11-12 18:13:45,045 [trainer.py] => scheduler: cosine
2024-11-12 18:13:45,045 [trainer.py] => pretrained: True
2024-11-12 18:13:45,045 [trainer.py] => vpt_type: Deep
2024-11-12 18:13:45,045 [trainer.py] => prompt_token_num: 5
2024-11-12 18:13:45,045 [trainer.py] => ffn_num: 64
2024-11-12 18:13:45,045 [trainer.py] => use_diagonal: False
2024-11-12 18:13:45,045 [trainer.py] => recalc_sim: True
2024-11-12 18:13:45,045 [trainer.py] => alpha: 0.1
2024-11-12 18:13:45,045 [trainer.py] => use_init_ptm: False
2024-11-12 18:13:45,045 [trainer.py] => beta: 0
2024-11-12 18:13:45,046 [trainer.py] => use_old_data: False
2024-11-12 18:13:45,046 [trainer.py] => use_reweight: False
2024-11-12 18:13:45,046 [trainer.py] => moni_adam: False
2024-11-12 18:13:45,046 [trainer.py] => adapter_num: -1
2024-11-12 18:13:46,886 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 18:13:51,277 [trainer.py] => All params: 87150252
2024-11-12 18:13:51,278 [trainer.py] => Trainable params: 1341696
2024-11-12 18:13:51,280 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 18:13:51,280 [dsease_hoc.py] => Learning on 0-5
2024-11-12 18:14:57,720 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 18:15:03,009 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 18:15:03,011 [dsease_hoc.py] => Task acc: 20.0
2024-11-12 18:15:03,087 [trainer.py] => No NME accuracy.
2024-11-12 18:15:03,088 [trainer.py] => CNN: {'total': 20.0, '00-04': 20.0, 'old': 0, 'new': 20.0}
2024-11-12 18:15:03,088 [trainer.py] => CNN top1 curve: [20.0]
2024-11-12 18:15:03,088 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 18:15:03,089 [trainer.py] => Average Accuracy (CNN): 20.0 

2024-11-12 18:15:03,091 [trainer.py] => All params: 87150252
2024-11-12 18:15:03,093 [trainer.py] => Trainable params: 1189632
2024-11-12 18:15:03,646 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 18:15:03,646 [dsease_hoc.py] => Learning on 5-10
2024-11-12 18:16:10,981 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.351, Train_accy 89.40
2024-11-12 18:16:22,441 [dsease_hoc.py] => Task correct: 50.0
2024-11-12 18:16:22,442 [dsease_hoc.py] => Task acc: 54.4
2024-11-12 18:16:22,487 [trainer.py] => No NME accuracy.
2024-11-12 18:16:22,487 [trainer.py] => CNN: {'total': 46.7, '00-04': 0.0, '05-09': 93.4, 'old': 0.0, 'new': 93.4}
2024-11-12 18:16:22,487 [trainer.py] => CNN top1 curve: [20.0, 46.7]
2024-11-12 18:16:22,487 [trainer.py] => CNN top5 curve: [100.0, 50.0]

2024-11-12 18:16:22,487 [trainer.py] => Average Accuracy (CNN): 33.35 

2024-11-12 18:16:22,488 [trainer.py] => All params: 87226284
2024-11-12 18:16:22,489 [trainer.py] => Trainable params: 1189632
2024-11-12 18:16:22,765 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-12 18:16:22,765 [dsease_hoc.py] => Learning on 10-15
2024-11-12 18:47:31,954 [trainer.py] => model: dsease_hoc
2024-11-12 18:47:31,954 [trainer.py] => prefix:  
2024-11-12 18:47:31,954 [trainer.py] => dataset: cifar224
2024-11-12 18:47:31,954 [trainer.py] => memory_size: 0
2024-11-12 18:47:31,954 [trainer.py] => memory_per_class: 0
2024-11-12 18:47:31,955 [trainer.py] => fixed_memory: False
2024-11-12 18:47:31,955 [trainer.py] => shuffle: True
2024-11-12 18:47:31,955 [trainer.py] => init_cls: 5
2024-11-12 18:47:31,955 [trainer.py] => increment: 5
2024-11-12 18:47:31,955 [trainer.py] => model_name: dsease_hoc
2024-11-12 18:47:31,955 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 18:47:31,955 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 18:47:31,955 [trainer.py] => seed: 110
2024-11-12 18:47:31,955 [trainer.py] => wandb_log: False
2024-11-12 18:47:31,955 [trainer.py] => test_future: False
2024-11-12 18:47:31,955 [trainer.py] => lambda: 0.1
2024-11-12 18:47:31,955 [trainer.py] => mu: 10
2024-11-12 18:47:31,956 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 18:47:31,956 [trainer.py] => hoc_epochs: 5
2024-11-12 18:47:31,956 [trainer.py] => init_epochs: 3
2024-11-12 18:47:31,956 [trainer.py] => init_lr: 0.025
2024-11-12 18:47:31,956 [trainer.py] => later_epochs: 3
2024-11-12 18:47:31,956 [trainer.py] => later_lr: 0.025
2024-11-12 18:47:31,956 [trainer.py] => batch_size: 48
2024-11-12 18:47:31,956 [trainer.py] => weight_decay: 0.0005
2024-11-12 18:47:31,956 [trainer.py] => min_lr: 0
2024-11-12 18:47:31,956 [trainer.py] => optimizer: sgd
2024-11-12 18:47:31,956 [trainer.py] => scheduler: cosine
2024-11-12 18:47:31,956 [trainer.py] => pretrained: True
2024-11-12 18:47:31,957 [trainer.py] => vpt_type: Deep
2024-11-12 18:47:31,957 [trainer.py] => prompt_token_num: 5
2024-11-12 18:47:31,957 [trainer.py] => ffn_num: 64
2024-11-12 18:47:31,957 [trainer.py] => use_diagonal: False
2024-11-12 18:47:31,957 [trainer.py] => recalc_sim: True
2024-11-12 18:47:31,957 [trainer.py] => alpha: 0.1
2024-11-12 18:47:31,957 [trainer.py] => use_init_ptm: False
2024-11-12 18:47:31,957 [trainer.py] => beta: 0
2024-11-12 18:47:31,957 [trainer.py] => use_old_data: False
2024-11-12 18:47:31,957 [trainer.py] => use_reweight: False
2024-11-12 18:47:31,957 [trainer.py] => moni_adam: False
2024-11-12 18:47:31,957 [trainer.py] => adapter_num: -1
2024-11-12 18:47:33,741 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 18:47:38,300 [trainer.py] => All params: 87150252
2024-11-12 18:47:38,300 [trainer.py] => Trainable params: 1341696
2024-11-12 18:47:38,302 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 18:47:38,302 [dsease_hoc.py] => Learning on 0-5
2024-11-12 18:48:45,185 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 18:49:44,643 [dsease_hoc.py] => Junction Layer Train: Task 0, Epoch 5/5 => Loss 0.344, Train_accy 94.64
2024-11-12 18:49:49,487 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 18:49:49,488 [dsease_hoc.py] => Task acc: 98.8
2024-11-12 18:49:49,523 [trainer.py] => No NME accuracy.
2024-11-12 18:49:49,523 [trainer.py] => CNN: {'total': 98.8, '00-04': 98.8, 'old': 0, 'new': 98.8}
2024-11-12 18:49:49,523 [trainer.py] => CNN top1 curve: [98.8]
2024-11-12 18:49:49,523 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 18:49:49,523 [trainer.py] => Average Accuracy (CNN): 98.8 

2024-11-12 18:49:49,524 [trainer.py] => All params: 87150252
2024-11-12 18:49:49,525 [trainer.py] => Trainable params: 1189632
2024-11-12 18:49:49,811 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 18:49:49,812 [dsease_hoc.py] => Learning on 5-10
2024-11-12 18:50:57,880 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.272, Train_accy 91.16
2024-11-12 18:52:41,067 [trainer.py] => model: dsease_hoc
2024-11-12 18:52:41,067 [trainer.py] => prefix:  
2024-11-12 18:52:41,068 [trainer.py] => dataset: cifar224
2024-11-12 18:52:41,068 [trainer.py] => memory_size: 0
2024-11-12 18:52:41,068 [trainer.py] => memory_per_class: 0
2024-11-12 18:52:41,068 [trainer.py] => fixed_memory: False
2024-11-12 18:52:41,068 [trainer.py] => shuffle: True
2024-11-12 18:52:41,068 [trainer.py] => init_cls: 5
2024-11-12 18:52:41,068 [trainer.py] => increment: 5
2024-11-12 18:52:41,068 [trainer.py] => model_name: dsease_hoc
2024-11-12 18:52:41,068 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 18:52:41,068 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 18:52:41,068 [trainer.py] => seed: 110
2024-11-12 18:52:41,068 [trainer.py] => wandb_log: False
2024-11-12 18:52:41,068 [trainer.py] => test_future: False
2024-11-12 18:52:41,068 [trainer.py] => lambda: 0.8
2024-11-12 18:52:41,068 [trainer.py] => mu: 10
2024-11-12 18:52:41,068 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 18:52:41,068 [trainer.py] => hoc_epochs: 5
2024-11-12 18:52:41,068 [trainer.py] => init_epochs: 3
2024-11-12 18:52:41,069 [trainer.py] => init_lr: 0.025
2024-11-12 18:52:41,069 [trainer.py] => later_epochs: 3
2024-11-12 18:52:41,069 [trainer.py] => later_lr: 0.025
2024-11-12 18:52:41,069 [trainer.py] => batch_size: 48
2024-11-12 18:52:41,069 [trainer.py] => weight_decay: 0.0005
2024-11-12 18:52:41,069 [trainer.py] => min_lr: 0
2024-11-12 18:52:41,069 [trainer.py] => optimizer: sgd
2024-11-12 18:52:41,069 [trainer.py] => scheduler: cosine
2024-11-12 18:52:41,069 [trainer.py] => pretrained: True
2024-11-12 18:52:41,069 [trainer.py] => vpt_type: Deep
2024-11-12 18:52:41,069 [trainer.py] => prompt_token_num: 5
2024-11-12 18:52:41,069 [trainer.py] => ffn_num: 64
2024-11-12 18:52:41,069 [trainer.py] => use_diagonal: False
2024-11-12 18:52:41,069 [trainer.py] => recalc_sim: True
2024-11-12 18:52:41,069 [trainer.py] => alpha: 0.1
2024-11-12 18:52:41,069 [trainer.py] => use_init_ptm: False
2024-11-12 18:52:41,069 [trainer.py] => beta: 0
2024-11-12 18:52:41,069 [trainer.py] => use_old_data: False
2024-11-12 18:52:41,069 [trainer.py] => use_reweight: False
2024-11-12 18:52:41,069 [trainer.py] => moni_adam: False
2024-11-12 18:52:41,070 [trainer.py] => adapter_num: -1
2024-11-12 18:52:42,798 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 18:52:47,232 [trainer.py] => All params: 87150252
2024-11-12 18:52:47,233 [trainer.py] => Trainable params: 1341696
2024-11-12 18:52:47,235 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 18:52:47,235 [dsease_hoc.py] => Learning on 0-5
2024-11-12 18:53:55,312 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 18:54:54,655 [dsease_hoc.py] => Junction Layer Train: Task 0, Epoch 5/5 => Loss 0.344, Train_accy 94.64
2024-11-12 18:54:59,525 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 18:54:59,525 [dsease_hoc.py] => Task acc: 98.8
2024-11-12 18:54:59,558 [trainer.py] => No NME accuracy.
2024-11-12 18:54:59,558 [trainer.py] => CNN: {'total': 98.8, '00-04': 98.8, 'old': 0, 'new': 98.8}
2024-11-12 18:54:59,558 [trainer.py] => CNN top1 curve: [98.8]
2024-11-12 18:54:59,558 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 18:54:59,558 [trainer.py] => Average Accuracy (CNN): 98.8 

2024-11-12 18:54:59,559 [trainer.py] => All params: 87150252
2024-11-12 18:54:59,559 [trainer.py] => Trainable params: 1189632
2024-11-12 18:54:59,854 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 18:54:59,854 [dsease_hoc.py] => Learning on 5-10
2024-11-12 18:56:07,513 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.272, Train_accy 91.16
2024-11-12 18:58:37,759 [trainer.py] => model: dsease_hoc
2024-11-12 18:58:37,759 [trainer.py] => prefix:  
2024-11-12 18:58:37,760 [trainer.py] => dataset: cifar224
2024-11-12 18:58:37,760 [trainer.py] => memory_size: 0
2024-11-12 18:58:37,760 [trainer.py] => memory_per_class: 0
2024-11-12 18:58:37,760 [trainer.py] => fixed_memory: False
2024-11-12 18:58:37,760 [trainer.py] => shuffle: True
2024-11-12 18:58:37,760 [trainer.py] => init_cls: 5
2024-11-12 18:58:37,760 [trainer.py] => increment: 5
2024-11-12 18:58:37,760 [trainer.py] => model_name: dsease_hoc
2024-11-12 18:58:37,760 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 18:58:37,760 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 18:58:37,760 [trainer.py] => seed: 110
2024-11-12 18:58:37,760 [trainer.py] => wandb_log: False
2024-11-12 18:58:37,760 [trainer.py] => test_future: False
2024-11-12 18:58:37,760 [trainer.py] => lambda: 0.8
2024-11-12 18:58:37,760 [trainer.py] => mu: 10
2024-11-12 18:58:37,760 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 18:58:37,760 [trainer.py] => hoc_epochs: 5
2024-11-12 18:58:37,760 [trainer.py] => init_epochs: 3
2024-11-12 18:58:37,761 [trainer.py] => init_lr: 0.025
2024-11-12 18:58:37,761 [trainer.py] => later_epochs: 3
2024-11-12 18:58:37,761 [trainer.py] => later_lr: 0.025
2024-11-12 18:58:37,761 [trainer.py] => batch_size: 48
2024-11-12 18:58:37,761 [trainer.py] => weight_decay: 0.0005
2024-11-12 18:58:37,761 [trainer.py] => min_lr: 0
2024-11-12 18:58:37,761 [trainer.py] => optimizer: sgd
2024-11-12 18:58:37,761 [trainer.py] => scheduler: cosine
2024-11-12 18:58:37,761 [trainer.py] => pretrained: True
2024-11-12 18:58:37,761 [trainer.py] => vpt_type: Deep
2024-11-12 18:58:37,761 [trainer.py] => prompt_token_num: 5
2024-11-12 18:58:37,761 [trainer.py] => ffn_num: 64
2024-11-12 18:58:37,761 [trainer.py] => use_diagonal: False
2024-11-12 18:58:37,761 [trainer.py] => recalc_sim: True
2024-11-12 18:58:37,761 [trainer.py] => alpha: 0.1
2024-11-12 18:58:37,761 [trainer.py] => use_init_ptm: False
2024-11-12 18:58:37,761 [trainer.py] => beta: 0
2024-11-12 18:58:37,761 [trainer.py] => use_old_data: False
2024-11-12 18:58:37,761 [trainer.py] => use_reweight: False
2024-11-12 18:58:37,762 [trainer.py] => moni_adam: False
2024-11-12 18:58:37,762 [trainer.py] => adapter_num: -1
2024-11-12 18:58:39,535 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 18:58:43,585 [trainer.py] => All params: 87150252
2024-11-12 18:58:43,586 [trainer.py] => Trainable params: 1341696
2024-11-12 18:58:43,587 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 18:58:43,587 [dsease_hoc.py] => Learning on 0-5
2024-11-12 18:59:51,160 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 19:00:50,457 [dsease_hoc.py] => Junction Layer Train: Task 0, Epoch 5/5 => Loss 0.344, Train_accy 94.64
2024-11-12 19:00:55,361 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 19:00:55,361 [dsease_hoc.py] => Task acc: 98.8
2024-11-12 19:00:55,393 [trainer.py] => No NME accuracy.
2024-11-12 19:00:55,394 [trainer.py] => CNN: {'total': 98.8, '00-04': 98.8, 'old': 0, 'new': 98.8}
2024-11-12 19:00:55,394 [trainer.py] => CNN top1 curve: [98.8]
2024-11-12 19:00:55,394 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 19:00:55,394 [trainer.py] => Average Accuracy (CNN): 98.8 

2024-11-12 19:00:55,395 [trainer.py] => All params: 87150252
2024-11-12 19:00:55,395 [trainer.py] => Trainable params: 1189632
2024-11-12 19:00:55,689 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 19:00:55,689 [dsease_hoc.py] => Learning on 5-10
2024-11-12 19:02:04,104 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.272, Train_accy 91.16
2024-11-12 19:22:55,369 [trainer.py] => model: dsease_hoc
2024-11-12 19:22:55,369 [trainer.py] => prefix:  
2024-11-12 19:22:55,369 [trainer.py] => dataset: cifar224
2024-11-12 19:22:55,369 [trainer.py] => memory_size: 0
2024-11-12 19:22:55,369 [trainer.py] => memory_per_class: 0
2024-11-12 19:22:55,369 [trainer.py] => fixed_memory: False
2024-11-12 19:22:55,369 [trainer.py] => shuffle: True
2024-11-12 19:22:55,369 [trainer.py] => init_cls: 5
2024-11-12 19:22:55,369 [trainer.py] => increment: 5
2024-11-12 19:22:55,370 [trainer.py] => model_name: dsease_hoc
2024-11-12 19:22:55,370 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 19:22:55,370 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 19:22:55,370 [trainer.py] => seed: 110
2024-11-12 19:22:55,370 [trainer.py] => wandb_log: False
2024-11-12 19:22:55,370 [trainer.py] => test_future: False
2024-11-12 19:22:55,370 [trainer.py] => lambda: 0.8
2024-11-12 19:22:55,370 [trainer.py] => mu: 10
2024-11-12 19:22:55,370 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 19:22:55,370 [trainer.py] => hoc_epochs: 5
2024-11-12 19:22:55,370 [trainer.py] => init_epochs: 3
2024-11-12 19:22:55,370 [trainer.py] => init_lr: 0.025
2024-11-12 19:22:55,370 [trainer.py] => later_epochs: 3
2024-11-12 19:22:55,370 [trainer.py] => later_lr: 0.025
2024-11-12 19:22:55,370 [trainer.py] => batch_size: 48
2024-11-12 19:22:55,370 [trainer.py] => weight_decay: 0.0005
2024-11-12 19:22:55,370 [trainer.py] => min_lr: 0
2024-11-12 19:22:55,370 [trainer.py] => optimizer: sgd
2024-11-12 19:22:55,370 [trainer.py] => scheduler: cosine
2024-11-12 19:22:55,370 [trainer.py] => pretrained: True
2024-11-12 19:22:55,370 [trainer.py] => vpt_type: Deep
2024-11-12 19:22:55,371 [trainer.py] => prompt_token_num: 5
2024-11-12 19:22:55,371 [trainer.py] => ffn_num: 64
2024-11-12 19:22:55,371 [trainer.py] => use_diagonal: False
2024-11-12 19:22:55,371 [trainer.py] => recalc_sim: True
2024-11-12 19:22:55,371 [trainer.py] => alpha: 0.1
2024-11-12 19:22:55,371 [trainer.py] => use_init_ptm: False
2024-11-12 19:22:55,371 [trainer.py] => beta: 0
2024-11-12 19:22:55,371 [trainer.py] => use_old_data: False
2024-11-12 19:22:55,371 [trainer.py] => use_reweight: False
2024-11-12 19:22:55,371 [trainer.py] => moni_adam: False
2024-11-12 19:22:55,371 [trainer.py] => adapter_num: -1
2024-11-12 19:22:57,059 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 19:23:01,268 [trainer.py] => All params: 87150252
2024-11-12 19:23:01,269 [trainer.py] => Trainable params: 1341696
2024-11-12 19:23:01,270 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 19:23:01,270 [dsease_hoc.py] => Learning on 0-5
2024-11-12 19:24:07,661 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 19:25:06,001 [dsease_hoc.py] => Junction Layer Train: Task 0, Epoch 5/5 => Loss 0.344, Train_accy 94.64
2024-11-12 19:25:11,033 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 19:25:11,033 [dsease_hoc.py] => Task acc: 98.8
2024-11-12 19:25:11,074 [trainer.py] => No NME accuracy.
2024-11-12 19:25:11,075 [trainer.py] => CNN: {'total': 98.8, '00-04': 98.8, 'old': 0, 'new': 98.8}
2024-11-12 19:25:11,075 [trainer.py] => CNN top1 curve: [98.8]
2024-11-12 19:25:11,075 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 19:25:11,075 [trainer.py] => Average Accuracy (CNN): 98.8 

2024-11-12 19:25:11,076 [trainer.py] => All params: 87150252
2024-11-12 19:25:11,077 [trainer.py] => Trainable params: 1189632
2024-11-12 19:25:11,359 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 19:25:11,359 [dsease_hoc.py] => Learning on 5-10
2024-11-12 19:26:18,757 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.272, Train_accy 91.16
2024-11-12 19:29:06,121 [dsease_hoc.py] => Junction Layer Train: Task 1, Epoch 5/5 => Loss 33.460, Train_accy 0.00
2024-11-12 19:29:17,974 [dsease_hoc.py] => Task correct: 50.0
2024-11-12 19:29:17,975 [dsease_hoc.py] => Task acc: 91.2
2024-11-12 19:29:18,017 [trainer.py] => No NME accuracy.
2024-11-12 19:29:18,018 [trainer.py] => CNN: {'total': 49.4, '00-04': 98.8, '05-09': 0.0, 'old': 98.8, 'new': 0.0}
2024-11-12 19:29:18,018 [trainer.py] => CNN top1 curve: [98.8, 49.4]
2024-11-12 19:29:18,018 [trainer.py] => CNN top5 curve: [100.0, 58.3]

2024-11-12 19:29:18,018 [trainer.py] => Average Accuracy (CNN): 74.1 

2024-11-12 19:29:18,019 [trainer.py] => All params: 87226284
2024-11-12 19:29:18,020 [trainer.py] => Trainable params: 1189632
2024-11-12 19:29:18,330 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-12 19:29:18,330 [dsease_hoc.py] => Learning on 10-15
2024-11-12 19:34:47,838 [trainer.py] => model: dsease_hoc
2024-11-12 19:34:47,838 [trainer.py] => prefix:  
2024-11-12 19:34:47,838 [trainer.py] => dataset: cifar224
2024-11-12 19:34:47,838 [trainer.py] => memory_size: 0
2024-11-12 19:34:47,838 [trainer.py] => memory_per_class: 0
2024-11-12 19:34:47,838 [trainer.py] => fixed_memory: False
2024-11-12 19:34:47,838 [trainer.py] => shuffle: True
2024-11-12 19:34:47,838 [trainer.py] => init_cls: 5
2024-11-12 19:34:47,838 [trainer.py] => increment: 5
2024-11-12 19:34:47,838 [trainer.py] => model_name: dsease_hoc
2024-11-12 19:34:47,838 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 19:34:47,838 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 19:34:47,839 [trainer.py] => seed: 110
2024-11-12 19:34:47,839 [trainer.py] => wandb_log: False
2024-11-12 19:34:47,839 [trainer.py] => test_future: False
2024-11-12 19:34:47,839 [trainer.py] => lambda: 0.8
2024-11-12 19:34:47,839 [trainer.py] => mu: 10
2024-11-12 19:34:47,839 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 19:34:47,839 [trainer.py] => hoc_epochs: 5
2024-11-12 19:34:47,839 [trainer.py] => init_epochs: 3
2024-11-12 19:34:47,839 [trainer.py] => init_lr: 0.025
2024-11-12 19:34:47,839 [trainer.py] => later_epochs: 3
2024-11-12 19:34:47,839 [trainer.py] => later_lr: 0.025
2024-11-12 19:34:47,839 [trainer.py] => batch_size: 48
2024-11-12 19:34:47,839 [trainer.py] => weight_decay: 0.0005
2024-11-12 19:34:47,839 [trainer.py] => min_lr: 0
2024-11-12 19:34:47,839 [trainer.py] => optimizer: sgd
2024-11-12 19:34:47,839 [trainer.py] => scheduler: cosine
2024-11-12 19:34:47,839 [trainer.py] => pretrained: True
2024-11-12 19:34:47,839 [trainer.py] => vpt_type: Deep
2024-11-12 19:34:47,839 [trainer.py] => prompt_token_num: 5
2024-11-12 19:34:47,839 [trainer.py] => ffn_num: 64
2024-11-12 19:34:47,840 [trainer.py] => use_diagonal: False
2024-11-12 19:34:47,840 [trainer.py] => recalc_sim: True
2024-11-12 19:34:47,840 [trainer.py] => alpha: 0.1
2024-11-12 19:34:47,840 [trainer.py] => use_init_ptm: False
2024-11-12 19:34:47,840 [trainer.py] => beta: 0
2024-11-12 19:34:47,840 [trainer.py] => use_old_data: False
2024-11-12 19:34:47,840 [trainer.py] => use_reweight: False
2024-11-12 19:34:47,840 [trainer.py] => moni_adam: False
2024-11-12 19:34:47,840 [trainer.py] => adapter_num: -1
2024-11-12 19:34:49,528 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 19:34:52,930 [trainer.py] => All params: 87150252
2024-11-12 19:34:52,931 [trainer.py] => Trainable params: 1341696
2024-11-12 19:34:52,932 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 19:34:52,932 [dsease_hoc.py] => Learning on 0-5
2024-11-12 19:35:59,725 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 19:36:58,030 [dsease_hoc.py] => Junction Layer Train: Task 0, Epoch 5/5 => Loss 4.618, Train_accy 2.40
2024-11-12 19:37:02,942 [dsease_hoc.py] => Task correct: 27.4
2024-11-12 19:37:02,942 [dsease_hoc.py] => Task acc: 17.6
2024-11-12 19:37:02,986 [trainer.py] => No NME accuracy.
2024-11-12 19:37:02,987 [trainer.py] => CNN: {'total': 2.2, '00-04': 2.2, 'old': 0, 'new': 2.2}
2024-11-12 19:37:02,987 [trainer.py] => CNN top1 curve: [2.2]
2024-11-12 19:37:02,987 [trainer.py] => CNN top5 curve: [8.8]

2024-11-12 19:37:02,987 [trainer.py] => Average Accuracy (CNN): 2.2 

2024-11-12 19:37:02,988 [trainer.py] => All params: 87150252
2024-11-12 19:37:02,989 [trainer.py] => Trainable params: 1189632
2024-11-12 19:37:03,291 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 19:37:03,291 [dsease_hoc.py] => Learning on 5-10
2024-11-12 19:38:51,691 [trainer.py] => model: dsease_hoc
2024-11-12 19:38:51,692 [trainer.py] => prefix:  
2024-11-12 19:38:51,692 [trainer.py] => dataset: cifar224
2024-11-12 19:38:51,692 [trainer.py] => memory_size: 0
2024-11-12 19:38:51,692 [trainer.py] => memory_per_class: 0
2024-11-12 19:38:51,692 [trainer.py] => fixed_memory: False
2024-11-12 19:38:51,692 [trainer.py] => shuffle: True
2024-11-12 19:38:51,692 [trainer.py] => init_cls: 5
2024-11-12 19:38:51,692 [trainer.py] => increment: 5
2024-11-12 19:38:51,692 [trainer.py] => model_name: dsease_hoc
2024-11-12 19:38:51,692 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 19:38:51,692 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 19:38:51,692 [trainer.py] => seed: 110
2024-11-12 19:38:51,692 [trainer.py] => wandb_log: False
2024-11-12 19:38:51,692 [trainer.py] => test_future: False
2024-11-12 19:38:51,692 [trainer.py] => lambda: 0.8
2024-11-12 19:38:51,692 [trainer.py] => mu: 10
2024-11-12 19:38:51,693 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 19:38:51,693 [trainer.py] => hoc_epochs: 5
2024-11-12 19:38:51,693 [trainer.py] => init_epochs: 3
2024-11-12 19:38:51,693 [trainer.py] => init_lr: 0.025
2024-11-12 19:38:51,693 [trainer.py] => later_epochs: 3
2024-11-12 19:38:51,693 [trainer.py] => later_lr: 0.025
2024-11-12 19:38:51,693 [trainer.py] => batch_size: 48
2024-11-12 19:38:51,693 [trainer.py] => weight_decay: 0.0005
2024-11-12 19:38:51,693 [trainer.py] => min_lr: 0
2024-11-12 19:38:51,693 [trainer.py] => optimizer: sgd
2024-11-12 19:38:51,693 [trainer.py] => scheduler: cosine
2024-11-12 19:38:51,693 [trainer.py] => pretrained: True
2024-11-12 19:38:51,693 [trainer.py] => vpt_type: Deep
2024-11-12 19:38:51,693 [trainer.py] => prompt_token_num: 5
2024-11-12 19:38:51,693 [trainer.py] => ffn_num: 64
2024-11-12 19:38:51,693 [trainer.py] => use_diagonal: False
2024-11-12 19:38:51,693 [trainer.py] => recalc_sim: True
2024-11-12 19:38:51,693 [trainer.py] => alpha: 0.1
2024-11-12 19:38:51,693 [trainer.py] => use_init_ptm: False
2024-11-12 19:38:51,693 [trainer.py] => beta: 0
2024-11-12 19:38:51,694 [trainer.py] => use_old_data: False
2024-11-12 19:38:51,694 [trainer.py] => use_reweight: False
2024-11-12 19:38:51,694 [trainer.py] => moni_adam: False
2024-11-12 19:38:51,694 [trainer.py] => adapter_num: -1
2024-11-12 19:38:53,380 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 19:38:57,575 [trainer.py] => All params: 87150252
2024-11-12 19:38:57,576 [trainer.py] => Trainable params: 1341696
2024-11-12 19:38:57,577 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 19:38:57,577 [dsease_hoc.py] => Learning on 0-5
2024-11-12 19:40:04,361 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 19:42:47,376 [trainer.py] => model: dsease_hoc
2024-11-12 19:42:47,376 [trainer.py] => prefix:  
2024-11-12 19:42:47,377 [trainer.py] => dataset: cifar224
2024-11-12 19:42:47,377 [trainer.py] => memory_size: 0
2024-11-12 19:42:47,377 [trainer.py] => memory_per_class: 0
2024-11-12 19:42:47,377 [trainer.py] => fixed_memory: False
2024-11-12 19:42:47,377 [trainer.py] => shuffle: True
2024-11-12 19:42:47,377 [trainer.py] => init_cls: 5
2024-11-12 19:42:47,377 [trainer.py] => increment: 5
2024-11-12 19:42:47,377 [trainer.py] => model_name: dsease_hoc
2024-11-12 19:42:47,377 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 19:42:47,377 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 19:42:47,377 [trainer.py] => seed: 110
2024-11-12 19:42:47,377 [trainer.py] => wandb_log: False
2024-11-12 19:42:47,377 [trainer.py] => test_future: False
2024-11-12 19:42:47,377 [trainer.py] => lambda: 0.8
2024-11-12 19:42:47,377 [trainer.py] => mu: 10
2024-11-12 19:42:47,377 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 19:42:47,377 [trainer.py] => hoc_epochs: 5
2024-11-12 19:42:47,377 [trainer.py] => init_epochs: 3
2024-11-12 19:42:47,377 [trainer.py] => init_lr: 0.025
2024-11-12 19:42:47,378 [trainer.py] => later_epochs: 3
2024-11-12 19:42:47,378 [trainer.py] => later_lr: 0.025
2024-11-12 19:42:47,378 [trainer.py] => batch_size: 48
2024-11-12 19:42:47,378 [trainer.py] => weight_decay: 0.0005
2024-11-12 19:42:47,378 [trainer.py] => min_lr: 0
2024-11-12 19:42:47,378 [trainer.py] => optimizer: sgd
2024-11-12 19:42:47,378 [trainer.py] => scheduler: cosine
2024-11-12 19:42:47,378 [trainer.py] => pretrained: True
2024-11-12 19:42:47,378 [trainer.py] => vpt_type: Deep
2024-11-12 19:42:47,378 [trainer.py] => prompt_token_num: 5
2024-11-12 19:42:47,378 [trainer.py] => ffn_num: 64
2024-11-12 19:42:47,378 [trainer.py] => use_diagonal: False
2024-11-12 19:42:47,378 [trainer.py] => recalc_sim: True
2024-11-12 19:42:47,378 [trainer.py] => alpha: 0.1
2024-11-12 19:42:47,378 [trainer.py] => use_init_ptm: False
2024-11-12 19:42:47,378 [trainer.py] => beta: 0
2024-11-12 19:42:47,378 [trainer.py] => use_old_data: False
2024-11-12 19:42:47,378 [trainer.py] => use_reweight: False
2024-11-12 19:42:47,378 [trainer.py] => moni_adam: False
2024-11-12 19:42:47,378 [trainer.py] => adapter_num: -1
2024-11-12 19:42:49,065 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 19:42:53,220 [trainer.py] => All params: 87150252
2024-11-12 19:42:53,221 [trainer.py] => Trainable params: 1341696
2024-11-12 19:42:53,223 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 19:42:53,223 [dsease_hoc.py] => Learning on 0-5
2024-11-12 19:44:00,163 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 19:44:58,669 [dsease_hoc.py] => Junction Layer Train: Task 0, Epoch 5/5 => Loss 2.043, Train_accy 94.72
2024-11-12 19:45:03,546 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 19:45:03,547 [dsease_hoc.py] => Task acc: 98.8
2024-11-12 19:45:03,574 [trainer.py] => No NME accuracy.
2024-11-12 19:45:03,574 [trainer.py] => CNN: {'total': 98.8, '00-04': 98.8, 'old': 0, 'new': 98.8}
2024-11-12 19:45:03,575 [trainer.py] => CNN top1 curve: [98.8]
2024-11-12 19:45:03,575 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 19:45:03,575 [trainer.py] => Average Accuracy (CNN): 98.8 

2024-11-12 19:45:03,575 [trainer.py] => All params: 87150252
2024-11-12 19:45:03,576 [trainer.py] => Trainable params: 1189632
2024-11-12 19:45:03,844 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 19:45:03,844 [dsease_hoc.py] => Learning on 5-10
2024-11-12 19:46:11,120 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.272, Train_accy 91.16
2024-11-12 19:48:59,105 [dsease_hoc.py] => Junction Layer Train: Task 1, Epoch 5/5 => Loss 9.799, Train_accy 92.40
2024-11-12 19:49:10,784 [dsease_hoc.py] => Task correct: 50.0
2024-11-12 19:49:10,784 [dsease_hoc.py] => Task acc: 64.2
2024-11-12 19:49:10,817 [trainer.py] => No NME accuracy.
2024-11-12 19:49:10,817 [trainer.py] => CNN: {'total': 49.5, '00-04': 0.0, '05-09': 99.0, 'old': 0.0, 'new': 99.0}
2024-11-12 19:49:10,817 [trainer.py] => CNN top1 curve: [98.8, 49.5]
2024-11-12 19:49:10,818 [trainer.py] => CNN top5 curve: [100.0, 50.0]

2024-11-12 19:49:10,818 [trainer.py] => Average Accuracy (CNN): 74.15 

2024-11-12 19:49:10,818 [trainer.py] => All params: 87226284
2024-11-12 19:49:10,819 [trainer.py] => Trainable params: 1189632
2024-11-12 19:49:11,120 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-12 19:49:11,121 [dsease_hoc.py] => Learning on 10-15
2024-11-12 19:52:07,617 [trainer.py] => model: dsease_hoc
2024-11-12 19:52:07,617 [trainer.py] => prefix:  
2024-11-12 19:52:07,618 [trainer.py] => dataset: cifar224
2024-11-12 19:52:07,618 [trainer.py] => memory_size: 0
2024-11-12 19:52:07,618 [trainer.py] => memory_per_class: 0
2024-11-12 19:52:07,618 [trainer.py] => fixed_memory: False
2024-11-12 19:52:07,618 [trainer.py] => shuffle: True
2024-11-12 19:52:07,618 [trainer.py] => init_cls: 5
2024-11-12 19:52:07,618 [trainer.py] => increment: 5
2024-11-12 19:52:07,618 [trainer.py] => model_name: dsease_hoc
2024-11-12 19:52:07,618 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 19:52:07,618 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 19:52:07,618 [trainer.py] => seed: 110
2024-11-12 19:52:07,618 [trainer.py] => wandb_log: False
2024-11-12 19:52:07,618 [trainer.py] => test_future: False
2024-11-12 19:52:07,618 [trainer.py] => lambda: 0.1
2024-11-12 19:52:07,618 [trainer.py] => mu: 10
2024-11-12 19:52:07,618 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 19:52:07,618 [trainer.py] => hoc_epochs: 5
2024-11-12 19:52:07,618 [trainer.py] => init_epochs: 3
2024-11-12 19:52:07,618 [trainer.py] => init_lr: 0.025
2024-11-12 19:52:07,618 [trainer.py] => later_epochs: 3
2024-11-12 19:52:07,618 [trainer.py] => later_lr: 0.025
2024-11-12 19:52:07,619 [trainer.py] => batch_size: 48
2024-11-12 19:52:07,619 [trainer.py] => weight_decay: 0.0005
2024-11-12 19:52:07,619 [trainer.py] => min_lr: 0
2024-11-12 19:52:07,619 [trainer.py] => optimizer: sgd
2024-11-12 19:52:07,619 [trainer.py] => scheduler: cosine
2024-11-12 19:52:07,619 [trainer.py] => pretrained: True
2024-11-12 19:52:07,619 [trainer.py] => vpt_type: Deep
2024-11-12 19:52:07,619 [trainer.py] => prompt_token_num: 5
2024-11-12 19:52:07,619 [trainer.py] => ffn_num: 64
2024-11-12 19:52:07,619 [trainer.py] => use_diagonal: False
2024-11-12 19:52:07,619 [trainer.py] => recalc_sim: True
2024-11-12 19:52:07,619 [trainer.py] => alpha: 0.1
2024-11-12 19:52:07,619 [trainer.py] => use_init_ptm: False
2024-11-12 19:52:07,619 [trainer.py] => beta: 0
2024-11-12 19:52:07,619 [trainer.py] => use_old_data: False
2024-11-12 19:52:07,619 [trainer.py] => use_reweight: False
2024-11-12 19:52:07,619 [trainer.py] => moni_adam: False
2024-11-12 19:52:07,619 [trainer.py] => adapter_num: -1
2024-11-12 19:52:09,308 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 19:52:13,574 [trainer.py] => All params: 87150252
2024-11-12 19:52:13,575 [trainer.py] => Trainable params: 1341696
2024-11-12 19:52:13,576 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 19:52:13,576 [dsease_hoc.py] => Learning on 0-5
2024-11-12 23:12:31,378 [trainer.py] => model: dsease_hoc
2024-11-12 23:12:31,378 [trainer.py] => prefix:  
2024-11-12 23:12:31,378 [trainer.py] => dataset: cifar224
2024-11-12 23:12:31,378 [trainer.py] => memory_size: 0
2024-11-12 23:12:31,378 [trainer.py] => memory_per_class: 0
2024-11-12 23:12:31,378 [trainer.py] => fixed_memory: False
2024-11-12 23:12:31,378 [trainer.py] => shuffle: True
2024-11-12 23:12:31,378 [trainer.py] => init_cls: 5
2024-11-12 23:12:31,378 [trainer.py] => increment: 5
2024-11-12 23:12:31,378 [trainer.py] => model_name: dsease_hoc
2024-11-12 23:12:31,378 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 23:12:31,378 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 23:12:31,378 [trainer.py] => seed: 110
2024-11-12 23:12:31,378 [trainer.py] => wandb_log: False
2024-11-12 23:12:31,378 [trainer.py] => test_future: False
2024-11-12 23:12:31,378 [trainer.py] => lambda: 0.1
2024-11-12 23:12:31,379 [trainer.py] => mu: 10
2024-11-12 23:12:31,379 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 23:12:31,379 [trainer.py] => hoc_epochs: 5
2024-11-12 23:12:31,379 [trainer.py] => init_epochs: 3
2024-11-12 23:12:31,379 [trainer.py] => init_lr: 0.025
2024-11-12 23:12:31,379 [trainer.py] => later_epochs: 3
2024-11-12 23:12:31,379 [trainer.py] => later_lr: 0.025
2024-11-12 23:12:31,379 [trainer.py] => batch_size: 48
2024-11-12 23:12:31,379 [trainer.py] => weight_decay: 0.0005
2024-11-12 23:12:31,379 [trainer.py] => min_lr: 0
2024-11-12 23:12:31,379 [trainer.py] => optimizer: sgd
2024-11-12 23:12:31,379 [trainer.py] => scheduler: cosine
2024-11-12 23:12:31,379 [trainer.py] => pretrained: True
2024-11-12 23:12:31,379 [trainer.py] => vpt_type: Deep
2024-11-12 23:12:31,379 [trainer.py] => prompt_token_num: 5
2024-11-12 23:12:31,379 [trainer.py] => ffn_num: 64
2024-11-12 23:12:31,379 [trainer.py] => use_diagonal: False
2024-11-12 23:12:31,379 [trainer.py] => recalc_sim: True
2024-11-12 23:12:31,379 [trainer.py] => alpha: 0.1
2024-11-12 23:12:31,379 [trainer.py] => use_init_ptm: False
2024-11-12 23:12:31,379 [trainer.py] => beta: 0
2024-11-12 23:12:31,379 [trainer.py] => use_old_data: False
2024-11-12 23:12:31,380 [trainer.py] => use_reweight: False
2024-11-12 23:12:31,380 [trainer.py] => moni_adam: False
2024-11-12 23:12:31,380 [trainer.py] => adapter_num: -1
2024-11-12 23:12:33,133 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 23:12:37,547 [trainer.py] => All params: 87150252
2024-11-12 23:12:37,548 [trainer.py] => Trainable params: 1341696
2024-11-12 23:12:37,549 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 23:12:37,549 [dsease_hoc.py] => Learning on 0-5
2024-11-12 23:13:43,477 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 23:14:41,060 [dsease_hoc.py] => Junction Layer Train: Task 0, Epoch 5/5 => Loss 2.043, Train_accy 94.72
2024-11-12 23:14:45,846 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 23:14:45,846 [dsease_hoc.py] => Task acc: 98.8
2024-11-12 23:14:45,888 [trainer.py] => No NME accuracy.
2024-11-12 23:14:45,889 [trainer.py] => CNN: {'total': 98.8, '00-04': 98.8, 'old': 0, 'new': 98.8}
2024-11-12 23:14:45,889 [trainer.py] => CNN top1 curve: [98.8]
2024-11-12 23:14:45,889 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 23:14:45,889 [trainer.py] => Average Accuracy (CNN): 98.8 

2024-11-12 23:14:45,890 [trainer.py] => All params: 87150252
2024-11-12 23:14:45,891 [trainer.py] => Trainable params: 1189632
2024-11-12 23:14:46,208 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 23:14:46,208 [dsease_hoc.py] => Learning on 5-10
2024-11-12 23:15:53,004 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.272, Train_accy 91.16
2024-11-12 23:18:39,078 [dsease_hoc.py] => Junction Layer Train: Task 1, Epoch 5/5 => Loss 3.157, Train_accy 94.64
2024-11-12 23:18:50,437 [dsease_hoc.py] => Task correct: 50.0
2024-11-12 23:18:50,438 [dsease_hoc.py] => Task acc: 71.6
2024-11-12 23:18:50,470 [trainer.py] => No NME accuracy.
2024-11-12 23:18:50,470 [trainer.py] => CNN: {'total': 49.3, '00-04': 0.0, '05-09': 98.6, 'old': 0.0, 'new': 98.6}
2024-11-12 23:18:50,470 [trainer.py] => CNN top1 curve: [98.8, 49.3]
2024-11-12 23:18:50,470 [trainer.py] => CNN top5 curve: [100.0, 51.2]

2024-11-12 23:18:50,470 [trainer.py] => Average Accuracy (CNN): 74.05 

2024-11-12 23:18:50,471 [trainer.py] => All params: 87226284
2024-11-12 23:18:50,472 [trainer.py] => Trainable params: 1189632
2024-11-12 23:18:50,766 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-12 23:18:50,766 [dsease_hoc.py] => Learning on 10-15
2024-11-12 23:26:45,264 [trainer.py] => model: dsease_hoc
2024-11-12 23:26:45,264 [trainer.py] => prefix:  
2024-11-12 23:26:45,264 [trainer.py] => dataset: cifar224
2024-11-12 23:26:45,264 [trainer.py] => memory_size: 0
2024-11-12 23:26:45,264 [trainer.py] => memory_per_class: 0
2024-11-12 23:26:45,264 [trainer.py] => fixed_memory: False
2024-11-12 23:26:45,264 [trainer.py] => shuffle: True
2024-11-12 23:26:45,264 [trainer.py] => init_cls: 5
2024-11-12 23:26:45,265 [trainer.py] => increment: 5
2024-11-12 23:26:45,265 [trainer.py] => model_name: dsease_hoc
2024-11-12 23:26:45,265 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 23:26:45,265 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 23:26:45,265 [trainer.py] => seed: 110
2024-11-12 23:26:45,265 [trainer.py] => wandb_log: False
2024-11-12 23:26:45,265 [trainer.py] => test_future: False
2024-11-12 23:26:45,265 [trainer.py] => lambda: 0.1
2024-11-12 23:26:45,265 [trainer.py] => mu: 10
2024-11-12 23:26:45,265 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 23:26:45,265 [trainer.py] => hoc_epochs: 5
2024-11-12 23:26:45,265 [trainer.py] => hoc_lr: 0.08
2024-11-12 23:26:45,265 [trainer.py] => init_epochs: 3
2024-11-12 23:26:45,265 [trainer.py] => init_lr: 0.025
2024-11-12 23:26:45,265 [trainer.py] => later_epochs: 3
2024-11-12 23:26:45,265 [trainer.py] => later_lr: 0.025
2024-11-12 23:26:45,265 [trainer.py] => batch_size: 48
2024-11-12 23:26:45,265 [trainer.py] => weight_decay: 0.0005
2024-11-12 23:26:45,265 [trainer.py] => min_lr: 0
2024-11-12 23:26:45,266 [trainer.py] => optimizer: sgd
2024-11-12 23:26:45,266 [trainer.py] => scheduler: cosine
2024-11-12 23:26:45,266 [trainer.py] => pretrained: True
2024-11-12 23:26:45,266 [trainer.py] => vpt_type: Deep
2024-11-12 23:26:45,266 [trainer.py] => prompt_token_num: 5
2024-11-12 23:26:45,266 [trainer.py] => ffn_num: 64
2024-11-12 23:26:45,266 [trainer.py] => use_diagonal: False
2024-11-12 23:26:45,266 [trainer.py] => recalc_sim: True
2024-11-12 23:26:45,266 [trainer.py] => alpha: 0.1
2024-11-12 23:26:45,266 [trainer.py] => use_init_ptm: False
2024-11-12 23:26:45,266 [trainer.py] => beta: 0
2024-11-12 23:26:45,266 [trainer.py] => use_old_data: False
2024-11-12 23:26:45,266 [trainer.py] => use_reweight: False
2024-11-12 23:26:45,266 [trainer.py] => moni_adam: False
2024-11-12 23:26:45,266 [trainer.py] => adapter_num: -1
2024-11-12 23:26:47,173 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 23:26:51,371 [trainer.py] => All params: 87150252
2024-11-12 23:26:51,372 [trainer.py] => Trainable params: 1341696
2024-11-12 23:26:51,374 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 23:26:51,374 [dsease_hoc.py] => Learning on 0-5
2024-11-12 23:27:57,363 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 23:28:02,047 [dsease_hoc.py] => Task correct: 27.4
2024-11-12 23:28:02,048 [dsease_hoc.py] => Task acc: 17.6
2024-11-12 23:28:02,076 [trainer.py] => No NME accuracy.
2024-11-12 23:28:02,076 [trainer.py] => CNN: {'total': 2.2, '00-04': 2.2, 'old': 0, 'new': 2.2}
2024-11-12 23:28:02,076 [trainer.py] => CNN top1 curve: [2.2]
2024-11-12 23:28:02,076 [trainer.py] => CNN top5 curve: [8.8]

2024-11-12 23:28:02,076 [trainer.py] => Average Accuracy (CNN): 2.2 

2024-11-12 23:28:02,077 [trainer.py] => All params: 87150252
2024-11-12 23:28:02,077 [trainer.py] => Trainable params: 1189632
2024-11-12 23:28:02,357 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 23:28:02,357 [dsease_hoc.py] => Learning on 5-10
2024-11-12 23:29:08,976 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.293, Train_accy 91.04
2024-11-12 23:31:55,604 [dsease_hoc.py] => Junction Layer Train: Task 1, Epoch 5/5 => Loss -0.680, Train_accy 86.60
2024-11-12 23:32:07,058 [dsease_hoc.py] => Task correct: 49.3
2024-11-12 23:32:07,058 [dsease_hoc.py] => Task acc: 57.8
2024-11-12 23:32:07,087 [trainer.py] => No NME accuracy.
2024-11-12 23:32:07,087 [trainer.py] => CNN: {'total': 48.2, '00-04': 0.2, '05-09': 96.2, 'old': 0.2, 'new': 96.2}
2024-11-12 23:32:07,087 [trainer.py] => CNN top1 curve: [2.2, 48.2]
2024-11-12 23:32:07,087 [trainer.py] => CNN top5 curve: [8.8, 50.7]

2024-11-12 23:32:07,087 [trainer.py] => Average Accuracy (CNN): 25.200000000000003 

2024-11-12 23:32:07,088 [trainer.py] => All params: 87226284
2024-11-12 23:32:07,089 [trainer.py] => Trainable params: 1189632
2024-11-12 23:32:07,514 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-12 23:32:07,514 [dsease_hoc.py] => Learning on 10-15
2024-11-12 23:32:59,463 [trainer.py] => model: dsease_hoc
2024-11-12 23:32:59,464 [trainer.py] => prefix:  
2024-11-12 23:32:59,464 [trainer.py] => dataset: cifar224
2024-11-12 23:32:59,464 [trainer.py] => memory_size: 0
2024-11-12 23:32:59,464 [trainer.py] => memory_per_class: 0
2024-11-12 23:32:59,464 [trainer.py] => fixed_memory: False
2024-11-12 23:32:59,464 [trainer.py] => shuffle: True
2024-11-12 23:32:59,464 [trainer.py] => init_cls: 5
2024-11-12 23:32:59,464 [trainer.py] => increment: 5
2024-11-12 23:32:59,464 [trainer.py] => model_name: dsease_hoc
2024-11-12 23:32:59,464 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 23:32:59,464 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 23:32:59,464 [trainer.py] => seed: 110
2024-11-12 23:32:59,464 [trainer.py] => wandb_log: False
2024-11-12 23:32:59,464 [trainer.py] => test_future: False
2024-11-12 23:32:59,464 [trainer.py] => lambda: 0.1
2024-11-12 23:32:59,464 [trainer.py] => mu: 10
2024-11-12 23:32:59,464 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 23:32:59,464 [trainer.py] => hoc_epochs: 5
2024-11-12 23:32:59,464 [trainer.py] => hoc_lr: 0.05
2024-11-12 23:32:59,465 [trainer.py] => init_epochs: 3
2024-11-12 23:32:59,465 [trainer.py] => init_lr: 0.025
2024-11-12 23:32:59,465 [trainer.py] => later_epochs: 3
2024-11-12 23:32:59,465 [trainer.py] => later_lr: 0.025
2024-11-12 23:32:59,465 [trainer.py] => batch_size: 48
2024-11-12 23:32:59,465 [trainer.py] => weight_decay: 0.0005
2024-11-12 23:32:59,465 [trainer.py] => min_lr: 0
2024-11-12 23:32:59,465 [trainer.py] => optimizer: sgd
2024-11-12 23:32:59,465 [trainer.py] => scheduler: cosine
2024-11-12 23:32:59,465 [trainer.py] => pretrained: True
2024-11-12 23:32:59,465 [trainer.py] => vpt_type: Deep
2024-11-12 23:32:59,465 [trainer.py] => prompt_token_num: 5
2024-11-12 23:32:59,465 [trainer.py] => ffn_num: 64
2024-11-12 23:32:59,465 [trainer.py] => use_diagonal: False
2024-11-12 23:32:59,465 [trainer.py] => recalc_sim: True
2024-11-12 23:32:59,465 [trainer.py] => alpha: 0.1
2024-11-12 23:32:59,465 [trainer.py] => use_init_ptm: False
2024-11-12 23:32:59,465 [trainer.py] => beta: 0
2024-11-12 23:32:59,465 [trainer.py] => use_old_data: False
2024-11-12 23:32:59,465 [trainer.py] => use_reweight: False
2024-11-12 23:32:59,465 [trainer.py] => moni_adam: False
2024-11-12 23:32:59,465 [trainer.py] => adapter_num: -1
2024-11-12 23:33:01,148 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 23:33:04,496 [trainer.py] => All params: 87150252
2024-11-12 23:33:04,497 [trainer.py] => Trainable params: 1341696
2024-11-12 23:33:04,499 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 23:33:04,499 [dsease_hoc.py] => Learning on 0-5
2024-11-12 23:34:11,481 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 23:34:16,486 [dsease_hoc.py] => Task correct: 27.4
2024-11-12 23:34:16,486 [dsease_hoc.py] => Task acc: 17.6
2024-11-12 23:34:16,529 [trainer.py] => No NME accuracy.
2024-11-12 23:34:16,529 [trainer.py] => CNN: {'total': 2.2, '00-04': 2.2, 'old': 0, 'new': 2.2}
2024-11-12 23:34:16,530 [trainer.py] => CNN top1 curve: [2.2]
2024-11-12 23:34:16,530 [trainer.py] => CNN top5 curve: [8.8]

2024-11-12 23:34:16,530 [trainer.py] => Average Accuracy (CNN): 2.2 

2024-11-12 23:34:16,531 [trainer.py] => All params: 87150252
2024-11-12 23:34:16,532 [trainer.py] => Trainable params: 1189632
2024-11-12 23:34:16,826 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 23:34:16,826 [dsease_hoc.py] => Learning on 5-10
2024-11-12 23:35:07,706 [trainer.py] => model: dsease_hoc
2024-11-12 23:35:07,707 [trainer.py] => prefix:  
2024-11-12 23:35:07,707 [trainer.py] => dataset: cifar224
2024-11-12 23:35:07,707 [trainer.py] => memory_size: 0
2024-11-12 23:35:07,707 [trainer.py] => memory_per_class: 0
2024-11-12 23:35:07,707 [trainer.py] => fixed_memory: False
2024-11-12 23:35:07,707 [trainer.py] => shuffle: True
2024-11-12 23:35:07,707 [trainer.py] => init_cls: 5
2024-11-12 23:35:07,707 [trainer.py] => increment: 5
2024-11-12 23:35:07,707 [trainer.py] => model_name: dsease_hoc
2024-11-12 23:35:07,707 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-12 23:35:07,707 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-12 23:35:07,707 [trainer.py] => seed: 110
2024-11-12 23:35:07,707 [trainer.py] => wandb_log: False
2024-11-12 23:35:07,707 [trainer.py] => test_future: False
2024-11-12 23:35:07,707 [trainer.py] => lambda: 0.1
2024-11-12 23:35:07,707 [trainer.py] => mu: 10
2024-11-12 23:35:07,707 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-12 23:35:07,707 [trainer.py] => hoc_epochs: 5
2024-11-12 23:35:07,707 [trainer.py] => hoc_lr: 0.05
2024-11-12 23:35:07,708 [trainer.py] => init_epochs: 3
2024-11-12 23:35:07,708 [trainer.py] => init_lr: 0.025
2024-11-12 23:35:07,708 [trainer.py] => later_epochs: 3
2024-11-12 23:35:07,708 [trainer.py] => later_lr: 0.025
2024-11-12 23:35:07,708 [trainer.py] => batch_size: 48
2024-11-12 23:35:07,708 [trainer.py] => weight_decay: 0.0005
2024-11-12 23:35:07,708 [trainer.py] => min_lr: 0
2024-11-12 23:35:07,708 [trainer.py] => optimizer: sgd
2024-11-12 23:35:07,708 [trainer.py] => scheduler: cosine
2024-11-12 23:35:07,708 [trainer.py] => pretrained: True
2024-11-12 23:35:07,708 [trainer.py] => vpt_type: Deep
2024-11-12 23:35:07,708 [trainer.py] => prompt_token_num: 5
2024-11-12 23:35:07,708 [trainer.py] => ffn_num: 64
2024-11-12 23:35:07,708 [trainer.py] => use_diagonal: False
2024-11-12 23:35:07,708 [trainer.py] => recalc_sim: True
2024-11-12 23:35:07,708 [trainer.py] => alpha: 0.1
2024-11-12 23:35:07,708 [trainer.py] => use_init_ptm: False
2024-11-12 23:35:07,708 [trainer.py] => beta: 0
2024-11-12 23:35:07,708 [trainer.py] => use_old_data: False
2024-11-12 23:35:07,708 [trainer.py] => use_reweight: False
2024-11-12 23:35:07,708 [trainer.py] => moni_adam: False
2024-11-12 23:35:07,708 [trainer.py] => adapter_num: -1
2024-11-12 23:35:09,422 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-12 23:35:13,655 [trainer.py] => All params: 87150252
2024-11-12 23:35:13,656 [trainer.py] => Trainable params: 1341696
2024-11-12 23:35:13,658 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 23:35:13,658 [dsease_hoc.py] => Learning on 0-5
2024-11-12 23:36:20,796 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-12 23:36:25,700 [dsease_hoc.py] => Task correct: 100.0
2024-11-12 23:36:25,701 [dsease_hoc.py] => Task acc: 98.8
2024-11-12 23:36:25,731 [trainer.py] => No NME accuracy.
2024-11-12 23:36:25,732 [trainer.py] => CNN: {'total': 98.8, '00-04': 98.8, 'old': 0, 'new': 98.8}
2024-11-12 23:36:25,732 [trainer.py] => CNN top1 curve: [98.8]
2024-11-12 23:36:25,732 [trainer.py] => CNN top5 curve: [100.0]

2024-11-12 23:36:25,732 [trainer.py] => Average Accuracy (CNN): 98.8 

2024-11-12 23:36:25,733 [trainer.py] => All params: 87150252
2024-11-12 23:36:25,733 [trainer.py] => Trainable params: 1189632
2024-11-12 23:36:26,012 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-12 23:36:26,012 [dsease_hoc.py] => Learning on 5-10
2024-11-12 23:37:33,188 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.293, Train_accy 91.04
2024-11-12 23:40:20,165 [dsease_hoc.py] => Junction Layer Train: Task 1, Epoch 5/5 => Loss 2.435, Train_accy 89.32
2024-11-12 23:40:31,764 [dsease_hoc.py] => Task correct: 89.0
2024-11-12 23:40:31,764 [dsease_hoc.py] => Task acc: 97.3
2024-11-12 23:40:31,793 [trainer.py] => No NME accuracy.
2024-11-12 23:40:31,794 [trainer.py] => CNN: {'total': 87.8, '00-04': 89.4, '05-09': 86.2, 'old': 89.4, 'new': 86.2}
2024-11-12 23:40:31,794 [trainer.py] => CNN top1 curve: [98.8, 87.8]
2024-11-12 23:40:31,794 [trainer.py] => CNN top5 curve: [100.0, 99.3]

2024-11-12 23:40:31,794 [trainer.py] => Average Accuracy (CNN): 93.3 

2024-11-12 23:40:31,795 [trainer.py] => All params: 87226284
2024-11-12 23:40:31,795 [trainer.py] => Trainable params: 1189632
2024-11-12 23:40:32,193 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-12 23:40:32,194 [dsease_hoc.py] => Learning on 10-15
2024-11-16 16:07:30,614 [trainer.py] => model: dsease_hoc
2024-11-16 16:07:30,614 [trainer.py] => prefix:  
2024-11-16 16:07:30,615 [trainer.py] => dataset: cifar224
2024-11-16 16:07:30,615 [trainer.py] => memory_size: 0
2024-11-16 16:07:30,615 [trainer.py] => memory_per_class: 0
2024-11-16 16:07:30,615 [trainer.py] => fixed_memory: False
2024-11-16 16:07:30,615 [trainer.py] => shuffle: True
2024-11-16 16:07:30,615 [trainer.py] => init_cls: 5
2024-11-16 16:07:30,615 [trainer.py] => increment: 5
2024-11-16 16:07:30,615 [trainer.py] => model_name: dsease_hoc
2024-11-16 16:07:30,615 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-16 16:07:30,615 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-16 16:07:30,616 [trainer.py] => seed: 110
2024-11-16 16:07:30,616 [trainer.py] => wandb_log: False
2024-11-16 16:07:30,616 [trainer.py] => test_future: False
2024-11-16 16:07:30,616 [trainer.py] => lambda: 0.1
2024-11-16 16:07:30,616 [trainer.py] => mu: 10
2024-11-16 16:07:30,616 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-16 16:07:30,616 [trainer.py] => hoc_epochs: 5
2024-11-16 16:07:30,616 [trainer.py] => hoc_lr: 0.025
2024-11-16 16:07:30,616 [trainer.py] => init_epochs: 3
2024-11-16 16:07:30,616 [trainer.py] => init_lr: 0.025
2024-11-16 16:07:30,616 [trainer.py] => later_epochs: 3
2024-11-16 16:07:30,616 [trainer.py] => later_lr: 0.025
2024-11-16 16:07:30,617 [trainer.py] => batch_size: 48
2024-11-16 16:07:30,617 [trainer.py] => weight_decay: 0.0005
2024-11-16 16:07:30,617 [trainer.py] => min_lr: 0
2024-11-16 16:07:30,617 [trainer.py] => optimizer: sgd
2024-11-16 16:07:30,617 [trainer.py] => scheduler: cosine
2024-11-16 16:07:30,617 [trainer.py] => pretrained: True
2024-11-16 16:07:30,617 [trainer.py] => vpt_type: Deep
2024-11-16 16:07:30,617 [trainer.py] => prompt_token_num: 5
2024-11-16 16:07:30,617 [trainer.py] => ffn_num: 64
2024-11-16 16:07:30,617 [trainer.py] => use_diagonal: False
2024-11-16 16:07:30,617 [trainer.py] => recalc_sim: True
2024-11-16 16:07:30,617 [trainer.py] => alpha: 0.1
2024-11-16 16:07:30,618 [trainer.py] => use_init_ptm: False
2024-11-16 16:07:30,618 [trainer.py] => beta: 0
2024-11-16 16:07:30,618 [trainer.py] => use_old_data: False
2024-11-16 16:07:30,618 [trainer.py] => use_reweight: False
2024-11-16 16:07:30,618 [trainer.py] => moni_adam: False
2024-11-16 16:07:30,618 [trainer.py] => adapter_num: -1
2024-11-16 16:07:32,314 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-16 16:07:38,850 [trainer.py] => All params: 87150252
2024-11-16 16:07:38,851 [trainer.py] => Trainable params: 1341696
2024-11-16 16:07:38,853 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 16:07:38,853 [dsease_hoc.py] => Learning on 0-5
2024-11-16 16:08:46,117 [dsease_hoc.py] => Task 0, Epoch 3/3 => Loss 0.399, Train_accy 95.44
2024-11-16 16:08:51,128 [dsease_hoc.py] => Task correct: 100.0
2024-11-16 16:08:51,128 [dsease_hoc.py] => Task acc: 98.8
2024-11-16 16:08:51,157 [trainer.py] => No NME accuracy.
2024-11-16 16:08:51,157 [trainer.py] => CNN: {'total': 98.8, '00-04': 98.8, 'old': 0, 'new': 98.8}
2024-11-16 16:08:51,157 [trainer.py] => CNN top1 curve: [98.8]
2024-11-16 16:08:51,157 [trainer.py] => CNN top5 curve: [100.0]

2024-11-16 16:08:51,158 [trainer.py] => Average Accuracy (CNN): 98.8 

2024-11-16 16:08:51,158 [trainer.py] => All params: 87150252
2024-11-16 16:08:51,159 [trainer.py] => Trainable params: 1189632
2024-11-16 16:08:51,477 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 16:08:51,477 [dsease_hoc.py] => Learning on 5-10
2024-11-16 16:09:59,210 [dsease_hoc.py] => Task 1, Epoch 3/3 => Loss 0.293, Train_accy 91.04
2024-11-16 16:12:47,642 [dsease_hoc.py] => Junction Layer Train: Task 1, Epoch 5/5 => Loss 2.546, Train_accy 88.72
2024-11-16 16:12:59,300 [dsease_hoc.py] => Task correct: 92.3
2024-11-16 16:12:59,301 [dsease_hoc.py] => Task acc: 96.9
2024-11-16 16:12:59,332 [trainer.py] => No NME accuracy.
2024-11-16 16:12:59,332 [trainer.py] => CNN: {'total': 91.1, '00-04': 89.2, '05-09': 93.0, 'old': 89.2, 'new': 93.0}
2024-11-16 16:12:59,332 [trainer.py] => CNN top1 curve: [98.8, 91.1]
2024-11-16 16:12:59,332 [trainer.py] => CNN top5 curve: [100.0, 98.5]

2024-11-16 16:12:59,332 [trainer.py] => Average Accuracy (CNN): 94.94999999999999 

2024-11-16 16:12:59,333 [trainer.py] => All params: 87226284
2024-11-16 16:12:59,334 [trainer.py] => Trainable params: 1189632
2024-11-16 16:12:59,804 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-16 16:12:59,804 [dsease_hoc.py] => Learning on 10-15
2024-11-16 16:14:28,933 [trainer.py] => model: dsease_hoc
2024-11-16 16:14:28,933 [trainer.py] => prefix:  
2024-11-16 16:14:28,933 [trainer.py] => dataset: cifar224
2024-11-16 16:14:28,933 [trainer.py] => memory_size: 0
2024-11-16 16:14:28,933 [trainer.py] => memory_per_class: 0
2024-11-16 16:14:28,933 [trainer.py] => fixed_memory: False
2024-11-16 16:14:28,934 [trainer.py] => shuffle: True
2024-11-16 16:14:28,934 [trainer.py] => init_cls: 5
2024-11-16 16:14:28,934 [trainer.py] => increment: 5
2024-11-16 16:14:28,934 [trainer.py] => model_name: dsease_hoc
2024-11-16 16:14:28,934 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-16 16:14:28,934 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-16 16:14:28,934 [trainer.py] => seed: 110
2024-11-16 16:14:28,934 [trainer.py] => wandb_log: True
2024-11-16 16:14:28,935 [trainer.py] => test_future: False
2024-11-16 16:14:28,935 [trainer.py] => lambda: 0.1
2024-11-16 16:14:28,935 [trainer.py] => mu: 10
2024-11-16 16:14:28,935 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-16 16:14:28,935 [trainer.py] => hoc_epochs: 10
2024-11-16 16:14:28,935 [trainer.py] => hoc_lr: 0.01
2024-11-16 16:14:28,935 [trainer.py] => init_epochs: 20
2024-11-16 16:14:28,935 [trainer.py] => init_lr: 0.025
2024-11-16 16:14:28,935 [trainer.py] => later_epochs: 20
2024-11-16 16:14:28,936 [trainer.py] => later_lr: 0.025
2024-11-16 16:14:28,936 [trainer.py] => batch_size: 48
2024-11-16 16:14:28,936 [trainer.py] => weight_decay: 0.0005
2024-11-16 16:14:28,936 [trainer.py] => min_lr: 0
2024-11-16 16:14:28,936 [trainer.py] => optimizer: sgd
2024-11-16 16:14:28,936 [trainer.py] => scheduler: cosine
2024-11-16 16:14:28,936 [trainer.py] => pretrained: True
2024-11-16 16:14:28,936 [trainer.py] => vpt_type: Deep
2024-11-16 16:14:28,936 [trainer.py] => prompt_token_num: 5
2024-11-16 16:14:28,937 [trainer.py] => ffn_num: 64
2024-11-16 16:14:28,937 [trainer.py] => use_diagonal: False
2024-11-16 16:14:28,937 [trainer.py] => recalc_sim: True
2024-11-16 16:14:28,937 [trainer.py] => alpha: 0.1
2024-11-16 16:14:28,937 [trainer.py] => use_init_ptm: False
2024-11-16 16:14:28,937 [trainer.py] => beta: 0
2024-11-16 16:14:28,937 [trainer.py] => use_old_data: False
2024-11-16 16:14:28,937 [trainer.py] => use_reweight: False
2024-11-16 16:14:28,938 [trainer.py] => moni_adam: False
2024-11-16 16:14:28,938 [trainer.py] => adapter_num: -1
2024-11-16 16:14:30,762 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-16 16:14:35,182 [trainer.py] => All params: 87150252
2024-11-16 16:14:35,184 [trainer.py] => Trainable params: 1341696
2024-11-16 16:14:35,186 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 16:14:35,186 [dsease_hoc.py] => Learning on 0-5
2024-11-16 16:22:07,094 [dsease_hoc.py] => Task 0, Epoch 20/20 => Loss 0.080, Train_accy 97.16
2024-11-16 16:22:12,009 [dsease_hoc.py] => Task correct: 100.0
2024-11-16 16:22:12,010 [dsease_hoc.py] => Task acc: 99.6
2024-11-16 16:22:12,040 [trainer.py] => No NME accuracy.
2024-11-16 16:22:12,040 [trainer.py] => CNN: {'total': 99.6, '00-04': 99.6, 'old': 0, 'new': 99.6}
2024-11-16 16:22:12,040 [trainer.py] => CNN top1 curve: [99.6]
2024-11-16 16:22:12,040 [trainer.py] => CNN top5 curve: [100.0]

2024-11-16 16:22:12,041 [trainer.py] => Average Accuracy (CNN): 99.6 

2024-11-16 16:22:12,042 [trainer.py] => All params: 87150252
2024-11-16 16:22:12,043 [trainer.py] => Trainable params: 1189632
2024-11-16 16:22:12,303 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 16:22:12,303 [dsease_hoc.py] => Learning on 5-10
2024-11-16 16:29:43,205 [dsease_hoc.py] => Task 1, Epoch 20/20 => Loss 0.127, Train_accy 96.24
2024-11-16 16:35:19,821 [dsease_hoc.py] => Junction Layer Train: Task 1, Epoch 10/10 => Loss 2.166, Train_accy 89.72
2024-11-16 16:35:31,332 [dsease_hoc.py] => Task correct: 94.6
2024-11-16 16:35:31,333 [dsease_hoc.py] => Task acc: 99.2
2024-11-16 16:35:31,376 [trainer.py] => No NME accuracy.
2024-11-16 16:35:31,376 [trainer.py] => CNN: {'total': 93.9, '00-04': 98.4, '05-09': 89.4, 'old': 98.4, 'new': 89.4}
2024-11-16 16:35:31,377 [trainer.py] => CNN top1 curve: [99.6, 93.9]
2024-11-16 16:35:31,377 [trainer.py] => CNN top5 curve: [100.0, 99.9]

2024-11-16 16:35:31,377 [trainer.py] => Average Accuracy (CNN): 96.75 

2024-11-16 16:35:31,379 [trainer.py] => All params: 87226284
2024-11-16 16:35:31,381 [trainer.py] => Trainable params: 1189632
2024-11-16 16:35:31,700 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-16 16:35:31,700 [dsease_hoc.py] => Learning on 10-15
2024-11-16 16:36:48,178 [trainer.py] => model: dsease_hoc
2024-11-16 16:36:48,178 [trainer.py] => prefix:  
2024-11-16 16:36:48,178 [trainer.py] => dataset: cifar224
2024-11-16 16:36:48,179 [trainer.py] => memory_size: 0
2024-11-16 16:36:48,179 [trainer.py] => memory_per_class: 0
2024-11-16 16:36:48,179 [trainer.py] => fixed_memory: False
2024-11-16 16:36:48,179 [trainer.py] => shuffle: True
2024-11-16 16:36:48,179 [trainer.py] => init_cls: 5
2024-11-16 16:36:48,179 [trainer.py] => increment: 5
2024-11-16 16:36:48,179 [trainer.py] => model_name: dsease_hoc
2024-11-16 16:36:48,180 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-16 16:36:48,180 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-16 16:36:48,180 [trainer.py] => seed: 110
2024-11-16 16:36:48,180 [trainer.py] => wandb_log: True
2024-11-16 16:36:48,180 [trainer.py] => test_future: False
2024-11-16 16:36:48,180 [trainer.py] => lambda: 0.1
2024-11-16 16:36:48,180 [trainer.py] => mu: 10
2024-11-16 16:36:48,181 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-16 16:36:48,181 [trainer.py] => hoc_epochs: 10
2024-11-16 16:36:48,181 [trainer.py] => hoc_lr: 0.025
2024-11-16 16:36:48,181 [trainer.py] => init_epochs: 20
2024-11-16 16:36:48,181 [trainer.py] => init_lr: 0.025
2024-11-16 16:36:48,181 [trainer.py] => later_epochs: 20
2024-11-16 16:36:48,181 [trainer.py] => later_lr: 0.025
2024-11-16 16:36:48,182 [trainer.py] => batch_size: 48
2024-11-16 16:36:48,182 [trainer.py] => weight_decay: 0.0005
2024-11-16 16:36:48,182 [trainer.py] => min_lr: 0
2024-11-16 16:36:48,182 [trainer.py] => optimizer: sgd
2024-11-16 16:36:48,182 [trainer.py] => scheduler: cosine
2024-11-16 16:36:48,182 [trainer.py] => pretrained: True
2024-11-16 16:36:48,182 [trainer.py] => vpt_type: Deep
2024-11-16 16:36:48,183 [trainer.py] => prompt_token_num: 5
2024-11-16 16:36:48,183 [trainer.py] => ffn_num: 64
2024-11-16 16:36:48,183 [trainer.py] => use_diagonal: False
2024-11-16 16:36:48,183 [trainer.py] => recalc_sim: True
2024-11-16 16:36:48,183 [trainer.py] => alpha: 0.1
2024-11-16 16:36:48,183 [trainer.py] => use_init_ptm: False
2024-11-16 16:36:48,183 [trainer.py] => beta: 0
2024-11-16 16:36:48,184 [trainer.py] => use_old_data: False
2024-11-16 16:36:48,184 [trainer.py] => use_reweight: False
2024-11-16 16:36:48,184 [trainer.py] => moni_adam: False
2024-11-16 16:36:48,184 [trainer.py] => adapter_num: -1
2024-11-16 16:36:50,034 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-16 16:36:53,712 [trainer.py] => All params: 87150252
2024-11-16 16:36:53,714 [trainer.py] => Trainable params: 1341696
2024-11-16 16:36:53,716 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 16:36:53,716 [dsease_hoc.py] => Learning on 0-5
2024-11-16 16:44:24,524 [dsease_hoc.py] => Task 0, Epoch 20/20 => Loss 0.080, Train_accy 97.16
2024-11-16 16:44:29,732 [dsease_hoc.py] => Task correct: 100.0
2024-11-16 16:44:29,733 [dsease_hoc.py] => Task acc: 99.6
2024-11-16 16:44:29,765 [trainer.py] => No NME accuracy.
2024-11-16 16:44:29,765 [trainer.py] => CNN: {'total': 99.6, '00-04': 99.6, 'old': 0, 'new': 99.6}
2024-11-16 16:44:29,765 [trainer.py] => CNN top1 curve: [99.6]
2024-11-16 16:44:29,765 [trainer.py] => CNN top5 curve: [100.0]

2024-11-16 16:44:29,766 [trainer.py] => Average Accuracy (CNN): 99.6 

2024-11-16 16:44:29,767 [trainer.py] => All params: 87150252
2024-11-16 16:44:29,768 [trainer.py] => Trainable params: 1189632
2024-11-16 16:44:30,060 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 16:44:30,060 [dsease_hoc.py] => Learning on 5-10
2024-11-16 16:52:03,967 [dsease_hoc.py] => Task 1, Epoch 20/20 => Loss 0.127, Train_accy 96.24
2024-11-16 16:57:41,194 [dsease_hoc.py] => Junction Layer Train: Task 1, Epoch 10/10 => Loss 2.118, Train_accy 88.76
2024-11-16 16:57:53,002 [dsease_hoc.py] => Task correct: 93.8
2024-11-16 16:57:53,003 [dsease_hoc.py] => Task acc: 99.4
2024-11-16 16:57:53,045 [trainer.py] => No NME accuracy.
2024-11-16 16:57:53,045 [trainer.py] => CNN: {'total': 93.2, '00-04': 99.2, '05-09': 87.2, 'old': 99.2, 'new': 87.2}
2024-11-16 16:57:53,045 [trainer.py] => CNN top1 curve: [99.6, 93.2]
2024-11-16 16:57:53,046 [trainer.py] => CNN top5 curve: [100.0, 99.9]

2024-11-16 16:57:53,046 [trainer.py] => Average Accuracy (CNN): 96.4 

2024-11-16 16:57:53,048 [trainer.py] => All params: 87226284
2024-11-16 16:57:53,049 [trainer.py] => Trainable params: 1189632
2024-11-16 16:57:53,350 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-16 16:57:53,350 [dsease_hoc.py] => Learning on 10-15
2024-11-16 17:00:26,238 [trainer.py] => model: dsease_hoc
2024-11-16 17:00:26,238 [trainer.py] => prefix:  
2024-11-16 17:00:26,238 [trainer.py] => dataset: cifar224
2024-11-16 17:00:26,238 [trainer.py] => memory_size: 0
2024-11-16 17:00:26,239 [trainer.py] => memory_per_class: 0
2024-11-16 17:00:26,239 [trainer.py] => fixed_memory: False
2024-11-16 17:00:26,239 [trainer.py] => shuffle: True
2024-11-16 17:00:26,239 [trainer.py] => init_cls: 5
2024-11-16 17:00:26,239 [trainer.py] => increment: 5
2024-11-16 17:00:26,240 [trainer.py] => model_name: dsease_hoc
2024-11-16 17:00:26,240 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-16 17:00:26,240 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-16 17:00:26,240 [trainer.py] => seed: 110
2024-11-16 17:00:26,240 [trainer.py] => wandb_log: True
2024-11-16 17:00:26,241 [trainer.py] => test_future: False
2024-11-16 17:00:26,241 [trainer.py] => lambda: 0.1
2024-11-16 17:00:26,241 [trainer.py] => mu: 10
2024-11-16 17:00:26,241 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-16 17:00:26,241 [trainer.py] => hoc_epochs: 20
2024-11-16 17:00:26,242 [trainer.py] => hoc_lr: 0.025
2024-11-16 17:00:26,242 [trainer.py] => init_epochs: 20
2024-11-16 17:00:26,242 [trainer.py] => init_lr: 0.025
2024-11-16 17:00:26,242 [trainer.py] => later_epochs: 20
2024-11-16 17:00:26,242 [trainer.py] => later_lr: 0.025
2024-11-16 17:00:26,243 [trainer.py] => batch_size: 48
2024-11-16 17:00:26,243 [trainer.py] => weight_decay: 0.0005
2024-11-16 17:00:26,243 [trainer.py] => min_lr: 0
2024-11-16 17:00:26,243 [trainer.py] => optimizer: sgd
2024-11-16 17:00:26,243 [trainer.py] => scheduler: cosine
2024-11-16 17:00:26,244 [trainer.py] => pretrained: True
2024-11-16 17:00:26,244 [trainer.py] => vpt_type: Deep
2024-11-16 17:00:26,244 [trainer.py] => prompt_token_num: 5
2024-11-16 17:00:26,244 [trainer.py] => ffn_num: 64
2024-11-16 17:00:26,245 [trainer.py] => use_diagonal: False
2024-11-16 17:00:26,245 [trainer.py] => recalc_sim: True
2024-11-16 17:00:26,245 [trainer.py] => alpha: 0.1
2024-11-16 17:00:26,245 [trainer.py] => use_init_ptm: False
2024-11-16 17:00:26,245 [trainer.py] => beta: 0
2024-11-16 17:00:26,246 [trainer.py] => use_old_data: False
2024-11-16 17:00:26,246 [trainer.py] => use_reweight: False
2024-11-16 17:00:26,246 [trainer.py] => moni_adam: False
2024-11-16 17:00:26,246 [trainer.py] => adapter_num: -1
2024-11-16 17:00:28,103 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-16 17:00:31,848 [trainer.py] => All params: 87150252
2024-11-16 17:00:31,849 [trainer.py] => Trainable params: 1341696
2024-11-16 17:00:31,851 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 17:00:31,851 [dsease_hoc.py] => Learning on 0-5
2024-11-16 17:08:00,777 [dsease_hoc.py] => Task 0, Epoch 20/20 => Loss 0.080, Train_accy 97.16
2024-11-16 17:08:05,721 [dsease_hoc.py] => Task correct: 31.8
2024-11-16 17:08:05,722 [dsease_hoc.py] => Task acc: 25.2
2024-11-16 17:08:05,767 [trainer.py] => No NME accuracy.
2024-11-16 17:08:05,767 [trainer.py] => CNN: {'total': 4.2, '00-04': 4.2, 'old': 0, 'new': 4.2}
2024-11-16 17:08:05,767 [trainer.py] => CNN top1 curve: [4.2]
2024-11-16 17:08:05,768 [trainer.py] => CNN top5 curve: [23.2]

2024-11-16 17:08:05,768 [trainer.py] => Average Accuracy (CNN): 4.2 

2024-11-16 17:08:05,770 [trainer.py] => All params: 87150252
2024-11-16 17:08:05,772 [trainer.py] => Trainable params: 1189632
2024-11-16 17:08:06,085 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 17:08:06,086 [dsease_hoc.py] => Learning on 5-10
2024-11-16 17:08:48,624 [trainer.py] => model: dsease_hoc
2024-11-16 17:08:48,624 [trainer.py] => prefix:  
2024-11-16 17:08:48,624 [trainer.py] => dataset: cifar224
2024-11-16 17:08:48,625 [trainer.py] => memory_size: 0
2024-11-16 17:08:48,625 [trainer.py] => memory_per_class: 0
2024-11-16 17:08:48,625 [trainer.py] => fixed_memory: False
2024-11-16 17:08:48,625 [trainer.py] => shuffle: True
2024-11-16 17:08:48,625 [trainer.py] => init_cls: 5
2024-11-16 17:08:48,625 [trainer.py] => increment: 5
2024-11-16 17:08:48,626 [trainer.py] => model_name: dsease_hoc
2024-11-16 17:08:48,626 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-16 17:08:48,626 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-16 17:08:48,626 [trainer.py] => seed: 110
2024-11-16 17:08:48,626 [trainer.py] => wandb_log: True
2024-11-16 17:08:48,626 [trainer.py] => test_future: False
2024-11-16 17:08:48,627 [trainer.py] => lambda: 0.1
2024-11-16 17:08:48,627 [trainer.py] => mu: 10
2024-11-16 17:08:48,627 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-16 17:08:48,627 [trainer.py] => hoc_epochs: 20
2024-11-16 17:08:48,627 [trainer.py] => hoc_lr: 0.025
2024-11-16 17:08:48,627 [trainer.py] => init_epochs: 20
2024-11-16 17:08:48,627 [trainer.py] => init_lr: 0.025
2024-11-16 17:08:48,628 [trainer.py] => later_epochs: 20
2024-11-16 17:08:48,628 [trainer.py] => later_lr: 0.025
2024-11-16 17:08:48,628 [trainer.py] => batch_size: 48
2024-11-16 17:08:48,628 [trainer.py] => weight_decay: 0.0005
2024-11-16 17:08:48,628 [trainer.py] => min_lr: 0
2024-11-16 17:08:48,628 [trainer.py] => optimizer: sgd
2024-11-16 17:08:48,628 [trainer.py] => scheduler: cosine
2024-11-16 17:08:48,629 [trainer.py] => pretrained: True
2024-11-16 17:08:48,629 [trainer.py] => vpt_type: Deep
2024-11-16 17:08:48,629 [trainer.py] => prompt_token_num: 5
2024-11-16 17:08:48,629 [trainer.py] => ffn_num: 64
2024-11-16 17:08:48,629 [trainer.py] => use_diagonal: False
2024-11-16 17:08:48,629 [trainer.py] => recalc_sim: True
2024-11-16 17:08:48,630 [trainer.py] => alpha: 0.1
2024-11-16 17:08:48,630 [trainer.py] => use_init_ptm: False
2024-11-16 17:08:48,630 [trainer.py] => beta: 0
2024-11-16 17:08:48,630 [trainer.py] => use_old_data: False
2024-11-16 17:08:48,630 [trainer.py] => use_reweight: False
2024-11-16 17:08:48,630 [trainer.py] => moni_adam: False
2024-11-16 17:08:48,630 [trainer.py] => adapter_num: -1
2024-11-16 17:08:50,409 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-16 17:08:54,517 [trainer.py] => All params: 87150252
2024-11-16 17:08:54,518 [trainer.py] => Trainable params: 1341696
2024-11-16 17:08:54,520 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 17:08:54,520 [dsease_hoc.py] => Learning on 0-5
2024-11-16 17:16:23,860 [dsease_hoc.py] => Task 0, Epoch 20/20 => Loss 0.080, Train_accy 97.16
2024-11-16 17:16:29,055 [dsease_hoc.py] => Task correct: 100.0
2024-11-16 17:16:29,056 [dsease_hoc.py] => Task acc: 99.6
2024-11-16 17:16:29,084 [trainer.py] => No NME accuracy.
2024-11-16 17:16:29,085 [trainer.py] => CNN: {'total': 99.6, '00-04': 99.6, 'old': 0, 'new': 99.6}
2024-11-16 17:16:29,085 [trainer.py] => CNN top1 curve: [99.6]
2024-11-16 17:16:29,085 [trainer.py] => CNN top5 curve: [100.0]

2024-11-16 17:16:29,085 [trainer.py] => Average Accuracy (CNN): 99.6 

2024-11-16 17:16:29,086 [trainer.py] => All params: 87150252
2024-11-16 17:16:29,087 [trainer.py] => Trainable params: 1189632
2024-11-16 17:16:29,362 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 17:16:29,362 [dsease_hoc.py] => Learning on 5-10
2024-11-16 17:23:58,581 [dsease_hoc.py] => Task 1, Epoch 20/20 => Loss 0.127, Train_accy 96.24
2024-11-16 17:28:14,830 [trainer.py] => model: dsease_hoc
2024-11-16 17:28:14,830 [trainer.py] => prefix:  
2024-11-16 17:28:14,830 [trainer.py] => dataset: cifar224
2024-11-16 17:28:14,830 [trainer.py] => memory_size: 0
2024-11-16 17:28:14,830 [trainer.py] => memory_per_class: 0
2024-11-16 17:28:14,830 [trainer.py] => fixed_memory: False
2024-11-16 17:28:14,830 [trainer.py] => shuffle: True
2024-11-16 17:28:14,831 [trainer.py] => init_cls: 5
2024-11-16 17:28:14,831 [trainer.py] => increment: 5
2024-11-16 17:28:14,831 [trainer.py] => model_name: dsease_hoc
2024-11-16 17:28:14,831 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-16 17:28:14,831 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-16 17:28:14,831 [trainer.py] => seed: 110
2024-11-16 17:28:14,831 [trainer.py] => wandb_log: False
2024-11-16 17:28:14,831 [trainer.py] => test_future: False
2024-11-16 17:28:14,831 [trainer.py] => lambda: 0.3
2024-11-16 17:28:14,831 [trainer.py] => mu: 10
2024-11-16 17:28:14,831 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-16 17:28:14,831 [trainer.py] => hoc_epochs: 5
2024-11-16 17:28:14,831 [trainer.py] => hoc_lr: 0.025
2024-11-16 17:28:14,831 [trainer.py] => init_epochs: 20
2024-11-16 17:28:14,831 [trainer.py] => init_lr: 0.025
2024-11-16 17:28:14,831 [trainer.py] => later_epochs: 20
2024-11-16 17:28:14,831 [trainer.py] => later_lr: 0.025
2024-11-16 17:28:14,831 [trainer.py] => batch_size: 48
2024-11-16 17:28:14,831 [trainer.py] => weight_decay: 0.0005
2024-11-16 17:28:14,831 [trainer.py] => min_lr: 0
2024-11-16 17:28:14,831 [trainer.py] => optimizer: sgd
2024-11-16 17:28:14,832 [trainer.py] => scheduler: cosine
2024-11-16 17:28:14,832 [trainer.py] => pretrained: True
2024-11-16 17:28:14,832 [trainer.py] => vpt_type: Deep
2024-11-16 17:28:14,832 [trainer.py] => prompt_token_num: 5
2024-11-16 17:28:14,832 [trainer.py] => ffn_num: 64
2024-11-16 17:28:14,832 [trainer.py] => use_diagonal: False
2024-11-16 17:28:14,832 [trainer.py] => recalc_sim: True
2024-11-16 17:28:14,832 [trainer.py] => alpha: 0.1
2024-11-16 17:28:14,832 [trainer.py] => use_init_ptm: False
2024-11-16 17:28:14,832 [trainer.py] => beta: 0
2024-11-16 17:28:14,832 [trainer.py] => use_old_data: False
2024-11-16 17:28:14,832 [trainer.py] => use_reweight: False
2024-11-16 17:28:14,832 [trainer.py] => moni_adam: False
2024-11-16 17:28:14,832 [trainer.py] => adapter_num: -1
2024-11-16 17:28:16,487 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-16 17:28:20,493 [trainer.py] => All params: 87150252
2024-11-16 17:28:20,494 [trainer.py] => Trainable params: 1341696
2024-11-16 17:28:20,495 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 17:28:20,495 [dsease_hoc.py] => Learning on 0-5
2024-11-16 17:35:49,189 [dsease_hoc.py] => Task 0, Epoch 20/20 => Loss 0.080, Train_accy 97.16
2024-11-16 17:35:54,200 [dsease_hoc.py] => Task correct: 100.0
2024-11-16 17:35:54,200 [dsease_hoc.py] => Task acc: 99.6
2024-11-16 17:35:54,246 [trainer.py] => No NME accuracy.
2024-11-16 17:35:54,246 [trainer.py] => CNN: {'total': 99.6, '00-04': 99.6, 'old': 0, 'new': 99.6}
2024-11-16 17:35:54,246 [trainer.py] => CNN top1 curve: [99.6]
2024-11-16 17:35:54,246 [trainer.py] => CNN top5 curve: [100.0]

2024-11-16 17:35:54,246 [trainer.py] => Average Accuracy (CNN): 99.6 

2024-11-16 17:35:54,247 [trainer.py] => All params: 87150252
2024-11-16 17:35:54,248 [trainer.py] => Trainable params: 1189632
2024-11-16 17:35:54,542 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 17:35:54,542 [dsease_hoc.py] => Learning on 5-10
2024-11-16 17:43:24,924 [dsease_hoc.py] => Task 1, Epoch 20/20 => Loss 0.127, Train_accy 96.24
2024-11-16 17:46:13,657 [dsease_hoc.py] => Junction Layer Train: Task 1, Epoch 5/5 => Loss 2.113, Train_accy 93.88
2024-11-16 17:46:25,230 [dsease_hoc.py] => Task correct: 70.8
2024-11-16 17:46:25,230 [dsease_hoc.py] => Task acc: 92.4
2024-11-16 17:46:25,260 [trainer.py] => No NME accuracy.
2024-11-16 17:46:25,261 [trainer.py] => CNN: {'total': 70.4, '00-04': 41.6, '05-09': 99.2, 'old': 41.6, 'new': 99.2}
2024-11-16 17:46:25,261 [trainer.py] => CNN top1 curve: [99.6, 70.4]
2024-11-16 17:46:25,261 [trainer.py] => CNN top5 curve: [100.0, 90.8]

2024-11-16 17:46:25,261 [trainer.py] => Average Accuracy (CNN): 85.0 

2024-11-16 17:46:25,261 [trainer.py] => All params: 87226284
2024-11-16 17:46:25,262 [trainer.py] => Trainable params: 1189632
2024-11-16 17:46:25,536 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-16 17:46:25,536 [dsease_hoc.py] => Learning on 10-15
2024-11-16 17:48:49,511 [trainer.py] => model: dsease_hoc
2024-11-16 17:48:49,511 [trainer.py] => prefix:  
2024-11-16 17:48:49,511 [trainer.py] => dataset: cifar224
2024-11-16 17:48:49,511 [trainer.py] => memory_size: 0
2024-11-16 17:48:49,511 [trainer.py] => memory_per_class: 0
2024-11-16 17:48:49,511 [trainer.py] => fixed_memory: False
2024-11-16 17:48:49,511 [trainer.py] => shuffle: True
2024-11-16 17:48:49,511 [trainer.py] => init_cls: 5
2024-11-16 17:48:49,511 [trainer.py] => increment: 5
2024-11-16 17:48:49,511 [trainer.py] => model_name: dsease_hoc
2024-11-16 17:48:49,511 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-16 17:48:49,512 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-16 17:48:49,512 [trainer.py] => seed: 110
2024-11-16 17:48:49,512 [trainer.py] => wandb_log: False
2024-11-16 17:48:49,512 [trainer.py] => test_future: False
2024-11-16 17:48:49,512 [trainer.py] => lambda: 0.1
2024-11-16 17:48:49,512 [trainer.py] => mu: 10
2024-11-16 17:48:49,512 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-16 17:48:49,512 [trainer.py] => hoc_epochs: 3
2024-11-16 17:48:49,512 [trainer.py] => hoc_lr: 0.025
2024-11-16 17:48:49,512 [trainer.py] => init_epochs: 20
2024-11-16 17:48:49,512 [trainer.py] => init_lr: 0.025
2024-11-16 17:48:49,512 [trainer.py] => later_epochs: 20
2024-11-16 17:48:49,512 [trainer.py] => later_lr: 0.025
2024-11-16 17:48:49,512 [trainer.py] => batch_size: 48
2024-11-16 17:48:49,512 [trainer.py] => weight_decay: 0.0005
2024-11-16 17:48:49,512 [trainer.py] => min_lr: 0
2024-11-16 17:48:49,512 [trainer.py] => optimizer: sgd
2024-11-16 17:48:49,512 [trainer.py] => scheduler: cosine
2024-11-16 17:48:49,512 [trainer.py] => pretrained: True
2024-11-16 17:48:49,513 [trainer.py] => vpt_type: Deep
2024-11-16 17:48:49,513 [trainer.py] => prompt_token_num: 5
2024-11-16 17:48:49,513 [trainer.py] => ffn_num: 64
2024-11-16 17:48:49,513 [trainer.py] => use_diagonal: False
2024-11-16 17:48:49,513 [trainer.py] => recalc_sim: True
2024-11-16 17:48:49,513 [trainer.py] => alpha: 0.1
2024-11-16 17:48:49,513 [trainer.py] => use_init_ptm: False
2024-11-16 17:48:49,513 [trainer.py] => beta: 0
2024-11-16 17:48:49,513 [trainer.py] => use_old_data: False
2024-11-16 17:48:49,513 [trainer.py] => use_reweight: False
2024-11-16 17:48:49,513 [trainer.py] => moni_adam: False
2024-11-16 17:48:49,513 [trainer.py] => adapter_num: -1
2024-11-16 17:48:51,181 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-16 17:48:54,735 [trainer.py] => All params: 87150252
2024-11-16 17:48:54,735 [trainer.py] => Trainable params: 1341696
2024-11-16 17:48:54,737 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 17:48:54,737 [dsease_hoc.py] => Learning on 0-5
2024-11-16 17:56:23,254 [dsease_hoc.py] => Task 0, Epoch 20/20 => Loss 0.080, Train_accy 97.16
2024-11-16 17:56:28,296 [dsease_hoc.py] => Task correct: 100.0
2024-11-16 17:56:28,296 [dsease_hoc.py] => Task acc: 99.6
2024-11-16 17:56:28,336 [trainer.py] => No NME accuracy.
2024-11-16 17:56:28,336 [trainer.py] => CNN: {'total': 99.6, '00-04': 99.6, 'old': 0, 'new': 99.6}
2024-11-16 17:56:28,336 [trainer.py] => CNN top1 curve: [99.6]
2024-11-16 17:56:28,336 [trainer.py] => CNN top5 curve: [100.0]

2024-11-16 17:56:28,337 [trainer.py] => Average Accuracy (CNN): 99.6 

2024-11-16 17:56:28,338 [trainer.py] => All params: 87150252
2024-11-16 17:56:28,339 [trainer.py] => Trainable params: 1189632
2024-11-16 17:56:28,595 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 17:56:28,596 [dsease_hoc.py] => Learning on 5-10
2024-11-16 18:03:58,393 [dsease_hoc.py] => Task 1, Epoch 20/20 => Loss 0.127, Train_accy 96.24
2024-11-16 18:05:39,236 [dsease_hoc.py] => Junction Layer Train: Task 1, Epoch 3/3 => Loss 2.303, Train_accy 91.20
2024-11-16 18:05:50,870 [dsease_hoc.py] => Task correct: 93.3
2024-11-16 18:05:50,870 [dsease_hoc.py] => Task acc: 98.3
2024-11-16 18:05:50,902 [trainer.py] => No NME accuracy.
2024-11-16 18:05:50,902 [trainer.py] => CNN: {'total': 92.2, '00-04': 95.0, '05-09': 89.4, 'old': 95.0, 'new': 89.4}
2024-11-16 18:05:50,902 [trainer.py] => CNN top1 curve: [99.6, 92.2]
2024-11-16 18:05:50,902 [trainer.py] => CNN top5 curve: [100.0, 99.8]

2024-11-16 18:05:50,903 [trainer.py] => Average Accuracy (CNN): 95.9 

2024-11-16 18:05:50,903 [trainer.py] => All params: 87226284
2024-11-16 18:05:50,904 [trainer.py] => Trainable params: 1189632
2024-11-16 18:05:51,110 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-16 18:05:51,110 [dsease_hoc.py] => Learning on 10-15
2024-11-16 18:11:49,832 [trainer.py] => model: dsease_hoc
2024-11-16 18:11:49,832 [trainer.py] => prefix:  
2024-11-16 18:11:49,832 [trainer.py] => dataset: cifar224
2024-11-16 18:11:49,832 [trainer.py] => memory_size: 0
2024-11-16 18:11:49,833 [trainer.py] => memory_per_class: 0
2024-11-16 18:11:49,833 [trainer.py] => fixed_memory: False
2024-11-16 18:11:49,833 [trainer.py] => shuffle: True
2024-11-16 18:11:49,833 [trainer.py] => init_cls: 5
2024-11-16 18:11:49,833 [trainer.py] => increment: 5
2024-11-16 18:11:49,833 [trainer.py] => model_name: dsease_hoc
2024-11-16 18:11:49,833 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-16 18:11:49,833 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-16 18:11:49,833 [trainer.py] => seed: 110
2024-11-16 18:11:49,833 [trainer.py] => wandb_log: False
2024-11-16 18:11:49,833 [trainer.py] => test_future: False
2024-11-16 18:11:49,833 [trainer.py] => lambda: 0.1
2024-11-16 18:11:49,833 [trainer.py] => mu: 10
2024-11-16 18:11:49,833 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-16 18:11:49,833 [trainer.py] => hoc_epochs: 3
2024-11-16 18:11:49,833 [trainer.py] => hoc_lr: 0.025
2024-11-16 18:11:49,833 [trainer.py] => init_epochs: 20
2024-11-16 18:11:49,833 [trainer.py] => init_lr: 0.025
2024-11-16 18:11:49,833 [trainer.py] => later_epochs: 20
2024-11-16 18:11:49,833 [trainer.py] => later_lr: 0.025
2024-11-16 18:11:49,834 [trainer.py] => batch_size: 48
2024-11-16 18:11:49,834 [trainer.py] => weight_decay: 0.0005
2024-11-16 18:11:49,834 [trainer.py] => min_lr: 0
2024-11-16 18:11:49,834 [trainer.py] => optimizer: sgd
2024-11-16 18:11:49,834 [trainer.py] => scheduler: cosine
2024-11-16 18:11:49,834 [trainer.py] => pretrained: True
2024-11-16 18:11:49,834 [trainer.py] => vpt_type: Deep
2024-11-16 18:11:49,834 [trainer.py] => prompt_token_num: 5
2024-11-16 18:11:49,834 [trainer.py] => ffn_num: 64
2024-11-16 18:11:49,834 [trainer.py] => use_diagonal: False
2024-11-16 18:11:49,834 [trainer.py] => recalc_sim: True
2024-11-16 18:11:49,834 [trainer.py] => alpha: 0.1
2024-11-16 18:11:49,834 [trainer.py] => use_init_ptm: False
2024-11-16 18:11:49,834 [trainer.py] => beta: 0
2024-11-16 18:11:49,834 [trainer.py] => use_old_data: False
2024-11-16 18:11:49,834 [trainer.py] => use_reweight: False
2024-11-16 18:11:49,834 [trainer.py] => moni_adam: False
2024-11-16 18:11:49,834 [trainer.py] => adapter_num: -1
2024-11-16 18:11:51,494 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-16 18:12:05,267 [trainer.py] => model: dsease_hoc
2024-11-16 18:12:05,268 [trainer.py] => prefix:  
2024-11-16 18:12:05,268 [trainer.py] => dataset: cifar224
2024-11-16 18:12:05,268 [trainer.py] => memory_size: 0
2024-11-16 18:12:05,268 [trainer.py] => memory_per_class: 0
2024-11-16 18:12:05,268 [trainer.py] => fixed_memory: False
2024-11-16 18:12:05,268 [trainer.py] => shuffle: True
2024-11-16 18:12:05,268 [trainer.py] => init_cls: 5
2024-11-16 18:12:05,269 [trainer.py] => increment: 5
2024-11-16 18:12:05,269 [trainer.py] => model_name: dsease_hoc
2024-11-16 18:12:05,269 [trainer.py] => backbone_type: vit_base_patch16_224_ease
2024-11-16 18:12:05,269 [trainer.py] => device: [device(type='cuda', index=1)]
2024-11-16 18:12:05,269 [trainer.py] => seed: 110
2024-11-16 18:12:05,269 [trainer.py] => wandb_log: True
2024-11-16 18:12:05,270 [trainer.py] => test_future: False
2024-11-16 18:12:05,270 [trainer.py] => lambda: 0.1
2024-11-16 18:12:05,270 [trainer.py] => mu: 10
2024-11-16 18:12:05,270 [trainer.py] => model_checkpoint_path: logs/dsease_hoc/model_checkpoint.pth
2024-11-16 18:12:05,270 [trainer.py] => hoc_epochs: 3
2024-11-16 18:12:05,270 [trainer.py] => hoc_lr: 0.025
2024-11-16 18:12:05,270 [trainer.py] => init_epochs: 20
2024-11-16 18:12:05,271 [trainer.py] => init_lr: 0.025
2024-11-16 18:12:05,271 [trainer.py] => later_epochs: 20
2024-11-16 18:12:05,271 [trainer.py] => later_lr: 0.025
2024-11-16 18:12:05,271 [trainer.py] => batch_size: 48
2024-11-16 18:12:05,271 [trainer.py] => weight_decay: 0.0005
2024-11-16 18:12:05,271 [trainer.py] => min_lr: 0
2024-11-16 18:12:05,271 [trainer.py] => optimizer: sgd
2024-11-16 18:12:05,272 [trainer.py] => scheduler: cosine
2024-11-16 18:12:05,272 [trainer.py] => pretrained: True
2024-11-16 18:12:05,272 [trainer.py] => vpt_type: Deep
2024-11-16 18:12:05,272 [trainer.py] => prompt_token_num: 5
2024-11-16 18:12:05,272 [trainer.py] => ffn_num: 64
2024-11-16 18:12:05,272 [trainer.py] => use_diagonal: False
2024-11-16 18:12:05,272 [trainer.py] => recalc_sim: True
2024-11-16 18:12:05,272 [trainer.py] => alpha: 0.1
2024-11-16 18:12:05,273 [trainer.py] => use_init_ptm: False
2024-11-16 18:12:05,273 [trainer.py] => beta: 0
2024-11-16 18:12:05,273 [trainer.py] => use_old_data: False
2024-11-16 18:12:05,273 [trainer.py] => use_reweight: False
2024-11-16 18:12:05,273 [trainer.py] => moni_adam: False
2024-11-16 18:12:05,273 [trainer.py] => adapter_num: -1
2024-11-16 18:12:07,086 [data_manager.py] => [14, 88, 71, 30, 75, 63, 24, 87, 98, 19, 33, 6, 3, 16, 39, 17, 53, 55, 84, 62, 50, 92, 7, 22, 69, 85, 28, 43, 44, 78, 86, 10, 57, 27, 11, 68, 97, 35, 58, 82, 83, 60, 90, 20, 38, 45, 54, 79, 72, 36, 76, 25, 65, 94, 56, 74, 12, 59, 95, 52, 46, 29, 18, 9, 13, 77, 40, 67, 37, 49, 64, 4, 91, 51, 2, 34, 96, 48, 31, 21, 66, 73, 1, 23, 42, 41, 26, 81, 32, 5, 8, 70, 93, 80, 99, 47, 89, 15, 61, 0]
2024-11-16 18:12:11,472 [trainer.py] => All params: 87150252
2024-11-16 18:12:11,474 [trainer.py] => Trainable params: 1341696
2024-11-16 18:12:11,476 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 18:12:11,476 [dsease_hoc.py] => Learning on 0-5
2024-11-16 18:19:39,430 [dsease_hoc.py] => Task 0, Epoch 20/20 => Loss 0.080, Train_accy 97.16
2024-11-16 18:19:44,434 [dsease_hoc.py] => Task correct: 100.0
2024-11-16 18:19:44,435 [dsease_hoc.py] => Task acc: 99.6
2024-11-16 18:19:44,476 [trainer.py] => No NME accuracy.
2024-11-16 18:19:44,476 [trainer.py] => CNN: {'total': 99.6, '00-04': 99.6, 'old': 0, 'new': 99.6}
2024-11-16 18:19:44,476 [trainer.py] => CNN top1 curve: [99.6]
2024-11-16 18:19:44,476 [trainer.py] => CNN top5 curve: [100.0]

2024-11-16 18:19:44,477 [trainer.py] => Average Accuracy (CNN): 99.6 

2024-11-16 18:19:44,479 [trainer.py] => All params: 87150252
2024-11-16 18:19:44,480 [trainer.py] => Trainable params: 1189632
2024-11-16 18:19:44,782 [dsease_hoc.py] => Total trainable params: 1341696
2024-11-16 18:19:44,783 [dsease_hoc.py] => Learning on 5-10
2024-11-16 18:27:14,244 [dsease_hoc.py] => Task 1, Epoch 20/20 => Loss 0.127, Train_accy 96.24
2024-11-16 18:28:55,368 [dsease_hoc.py] => Junction Layer Train: Task 1, Epoch 3/3 => Loss 2.249, Train_accy 90.44
2024-11-16 18:29:07,026 [dsease_hoc.py] => Task correct: 94.2
2024-11-16 18:29:07,027 [dsease_hoc.py] => Task acc: 98.8
2024-11-16 18:29:07,079 [trainer.py] => No NME accuracy.
2024-11-16 18:29:07,079 [trainer.py] => CNN: {'total': 93.4, '00-04': 96.2, '05-09': 90.6, 'old': 96.2, 'new': 90.6}
2024-11-16 18:29:07,079 [trainer.py] => CNN top1 curve: [99.6, 93.4]
2024-11-16 18:29:07,080 [trainer.py] => CNN top5 curve: [100.0, 99.9]

2024-11-16 18:29:07,080 [trainer.py] => Average Accuracy (CNN): 96.5 

2024-11-16 18:29:07,083 [trainer.py] => All params: 87226284
2024-11-16 18:29:07,084 [trainer.py] => Trainable params: 1189632
2024-11-16 18:29:07,409 [dsease_hoc.py] => Total trainable params: 1417728
2024-11-16 18:29:07,409 [dsease_hoc.py] => Learning on 10-15
2024-11-16 18:36:38,234 [dsease_hoc.py] => Task 2, Epoch 20/20 => Loss 0.109, Train_accy 96.36
2024-11-16 18:39:23,430 [dsease_hoc.py] => Junction Layer Train: Task 2, Epoch 3/3 => Loss -1.262, Train_accy 83.92
2024-11-16 18:39:46,031 [dsease_hoc.py] => Task correct: 68.73333333333333
2024-11-16 18:39:46,031 [dsease_hoc.py] => Task acc: 97.6
2024-11-16 18:39:46,073 [trainer.py] => No NME accuracy.
2024-11-16 18:39:46,074 [trainer.py] => CNN: {'total': 67.33, '00-04': 92.8, '05-09': 36.4, '10-14': 72.8, 'old': 64.6, 'new': 72.8}
2024-11-16 18:39:46,074 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33]
2024-11-16 18:39:46,074 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73]

2024-11-16 18:39:46,074 [trainer.py] => Average Accuracy (CNN): 86.77666666666666 

2024-11-16 18:39:46,076 [trainer.py] => All params: 87302316
2024-11-16 18:39:46,078 [trainer.py] => Trainable params: 1189632
2024-11-16 18:39:46,358 [dsease_hoc.py] => Total trainable params: 1493760
2024-11-16 18:39:46,358 [dsease_hoc.py] => Learning on 15-20
2024-11-16 18:47:16,801 [dsease_hoc.py] => Task 3, Epoch 20/20 => Loss 0.087, Train_accy 96.92
2024-11-16 18:51:06,302 [dsease_hoc.py] => Junction Layer Train: Task 3, Epoch 3/3 => Loss -2.758, Train_accy 85.96
2024-11-16 18:51:44,061 [dsease_hoc.py] => Task correct: 55.9
2024-11-16 18:51:44,061 [dsease_hoc.py] => Task acc: 94.35
2024-11-16 18:51:44,101 [trainer.py] => No NME accuracy.
2024-11-16 18:51:44,101 [trainer.py] => CNN: {'total': 54.25, '00-04': 81.0, '05-09': 11.8, '10-14': 30.6, '15-19': 93.6, 'old': 41.13, 'new': 93.6}
2024-11-16 18:51:44,102 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25]
2024-11-16 18:51:44,102 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05]

2024-11-16 18:51:44,102 [trainer.py] => Average Accuracy (CNN): 78.645 

2024-11-16 18:51:44,104 [trainer.py] => All params: 87378348
2024-11-16 18:51:44,105 [trainer.py] => Trainable params: 1189632
2024-11-16 18:51:44,408 [dsease_hoc.py] => Total trainable params: 1569792
2024-11-16 18:51:44,408 [dsease_hoc.py] => Learning on 20-25
2024-11-16 18:59:14,103 [dsease_hoc.py] => Task 4, Epoch 20/20 => Loss 0.111, Train_accy 96.56
2024-11-16 19:04:07,954 [dsease_hoc.py] => Junction Layer Train: Task 4, Epoch 3/3 => Loss -3.046, Train_accy 81.84
2024-11-16 19:05:05,372 [dsease_hoc.py] => Task correct: 43.68
2024-11-16 19:05:05,373 [dsease_hoc.py] => Task acc: 93.68
2024-11-16 19:05:05,418 [trainer.py] => No NME accuracy.
2024-11-16 19:05:05,418 [trainer.py] => CNN: {'total': 43.24, '00-04': 69.0, '05-09': 9.0, '10-14': 36.4, '15-19': 36.2, '20-24': 65.6, 'old': 37.65, 'new': 65.6}
2024-11-16 19:05:05,418 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24]
2024-11-16 19:05:05,418 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08]

2024-11-16 19:05:05,419 [trainer.py] => Average Accuracy (CNN): 71.564 

2024-11-16 19:05:05,421 [trainer.py] => All params: 87454380
2024-11-16 19:05:05,422 [trainer.py] => Trainable params: 1189632
2024-11-16 19:05:05,740 [dsease_hoc.py] => Total trainable params: 1645824
2024-11-16 19:05:05,740 [dsease_hoc.py] => Learning on 25-30
2024-11-16 19:12:35,326 [dsease_hoc.py] => Task 5, Epoch 20/20 => Loss 0.144, Train_accy 94.96
2024-11-16 19:18:33,851 [dsease_hoc.py] => Junction Layer Train: Task 5, Epoch 3/3 => Loss -3.114, Train_accy 80.08
2024-11-16 19:19:55,397 [dsease_hoc.py] => Task correct: 45.06666666666667
2024-11-16 19:19:55,398 [dsease_hoc.py] => Task acc: 92.03333333333333
2024-11-16 19:19:55,442 [trainer.py] => No NME accuracy.
2024-11-16 19:19:55,442 [trainer.py] => CNN: {'total': 43.7, '00-04': 60.4, '05-09': 19.6, '10-14': 27.2, '15-19': 32.8, '20-24': 32.4, '25-29': 89.8, 'old': 34.48, 'new': 89.8}
2024-11-16 19:19:55,442 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7]
2024-11-16 19:19:55,443 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7]

2024-11-16 19:19:55,443 [trainer.py] => Average Accuracy (CNN): 66.92 

2024-11-16 19:19:55,445 [trainer.py] => All params: 87530412
2024-11-16 19:19:55,447 [trainer.py] => Trainable params: 1189632
2024-11-16 19:19:55,806 [dsease_hoc.py] => Total trainable params: 1721856
2024-11-16 19:19:55,806 [dsease_hoc.py] => Learning on 30-35
2024-11-16 19:27:26,333 [dsease_hoc.py] => Task 6, Epoch 20/20 => Loss 0.159, Train_accy 94.40
2024-11-16 19:34:29,561 [dsease_hoc.py] => Junction Layer Train: Task 6, Epoch 3/3 => Loss -3.187, Train_accy 84.16
2024-11-16 19:36:18,900 [dsease_hoc.py] => Task correct: 25.228571428571428
2024-11-16 19:36:18,901 [dsease_hoc.py] => Task acc: 90.74285714285715
2024-11-16 19:36:18,948 [trainer.py] => No NME accuracy.
2024-11-16 19:36:18,948 [trainer.py] => CNN: {'total': 22.77, '00-04': 32.4, '05-09': 2.8, '10-14': 20.6, '15-19': 10.8, '20-24': 17.2, '25-29': 18.6, '30-34': 57.0, 'old': 17.07, 'new': 57.0}
2024-11-16 19:36:18,949 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77]
2024-11-16 19:36:18,949 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4]

2024-11-16 19:36:18,949 [trainer.py] => Average Accuracy (CNN): 60.61285714285714 

2024-11-16 19:36:18,951 [trainer.py] => All params: 87606444
2024-11-16 19:36:18,952 [trainer.py] => Trainable params: 1189632
2024-11-16 19:36:19,527 [dsease_hoc.py] => Total trainable params: 1797888
2024-11-16 19:36:19,528 [dsease_hoc.py] => Learning on 35-40
2024-11-16 19:43:51,803 [dsease_hoc.py] => Task 7, Epoch 20/20 => Loss 0.077, Train_accy 97.64
2024-11-16 19:52:00,438 [dsease_hoc.py] => Junction Layer Train: Task 7, Epoch 3/3 => Loss -3.522, Train_accy 88.16
2024-11-16 19:54:22,578 [dsease_hoc.py] => Task correct: 27.9
2024-11-16 19:54:22,579 [dsease_hoc.py] => Task acc: 92.225
2024-11-16 19:54:22,620 [trainer.py] => No NME accuracy.
2024-11-16 19:54:22,620 [trainer.py] => CNN: {'total': 27.65, '00-04': 46.8, '05-09': 1.0, '10-14': 11.6, '15-19': 14.2, '20-24': 17.6, '25-29': 21.2, '30-34': 19.4, '35-39': 89.4, 'old': 18.83, 'new': 89.4}
2024-11-16 19:54:22,620 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65]
2024-11-16 19:54:22,621 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28]

2024-11-16 19:54:22,621 [trainer.py] => Average Accuracy (CNN): 56.49249999999999 

2024-11-16 19:54:22,623 [trainer.py] => All params: 87682476
2024-11-16 19:54:22,624 [trainer.py] => Trainable params: 1189632
2024-11-16 19:54:22,970 [dsease_hoc.py] => Total trainable params: 1873920
2024-11-16 19:54:22,971 [dsease_hoc.py] => Learning on 40-45
2024-11-16 20:01:55,628 [dsease_hoc.py] => Task 8, Epoch 20/20 => Loss 0.097, Train_accy 97.48
2024-11-16 20:11:08,889 [dsease_hoc.py] => Junction Layer Train: Task 8, Epoch 3/3 => Loss -3.811, Train_accy 88.40
2024-11-16 20:14:07,452 [dsease_hoc.py] => Task correct: 28.377777777777776
2024-11-16 20:14:07,453 [dsease_hoc.py] => Task acc: 91.62222222222222
2024-11-16 20:14:07,484 [trainer.py] => No NME accuracy.
2024-11-16 20:14:07,484 [trainer.py] => CNN: {'total': 28.13, '00-04': 33.0, '05-09': 3.6, '10-14': 15.2, '15-19': 5.8, '20-24': 27.6, '25-29': 30.0, '30-34': 14.0, '35-39': 31.4, '40-44': 92.6, 'old': 20.08, 'new': 92.6}
2024-11-16 20:14:07,484 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65, 28.13]
2024-11-16 20:14:07,484 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28, 62.44]

2024-11-16 20:14:07,484 [trainer.py] => Average Accuracy (CNN): 53.341111111111104 

2024-11-16 20:14:07,486 [trainer.py] => All params: 87758508
2024-11-16 20:14:07,486 [trainer.py] => Trainable params: 1189632
2024-11-16 20:14:07,842 [dsease_hoc.py] => Total trainable params: 1949952
2024-11-16 20:14:07,842 [dsease_hoc.py] => Learning on 45-50
2024-11-16 20:21:39,073 [dsease_hoc.py] => Task 9, Epoch 20/20 => Loss 0.137, Train_accy 95.04
2024-11-16 20:31:56,421 [dsease_hoc.py] => Junction Layer Train: Task 9, Epoch 3/3 => Loss -2.824, Train_accy 85.96
2024-11-16 20:35:35,919 [dsease_hoc.py] => Task correct: 20.98
2024-11-16 20:35:35,919 [dsease_hoc.py] => Task acc: 91.56
2024-11-16 20:35:35,949 [trainer.py] => No NME accuracy.
2024-11-16 20:35:35,949 [trainer.py] => CNN: {'total': 20.48, '00-04': 9.6, '05-09': 0.4, '10-14': 17.6, '15-19': 3.0, '20-24': 7.0, '25-29': 18.6, '30-34': 5.8, '35-39': 19.0, '40-44': 35.2, '45-49': 88.6, 'old': 12.91, 'new': 88.6}
2024-11-16 20:35:35,949 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65, 28.13, 20.48]
2024-11-16 20:35:35,949 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28, 62.44, 59.2]

2024-11-16 20:35:35,950 [trainer.py] => Average Accuracy (CNN): 50.05499999999999 

2024-11-16 20:35:35,951 [trainer.py] => All params: 87834540
2024-11-16 20:35:35,952 [trainer.py] => Trainable params: 1189632
2024-11-16 20:35:36,293 [dsease_hoc.py] => Total trainable params: 2025984
2024-11-16 20:35:36,293 [dsease_hoc.py] => Learning on 50-55
2024-11-16 20:43:07,414 [dsease_hoc.py] => Task 10, Epoch 20/20 => Loss 0.132, Train_accy 95.48
2024-11-16 20:54:28,353 [dsease_hoc.py] => Junction Layer Train: Task 10, Epoch 3/3 => Loss -2.528, Train_accy 88.00
2024-11-16 20:58:53,415 [dsease_hoc.py] => Task correct: 20.581818181818182
2024-11-16 20:58:53,416 [dsease_hoc.py] => Task acc: 88.9090909090909
2024-11-16 20:58:53,446 [trainer.py] => No NME accuracy.
2024-11-16 20:58:53,446 [trainer.py] => CNN: {'total': 20.0, '00-04': 18.0, '05-09': 2.2, '10-14': 18.0, '15-19': 0.2, '20-24': 11.8, '25-29': 25.2, '30-34': 5.8, '35-39': 11.2, '40-44': 7.8, '45-49': 33.8, '50-54': 86.0, 'old': 13.4, 'new': 86.0}
2024-11-16 20:58:53,446 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65, 28.13, 20.48, 20.0]
2024-11-16 20:58:53,446 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28, 62.44, 59.2, 56.36]

2024-11-16 20:58:53,447 [trainer.py] => Average Accuracy (CNN): 47.32272727272727 

2024-11-16 20:58:53,448 [trainer.py] => All params: 87910572
2024-11-16 20:58:53,449 [trainer.py] => Trainable params: 1189632
2024-11-16 20:58:53,795 [dsease_hoc.py] => Total trainable params: 2102016
2024-11-16 20:58:53,796 [dsease_hoc.py] => Learning on 55-60
2024-11-16 21:06:25,077 [dsease_hoc.py] => Task 11, Epoch 20/20 => Loss 0.204, Train_accy 92.12
2024-11-16 21:18:51,374 [dsease_hoc.py] => Junction Layer Train: Task 11, Epoch 3/3 => Loss -1.550, Train_accy 80.24
2024-11-16 21:24:06,443 [dsease_hoc.py] => Task correct: 16.25
2024-11-16 21:24:06,444 [dsease_hoc.py] => Task acc: 86.51666666666667
2024-11-16 21:24:06,475 [trainer.py] => No NME accuracy.
2024-11-16 21:24:06,475 [trainer.py] => CNN: {'total': 15.37, '00-04': 7.8, '05-09': 0.0, '10-14': 16.2, '15-19': 0.0, '20-24': 5.8, '25-29': 4.2, '30-34': 2.4, '35-39': 5.2, '40-44': 1.0, '45-49': 17.0, '50-54': 36.8, '55-59': 88.0, 'old': 8.76, 'new': 88.0}
2024-11-16 21:24:06,476 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65, 28.13, 20.48, 20.0, 15.37]
2024-11-16 21:24:06,476 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28, 62.44, 59.2, 56.36, 52.73]

2024-11-16 21:24:06,476 [trainer.py] => Average Accuracy (CNN): 44.66 

2024-11-16 21:24:06,477 [trainer.py] => All params: 87986604
2024-11-16 21:24:06,478 [trainer.py] => Trainable params: 1189632
2024-11-16 21:24:06,881 [dsease_hoc.py] => Total trainable params: 2178048
2024-11-16 21:24:06,882 [dsease_hoc.py] => Learning on 60-65
2024-11-16 21:31:38,156 [dsease_hoc.py] => Task 12, Epoch 20/20 => Loss 0.121, Train_accy 95.60
2024-11-16 21:45:10,186 [dsease_hoc.py] => Junction Layer Train: Task 12, Epoch 3/3 => Loss -3.187, Train_accy 87.40
2024-11-16 21:51:19,170 [dsease_hoc.py] => Task correct: 20.046153846153846
2024-11-16 21:51:19,171 [dsease_hoc.py] => Task acc: 88.43076923076923
2024-11-16 21:51:19,204 [trainer.py] => No NME accuracy.
2024-11-16 21:51:19,204 [trainer.py] => CNN: {'total': 19.51, '00-04': 18.8, '05-09': 0.2, '10-14': 10.4, '15-19': 2.6, '20-24': 7.2, '25-29': 7.8, '30-34': 11.0, '35-39': 8.0, '40-44': 4.2, '45-49': 23.8, '50-54': 12.2, '55-59': 51.2, '60-64': 96.2, 'old': 13.12, 'new': 96.2}
2024-11-16 21:51:19,204 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65, 28.13, 20.48, 20.0, 15.37, 19.51]
2024-11-16 21:51:19,204 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28, 62.44, 59.2, 56.36, 52.73, 53.83]

2024-11-16 21:51:19,204 [trainer.py] => Average Accuracy (CNN): 42.72538461538461 

2024-11-16 21:51:19,206 [trainer.py] => All params: 88062636
2024-11-16 21:51:19,206 [trainer.py] => Trainable params: 1189632
2024-11-16 21:51:19,615 [dsease_hoc.py] => Total trainable params: 2254080
2024-11-16 21:51:19,615 [dsease_hoc.py] => Learning on 65-70
2024-11-16 21:58:49,744 [dsease_hoc.py] => Task 13, Epoch 20/20 => Loss 0.122, Train_accy 95.68
2024-11-16 22:13:23,914 [dsease_hoc.py] => Junction Layer Train: Task 13, Epoch 3/3 => Loss -2.745, Train_accy 87.64
2024-11-16 22:20:29,692 [dsease_hoc.py] => Task correct: 20.9
2024-11-16 22:20:29,693 [dsease_hoc.py] => Task acc: 87.67142857142858
2024-11-16 22:20:29,735 [trainer.py] => No NME accuracy.
2024-11-16 22:20:29,735 [trainer.py] => CNN: {'total': 20.51, '00-04': 9.8, '05-09': 0.2, '10-14': 8.6, '15-19': 2.2, '20-24': 6.2, '25-29': 16.2, '30-34': 6.8, '35-39': 16.0, '40-44': 17.2, '45-49': 23.6, '50-54': 21.2, '55-59': 31.0, '60-64': 30.8, '65-69': 97.4, 'old': 14.6, 'new': 97.4}
2024-11-16 22:20:29,735 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65, 28.13, 20.48, 20.0, 15.37, 19.51, 20.51]
2024-11-16 22:20:29,735 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28, 62.44, 59.2, 56.36, 52.73, 53.83, 55.1]

2024-11-16 22:20:29,736 [trainer.py] => Average Accuracy (CNN): 41.138571428571424 

2024-11-16 22:20:29,738 [trainer.py] => All params: 88138668
2024-11-16 22:20:29,739 [trainer.py] => Trainable params: 1189632
2024-11-16 22:20:30,154 [dsease_hoc.py] => Total trainable params: 2330112
2024-11-16 22:20:30,154 [dsease_hoc.py] => Learning on 70-75
2024-11-16 22:27:58,801 [dsease_hoc.py] => Task 14, Epoch 20/20 => Loss 0.194, Train_accy 92.40
2024-11-16 22:43:36,571 [dsease_hoc.py] => Junction Layer Train: Task 14, Epoch 3/3 => Loss -2.217, Train_accy 88.00
2024-11-16 22:51:44,643 [dsease_hoc.py] => Task correct: 24.14666666666667
2024-11-16 22:51:44,643 [dsease_hoc.py] => Task acc: 86.89333333333333
2024-11-16 22:51:44,686 [trainer.py] => No NME accuracy.
2024-11-16 22:51:44,686 [trainer.py] => CNN: {'total': 23.77, '00-04': 8.0, '05-09': 4.4, '10-14': 10.8, '15-19': 0.8, '20-24': 4.8, '25-29': 8.8, '30-34': 7.8, '35-39': 13.0, '40-44': 24.8, '45-49': 30.0, '50-54': 27.6, '55-59': 36.8, '60-64': 19.2, '65-69': 65.2, '70-74': 94.6, 'old': 18.71, 'new': 94.6}
2024-11-16 22:51:44,686 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65, 28.13, 20.48, 20.0, 15.37, 19.51, 20.51, 23.77]
2024-11-16 22:51:44,687 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28, 62.44, 59.2, 56.36, 52.73, 53.83, 55.1, 54.73]

2024-11-16 22:51:44,687 [trainer.py] => Average Accuracy (CNN): 39.980666666666664 

2024-11-16 22:51:44,689 [trainer.py] => All params: 88214700
2024-11-16 22:51:44,690 [trainer.py] => Trainable params: 1189632
2024-11-16 22:51:45,107 [dsease_hoc.py] => Total trainable params: 2406144
2024-11-16 22:51:45,107 [dsease_hoc.py] => Learning on 75-80
2024-11-16 22:59:14,074 [dsease_hoc.py] => Task 15, Epoch 20/20 => Loss 0.121, Train_accy 96.00
2024-11-16 23:15:57,814 [dsease_hoc.py] => Junction Layer Train: Task 15, Epoch 3/3 => Loss -2.713, Train_accy 90.32
2024-11-16 23:25:13,742 [dsease_hoc.py] => Task correct: 22.625
2024-11-16 23:25:13,743 [dsease_hoc.py] => Task acc: 85.575
2024-11-16 23:25:13,786 [trainer.py] => No NME accuracy.
2024-11-16 23:25:13,786 [trainer.py] => CNN: {'total': 22.31, '00-04': 12.4, '05-09': 5.0, '10-14': 4.6, '15-19': 4.4, '20-24': 4.6, '25-29': 4.4, '30-34': 10.4, '35-39': 17.8, '40-44': 22.0, '45-49': 20.4, '50-54': 19.6, '55-59': 19.8, '60-64': 14.0, '65-69': 37.2, '70-74': 67.4, '75-79': 93.0, 'old': 17.6, 'new': 93.0}
2024-11-16 23:25:13,786 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65, 28.13, 20.48, 20.0, 15.37, 19.51, 20.51, 23.77, 22.31]
2024-11-16 23:25:13,787 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28, 62.44, 59.2, 56.36, 52.73, 53.83, 55.1, 54.73, 53.28]

2024-11-16 23:25:13,787 [trainer.py] => Average Accuracy (CNN): 38.87624999999999 

2024-11-16 23:25:13,789 [trainer.py] => All params: 88290732
2024-11-16 23:25:13,790 [trainer.py] => Trainable params: 1189632
2024-11-16 23:25:14,401 [dsease_hoc.py] => Total trainable params: 2482176
2024-11-16 23:25:14,401 [dsease_hoc.py] => Learning on 80-85
2024-11-16 23:32:43,974 [dsease_hoc.py] => Task 16, Epoch 20/20 => Loss 0.106, Train_accy 95.60
2024-11-16 23:50:31,841 [dsease_hoc.py] => Junction Layer Train: Task 16, Epoch 3/3 => Loss -2.517, Train_accy 90.44
2024-11-17 00:01:00,036 [dsease_hoc.py] => Task correct: 17.341176470588234
2024-11-17 00:01:00,036 [dsease_hoc.py] => Task acc: 85.43529411764706
2024-11-17 00:01:00,081 [trainer.py] => No NME accuracy.
2024-11-17 00:01:00,081 [trainer.py] => CNN: {'total': 17.07, '00-04': 1.4, '05-09': 0.0, '10-14': 1.0, '15-19': 2.0, '20-24': 7.6, '25-29': 4.4, '30-34': 11.2, '35-39': 15.8, '40-44': 14.2, '45-49': 12.8, '50-54': 22.6, '55-59': 7.8, '60-64': 17.8, '65-69': 24.8, '70-74': 22.0, '75-79': 29.6, '80-84': 95.2, 'old': 12.19, 'new': 95.2}
2024-11-17 00:01:00,082 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65, 28.13, 20.48, 20.0, 15.37, 19.51, 20.51, 23.77, 22.31, 17.07]
2024-11-17 00:01:00,082 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28, 62.44, 59.2, 56.36, 52.73, 53.83, 55.1, 54.73, 53.28, 50.65]

2024-11-17 00:01:00,082 [trainer.py] => Average Accuracy (CNN): 37.5935294117647 

2024-11-17 00:01:00,084 [trainer.py] => All params: 88366764
2024-11-17 00:01:00,086 [trainer.py] => Trainable params: 1189632
2024-11-17 00:01:00,536 [dsease_hoc.py] => Total trainable params: 2558208
2024-11-17 00:01:00,537 [dsease_hoc.py] => Learning on 85-90
2024-11-17 00:08:30,401 [dsease_hoc.py] => Task 17, Epoch 20/20 => Loss 0.130, Train_accy 95.24
2024-11-17 00:27:24,749 [dsease_hoc.py] => Junction Layer Train: Task 17, Epoch 3/3 => Loss -2.520, Train_accy 88.84
2024-11-17 00:39:07,894 [dsease_hoc.py] => Task correct: 17.233333333333334
2024-11-17 00:39:07,895 [dsease_hoc.py] => Task acc: 84.93333333333334
2024-11-17 00:39:07,928 [trainer.py] => No NME accuracy.
2024-11-17 00:39:07,928 [trainer.py] => CNN: {'total': 16.96, '00-04': 2.8, '05-09': 4.0, '10-14': 0.6, '15-19': 2.0, '20-24': 5.6, '25-29': 2.0, '30-34': 2.6, '35-39': 24.8, '40-44': 6.4, '45-49': 18.2, '50-54': 3.4, '55-59': 7.0, '60-64': 11.4, '65-69': 12.0, '70-74': 28.2, '75-79': 15.0, '80-84': 63.6, '85-89': 95.6, 'old': 12.33, 'new': 95.6}
2024-11-17 00:39:07,928 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65, 28.13, 20.48, 20.0, 15.37, 19.51, 20.51, 23.77, 22.31, 17.07, 16.96]
2024-11-17 00:39:07,928 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28, 62.44, 59.2, 56.36, 52.73, 53.83, 55.1, 54.73, 53.28, 50.65, 50.0]

2024-11-17 00:39:07,929 [trainer.py] => Average Accuracy (CNN): 36.44722222222222 

2024-11-17 00:39:07,930 [trainer.py] => All params: 88442796
2024-11-17 00:39:07,930 [trainer.py] => Trainable params: 1189632
2024-11-17 00:39:08,421 [dsease_hoc.py] => Total trainable params: 2634240
2024-11-17 00:39:08,421 [dsease_hoc.py] => Learning on 90-95
2024-11-17 00:46:38,788 [dsease_hoc.py] => Task 18, Epoch 20/20 => Loss 0.123, Train_accy 96.00
2024-11-17 01:06:35,504 [dsease_hoc.py] => Junction Layer Train: Task 18, Epoch 3/3 => Loss -2.667, Train_accy 89.36
2024-11-17 01:19:37,061 [dsease_hoc.py] => Task correct: 15.08421052631579
2024-11-17 01:19:37,062 [dsease_hoc.py] => Task acc: 85.30526315789474
2024-11-17 01:19:37,093 [trainer.py] => No NME accuracy.
2024-11-17 01:19:37,093 [trainer.py] => CNN: {'total': 14.77, '00-04': 5.8, '05-09': 0.0, '10-14': 2.0, '15-19': 3.6, '20-24': 7.0, '25-29': 2.0, '30-34': 10.0, '35-39': 16.0, '40-44': 6.0, '45-49': 4.0, '50-54': 2.4, '55-59': 6.8, '60-64': 4.0, '65-69': 11.0, '70-74': 11.2, '75-79': 17.6, '80-84': 34.6, '85-89': 42.4, '90-94': 94.2, 'old': 10.36, 'new': 94.2}
2024-11-17 01:19:37,093 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65, 28.13, 20.48, 20.0, 15.37, 19.51, 20.51, 23.77, 22.31, 17.07, 16.96, 14.77]
2024-11-17 01:19:37,093 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28, 62.44, 59.2, 56.36, 52.73, 53.83, 55.1, 54.73, 53.28, 50.65, 50.0, 48.99]

2024-11-17 01:19:37,094 [trainer.py] => Average Accuracy (CNN): 35.30631578947368 

2024-11-17 01:19:37,095 [trainer.py] => All params: 88518828
2024-11-17 01:19:37,096 [trainer.py] => Trainable params: 1189632
2024-11-17 01:19:37,588 [dsease_hoc.py] => Total trainable params: 2710272
2024-11-17 01:19:37,588 [dsease_hoc.py] => Learning on 95-100
2024-11-17 01:27:07,271 [dsease_hoc.py] => Task 19, Epoch 20/20 => Loss 0.078, Train_accy 97.48
2024-11-17 01:48:08,777 [dsease_hoc.py] => Junction Layer Train: Task 19, Epoch 3/3 => Loss -2.956, Train_accy 93.00
2024-11-17 02:02:36,238 [dsease_hoc.py] => Task correct: 16.96
2024-11-17 02:02:36,239 [dsease_hoc.py] => Task acc: 86.58
2024-11-17 02:02:36,285 [trainer.py] => No NME accuracy.
2024-11-17 02:02:36,285 [trainer.py] => CNN: {'total': 16.79, '00-04': 5.8, '05-09': 0.0, '10-14': 3.6, '15-19': 3.0, '20-24': 8.6, '25-29': 1.8, '30-34': 10.8, '35-39': 27.4, '40-44': 7.8, '45-49': 8.6, '50-54': 3.6, '55-59': 5.4, '60-64': 8.8, '65-69': 8.8, '70-74': 7.8, '75-79': 9.8, '80-84': 38.0, '85-89': 27.0, '90-94': 49.6, '95-99': 99.6, 'old': 12.43, 'new': 99.6}
2024-11-17 02:02:36,285 [trainer.py] => CNN top1 curve: [99.6, 93.4, 67.33, 54.25, 43.24, 43.7, 22.77, 27.65, 28.13, 20.48, 20.0, 15.37, 19.51, 20.51, 23.77, 22.31, 17.07, 16.96, 14.77, 16.79]
2024-11-17 02:02:36,286 [trainer.py] => CNN top5 curve: [100.0, 99.9, 91.73, 79.05, 80.08, 74.7, 70.4, 61.28, 62.44, 59.2, 56.36, 52.73, 53.83, 55.1, 54.73, 53.28, 50.65, 50.0, 48.99, 48.67]

2024-11-17 02:02:36,286 [trainer.py] => Average Accuracy (CNN): 34.3805 

